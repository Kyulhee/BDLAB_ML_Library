{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] file_name:  inter_OV_Var_200 \n",
      "sample : 196  \n",
      "features : 200\n",
      "[2] file_name:  inter_OV_Annotation3000_100 \n",
      "sample : 196  \n",
      "features : 100\n",
      "[3] file_name:  inter_OV_CV_400 \n",
      "sample : 196  \n",
      "features : 400\n",
      "[4] file_name:  inter_OV_new_Diff_400 \n",
      "sample : 196  \n",
      "features : 400\n",
      "[5] file_name:  inter_OV_Clin \n",
      "sample : 196  \n",
      "features : 35\n",
      "[6] file_name:  inter_OV_SNV_ch \n",
      "sample : 196  \n",
      "features : 282\n"
     ]
    }
   ],
   "source": [
    "path = \"C://test/TC_intersect_subsamples/\"\n",
    "types = [\"inter_OV_Var_200\", \"inter_OV_Annotation3000_100\", \n",
    "         \"inter_OV_CV_400\", \"inter_OV_new_Diff_400\",\n",
    "         \"inter_OV_Clin\", \n",
    "         \"inter_OV_SNV_ch\" \n",
    "         ]\n",
    "\n",
    "file_1 = path+types[0]+\".csv\"\n",
    "file_2 = path+types[1]+\".csv\"\n",
    "file_3 = path+types[2]+\".csv\"\n",
    "file_4 = path+types[3]+\".csv\"\n",
    "file_5 = path+types[4]+\".csv\"\n",
    "file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "sample_1,features_1 = data_1.shape\n",
    "sample_2,features_2 = data_2.shape\n",
    "sample_3,features_3 = data_3.shape\n",
    "sample_4,features_4 = data_4.shape\n",
    "sample_5,features_5 = data_5.shape\n",
    "sample_6,features_6 = data_6.shape\n",
    "\n",
    "# Data frame include index & Platinum_Status column, substract 2 to calculate real number of features \n",
    "[features_1, features_2, features_3, features_4, features_5, features_6] = [features_1-2, features_2-2, features_3-2, features_4-2, features_5-2, features_6-2]\n",
    "\n",
    "print(\"[1] file_name: \", types[0], \"\\nsample : {}  \\nfeatures : {}\".format(sample_1,features_1))\n",
    "print(\"[2] file_name: \", types[1], \"\\nsample : {}  \\nfeatures : {}\".format(sample_2,features_2))\n",
    "print(\"[3] file_name: \", types[2], \"\\nsample : {}  \\nfeatures : {}\".format(sample_3,features_3))\n",
    "print(\"[4] file_name: \", types[3], \"\\nsample : {}  \\nfeatures : {}\".format(sample_4,features_4))\n",
    "print(\"[5] file_name: \", types[4], \"\\nsample : {}  \\nfeatures : {}\".format(sample_5,features_5))\n",
    "print(\"[6] file_name: \", types[5], \"\\nsample : {}  \\nfeatures : {}\".format(sample_6,features_6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_Var_200  ######################################\n",
      "(156, 200) (40, 200)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[0]+'  ######################################')\n",
    "\n",
    "train_data_1 = data_1.iloc[list(data_1.iloc[:,-1]!=1)]\n",
    "test_data_1 = data_1.iloc[list(data_1.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_1 = train_data_1.Platinum_Status\n",
    "x_val_1 = train_data_1.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_1 = test_data_1.Platinum_Status\n",
    "test_x_val_1 = test_data_1.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_1.shape, test_x_val_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_Annotation3000_100  ######################################\n",
      "(156, 100) (40, 100)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[1]+'  ######################################')\n",
    "\n",
    "train_data_2 = data_2.iloc[list(data_2.iloc[:,-1]!=1)]\n",
    "test_data_2 = data_2.iloc[list(data_2.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_2 = train_data_2.Platinum_Status\n",
    "x_val_2 = train_data_2.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_2 = test_data_2.Platinum_Status\n",
    "test_x_val_2 = test_data_2.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_2.shape, test_x_val_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_CV_400  ######################################\n",
      "(156, 400) (40, 400)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[2]+'  ######################################')\n",
    "\n",
    "train_data_3 = data_3.iloc[list(data_3.iloc[:,-1]!=1)]\n",
    "test_data_3 = data_3.iloc[list(data_3.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_3 = train_data_3.Platinum_Status\n",
    "x_val_3 = train_data_3.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_3 = test_data_3.Platinum_Status\n",
    "test_x_val_3 = test_data_3.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_3.shape, test_x_val_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_new_Diff_400  ######################################\n",
      "(156, 400) (40, 400)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[3]+'  ######################################')\n",
    "\n",
    "train_data_4 = data_4.iloc[list(data_4.iloc[:,-1]!=1)]\n",
    "test_data_4 = data_4.iloc[list(data_4.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_4 = train_data_4.Platinum_Status\n",
    "x_val_4 = train_data_4.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_4 = test_data_4.Platinum_Status\n",
    "test_x_val_4 = test_data_4.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_4.shape, test_x_val_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_Clin  ######################################\n",
      "(156, 35) (40, 35)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[4]+'  ######################################')\n",
    "\n",
    "train_data_5 = data_5.iloc[list(data_5.iloc[:,-1]!=1)]\n",
    "test_data_5 = data_5.iloc[list(data_5.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_5 = train_data_5.Platinum_Status\n",
    "x_val_5 = train_data_5.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_5 = test_data_5.Platinum_Status\n",
    "test_x_val_5 = test_data_5.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_5.shape, test_x_val_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_SNV_ch  ######################################\n",
      "(156, 282) (40, 282)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[5]+'  ######################################')\n",
    "\n",
    "train_data_6 = data_6.iloc[list(data_6.iloc[:,-1]!=1)]\n",
    "test_data_6 = data_6.iloc[list(data_6.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_6 = train_data_6.Platinum_Status\n",
    "x_val_6 = train_data_6.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_6 = test_data_6.Platinum_Status\n",
    "test_x_val_6 = test_data_6.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_6.shape, test_x_val_6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Seperate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building seperate model for ensemble(model 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 100 400 400 35 282\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "print(features_1, features_2, features_3, features_4, features_5, features_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_Var_200  ######################################\n",
      "Epoch 1/20\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 1.1480 - acc: 0.5577\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 0s 486us/step - loss: 1.0085 - acc: 0.5577\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 0s 607us/step - loss: 1.0336 - acc: 0.5192\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 0s 556us/step - loss: 0.9133 - acc: 0.5577\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 0s 537us/step - loss: 0.7959 - acc: 0.5641\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 0s 537us/step - loss: 0.7485 - acc: 0.6282\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 0s 569us/step - loss: 0.8666 - acc: 0.5449\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 0s 543us/step - loss: 0.7507 - acc: 0.5833\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 0s 569us/step - loss: 0.7001 - acc: 0.6410\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 0s 556us/step - loss: 0.6894 - acc: 0.6410\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 0s 569us/step - loss: 0.7095 - acc: 0.5769\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 0s 531us/step - loss: 0.7670 - acc: 0.6603\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 0s 563us/step - loss: 0.7228 - acc: 0.6346\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 0s 550us/step - loss: 0.6683 - acc: 0.6667\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 0s 543us/step - loss: 0.6468 - acc: 0.6923\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 0s 550us/step - loss: 0.6212 - acc: 0.6538\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 0s 531us/step - loss: 0.5968 - acc: 0.6538\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 0s 550us/step - loss: 0.5863 - acc: 0.6923\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 0s 537us/step - loss: 0.6022 - acc: 0.6987\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 0s 556us/step - loss: 0.6588 - acc: 0.6346\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "40/40 [==============================] - 0s 274us/step\n",
      "Train Accuracy: 0.8717948672098991\n",
      "Train Sensitivities & Specificities : 0.9705882352941176, 0.7954545454545454\n",
      "Test Accuracy: 0.325\n",
      "Test Sensitivities & Specificities : 0.4444444444444444, 0.22727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\saving.py:126: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[0]+'  ######################################')\n",
    "\n",
    "keep_prob_1 = 0.5\n",
    "\n",
    "input_m_1 = Input(shape=(features_1,))\n",
    "m_1_dp = Dropout(keep_prob_1)(input_m_1)\n",
    "\n",
    "for i in [100, 150]:\n",
    "  m_1 = Dense(i,activation='relu')(m_1_dp)\n",
    "\n",
    "m_1_dp = Dropout(keep_prob_1)(m_1)\n",
    "m_1_final = m_1_dp\n",
    "output_m_1 = Dense(1, activation=\"sigmoid\")(m_1_final)\n",
    "\n",
    "model_1 = Model(inputs=input_m_1,outputs=output_m_1)\n",
    "\n",
    "model_1.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(x_val_1, y_val_1, epochs=20, batch_size=10)\n",
    "\n",
    "m_1_tr_loss,m_1_tr_accuracy=model_1.evaluate(x_val_1,y_val_1)\n",
    "m_1_loss,m_1_accuracy= model_1.evaluate(test_x_val_1,test_y_val_1)\n",
    "\n",
    "m_1_predictions = model_1.predict(x_val_1)\n",
    "labeled_m_1_predictions = np.where(m_1_predictions > 0.5, 1, 0).flatten()\n",
    "m_1_tr_sensitivity, m_1_tr_specificity = check_correct(labeled_m_1_predictions, y_val_1)\n",
    "m_1_test_predictions = model_1.predict(test_x_val_1)\n",
    "labeled_m_1_test_predictions = np.where(m_1_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_1_sensitivity, m_1_specificity = check_correct(labeled_m_1_test_predictions, test_y_val_1)\n",
    "#m_1_test_predictions = m_1_test_predictions.flatten()\n",
    "m_1_test_predictions_flat = m_1_test_predictions[:,0]\n",
    "\n",
    "df_1 = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis_1\": list(m_1_test_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_1_test_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "df_1.to_csv(\"../result/prediction_result_m_1.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_1_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_1_tr_sensitivity)+\", \"+str(m_1_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_1_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_1_sensitivity)+\", \"+str(m_1_specificity))\n",
    "\n",
    "model_1.save(\"../models/Ovary/m_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_Annotation3000_100  ######################################\n",
      "Epoch 1/20\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.9397 - acc: 0.5256\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 0s 524us/step - loss: 0.8542 - acc: 0.5192\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.8914 - acc: 0.4872\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.7756 - acc: 0.5449\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.8389 - acc: 0.5256\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.7904 - acc: 0.5000\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 0s 511us/step - loss: 0.7283 - acc: 0.5513\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 0s 454us/step - loss: 0.7320 - acc: 0.5962\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.6501 - acc: 0.6538\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 0s 467us/step - loss: 0.7072 - acc: 0.5449\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.7158 - acc: 0.5769\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 0s 460us/step - loss: 0.7171 - acc: 0.5577\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.7325 - acc: 0.5000\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.7403 - acc: 0.5449\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 0s 486us/step - loss: 0.7375 - acc: 0.5449\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.7003 - acc: 0.5897\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 0s 486us/step - loss: 0.6877 - acc: 0.5833\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.7236 - acc: 0.5513\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 0s 486us/step - loss: 0.6635 - acc: 0.5897\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 0s 511us/step - loss: 0.6526 - acc: 0.6410\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "40/40 [==============================] - 0s 224us/step\n",
      "Train Accuracy: 0.6474359004925458\n",
      "Train Sensitivities & Specificities : 0.19117647058823528, 1.0\n",
      "Test Accuracy: 0.575\n",
      "Test Sensitivities & Specificities : 0.05555555555555555, 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\saving.py:126: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[1]+'  ######################################')\n",
    "\n",
    "keep_prob_2 = 0.5\n",
    "\n",
    "input_m_2 = Input(shape=(features_2,))\n",
    "m_2_dp = Dropout(keep_prob_2)(input_m_2)\n",
    "\n",
    "for i in [100, 150]:\n",
    "  m_2 = Dense(i,activation='relu')(m_2_dp)\n",
    "\n",
    "m_2_dp = Dropout(keep_prob_2)(m_2)\n",
    "m_2_final = m_2_dp\n",
    "output_m_2 = Dense(1, activation=\"sigmoid\")(m_2_final)\n",
    "model_2 = Model(inputs=input_m_2,outputs=output_m_2)\n",
    "\n",
    "model_2.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(x_val_2, y_val_2, epochs=20, batch_size=10)\n",
    "\n",
    "m_2_tr_loss,m_2_tr_accuracy=model_2.evaluate(x_val_2,y_val_2)\n",
    "m_2_loss,m_2_accuracy= model_2.evaluate(test_x_val_2,test_y_val_2)\n",
    "\n",
    "m_2_predictions = model_2.predict(x_val_2)\n",
    "labeled_m_2_predictions = np.where(m_2_predictions > 0.5, 1, 0).flatten()\n",
    "m_2_tr_sensitivity, m_2_tr_specificity = check_correct(labeled_m_2_predictions, y_val_2)\n",
    "m_2_test_predictions = model_2.predict(test_x_val_2)\n",
    "labeled_m_2_test_predictions = np.where(m_2_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_2_sensitivity, m_2_specificity = check_correct(labeled_m_2_test_predictions, test_y_val_2)\n",
    "#m_2_test_predictions = m_2_test_predictions.flatten()\n",
    "m_2_test_predictions_flat = m_2_test_predictions[:,0]\n",
    "\n",
    "df_2 = pd.DataFrame(data={\"patient\":list(test_data_2.index), \"hypothesis_2\": list(m_2_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_m_2_test_predictions), \"Platinum_Status\":list(test_y_val_2)})\n",
    "df_2.to_csv(\"../result/prediction_result_m_2.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_2\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_2_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_2_tr_sensitivity)+\", \"+str(m_2_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_2_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_2_sensitivity)+\", \"+str(m_2_specificity))\n",
    "\n",
    "model_2.save(\"../models/Ovary/m_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_CV_400  ######################################\n",
      "Epoch 1/20\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.7305 - acc: 0.5321\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.6396 - acc: 0.6410\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 0s 627us/step - loss: 0.5748 - acc: 0.6859\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 0s 614us/step - loss: 0.5673 - acc: 0.7372\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 0s 659us/step - loss: 0.5050 - acc: 0.7821\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.5199 - acc: 0.7436\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 0s 627us/step - loss: 0.4218 - acc: 0.8590\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 0s 607us/step - loss: 0.4469 - acc: 0.8333\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 0s 633us/step - loss: 0.4469 - acc: 0.7949\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 0s 607us/step - loss: 0.4430 - acc: 0.8077\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 0s 594us/step - loss: 0.3310 - acc: 0.9038\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.3805 - acc: 0.8397\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.3515 - acc: 0.8397\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.3922 - acc: 0.8205\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 0s 658us/step - loss: 0.3660 - acc: 0.8397\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 0s 627us/step - loss: 0.3736 - acc: 0.8590\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.3026 - acc: 0.8718\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 0s 588us/step - loss: 0.2887 - acc: 0.9167\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.2915 - acc: 0.8718\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.2840 - acc: 0.9038\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "40/40 [==============================] - 0s 249us/step\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.65\n",
      "Test Sensitivities & Specificities : 0.5555555555555556, 0.7272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\saving.py:126: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[2]+'  ######################################')\n",
    "\n",
    "keep_prob_3 = 0.5\n",
    "\n",
    "input_m_3 = Input(shape=(features_3,))\n",
    "m_3_dp = Dropout(keep_prob_3)(input_m_3)\n",
    "\n",
    "for i in [100, 150]:\n",
    "  m_3 = Dense(i,activation='relu')(m_3_dp)\n",
    "\n",
    "m_3_dp = Dropout(keep_prob_3)(m_3)\n",
    "m_3_final = m_3_dp\n",
    "output_m_3 = Dense(1, activation=\"sigmoid\")(m_3_final)\n",
    "model_3 = Model(inputs=input_m_3,outputs=output_m_3)\n",
    "\n",
    "model_3.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_3.fit(x_val_3, y_val_3, epochs=20, batch_size=10)\n",
    "\n",
    "m_3_tr_loss,m_3_tr_accuracy=model_3.evaluate(x_val_3,y_val_3)\n",
    "m_3_loss,m_3_accuracy= model_3.evaluate(test_x_val_3,test_y_val_3)\n",
    "\n",
    "m_3_predictions = model_3.predict(x_val_3)\n",
    "labeled_m_3_predictions = np.where(m_3_predictions > 0.5, 1, 0).flatten()\n",
    "m_3_tr_sensitivity, m_3_tr_specificity = check_correct(labeled_m_3_predictions, y_val_3)\n",
    "m_3_test_predictions = model_3.predict(test_x_val_3)\n",
    "labeled_m_3_test_predictions = np.where(m_3_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_3_sensitivity, m_3_specificity = check_correct(labeled_m_3_test_predictions, test_y_val_3)\n",
    "#m_3_test_predictions = m_3_test_predictions.flatten()\n",
    "m_3_test_predictions_flat = m_3_test_predictions[:,0]\n",
    "\n",
    "df_3 = pd.DataFrame(data={\"patient\":list(test_data_3.index), \"hypothesis_3\": list(m_3_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_m_3_test_predictions), \"Platinum_Status\":list(test_y_val_3)})\n",
    "df_3.to_csv(\"../result/prediction_result_m_3.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_3\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_3_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_3_tr_sensitivity)+\", \"+str(m_3_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_3_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_3_sensitivity)+\", \"+str(m_3_specificity))\n",
    "\n",
    "model_3.save(\"../models/Ovary/m_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_new_Diff_400  ######################################\n",
      "Epoch 1/20\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 1.5935 - acc: 0.4487\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 0s 575us/step - loss: 1.2799 - acc: 0.5000\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 0s 633us/step - loss: 0.8351 - acc: 0.6282\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 0s 633us/step - loss: 0.8799 - acc: 0.6410\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.7213 - acc: 0.6474\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 0s 627us/step - loss: 0.6369 - acc: 0.6731\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.5850 - acc: 0.6859\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 0s 633us/step - loss: 0.5828 - acc: 0.6923\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 0s 582us/step - loss: 0.6145 - acc: 0.6795\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 0s 614us/step - loss: 0.5307 - acc: 0.7308\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.5994 - acc: 0.6859\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.5208 - acc: 0.7628\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.4652 - acc: 0.7628\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 0s 607us/step - loss: 0.5819 - acc: 0.7244\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 0s 588us/step - loss: 0.4109 - acc: 0.8013\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.4617 - acc: 0.7821\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.4401 - acc: 0.7756\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.5288 - acc: 0.7436\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.5144 - acc: 0.7179\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 0s 614us/step - loss: 0.4916 - acc: 0.7179\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "40/40 [==============================] - 0s 274us/step\n",
      "Train Accuracy: 0.9487179487179487\n",
      "Train Sensitivities & Specificities : 0.9852941176470589, 0.9204545454545454\n",
      "Test Accuracy: 0.55\n",
      "Test Sensitivities & Specificities : 0.4444444444444444, 0.6363636363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\saving.py:126: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[3]+'  ######################################')\n",
    "\n",
    "keep_prob_4 = 0.5\n",
    "\n",
    "input_m_4 = Input(shape=(features_4,))\n",
    "m_4_dp = Dropout(keep_prob_4)(input_m_4)\n",
    "\n",
    "for i in [100, 150]:\n",
    "  m_4 = Dense(i,activation='relu')(m_4_dp)\n",
    "\n",
    "m_4_dp = Dropout(keep_prob_4)(m_4)\n",
    "m_4_final = m_4_dp\n",
    "output_m_4 = Dense(1, activation=\"sigmoid\")(m_4_final)\n",
    "model_4 = Model(inputs=input_m_4,outputs=output_m_4)\n",
    "\n",
    "model_4.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_4.fit(x_val_4, y_val_4, epochs=20, batch_size=10)\n",
    "\n",
    "m_4_tr_loss,m_4_tr_accuracy=model_4.evaluate(x_val_4,y_val_4)\n",
    "m_4_loss,m_4_accuracy= model_4.evaluate(test_x_val_4,test_y_val_4)\n",
    "\n",
    "m_4_predictions = model_4.predict(x_val_4)\n",
    "labeled_m_4_predictions = np.where(m_4_predictions > 0.5, 1, 0).flatten()\n",
    "m_4_tr_sensitivity, m_4_tr_specificity = check_correct(labeled_m_4_predictions, y_val_4)\n",
    "m_4_test_predictions = model_4.predict(test_x_val_4)\n",
    "labeled_m_4_test_predictions = np.where(m_4_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_4_sensitivity, m_4_specificity = check_correct(labeled_m_4_test_predictions, test_y_val_4)\n",
    "#m_4_test_predictions = m_4_test_predictions.flatten()\n",
    "m_4_test_predictions_flat = m_4_test_predictions[:,0]\n",
    "\n",
    "df_4 = pd.DataFrame(data={\"patient\":list(test_data_4.index), \"hypothesis_4\": list(m_4_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_m_4_test_predictions), \"Platinum_Status\":list(test_y_val_4)})\n",
    "df_4.to_csv(\"../result/prediction_result_m_4.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_4\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_4_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_4_tr_sensitivity)+\", \"+str(m_4_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_4_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_4_sensitivity)+\", \"+str(m_4_specificity))\n",
    "\n",
    "model_4.save(\"../models/Ovary/m_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_Clin  ######################################\n",
      "Epoch 1/20\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.9133 - acc: 0.4423\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 0s 537us/step - loss: 0.7612 - acc: 0.5833\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 0s 505us/step - loss: 0.7524 - acc: 0.5641\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 0s 473us/step - loss: 0.7198 - acc: 0.5769\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 0s 518us/step - loss: 0.6952 - acc: 0.6154\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 0s 467us/step - loss: 0.7286 - acc: 0.5449\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 0s 499us/step - loss: 0.6753 - acc: 0.5962\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.6364 - acc: 0.6474\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.6861 - acc: 0.6026\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 0s 473us/step - loss: 0.6821 - acc: 0.5833\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 0s 467us/step - loss: 0.6644 - acc: 0.6282\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.6574 - acc: 0.6282\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 0s 467us/step - loss: 0.7507 - acc: 0.6795\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 0s 467us/step - loss: 0.6047 - acc: 0.6154\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.6481 - acc: 0.6346\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.6938 - acc: 0.5897\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 0s 473us/step - loss: 0.6761 - acc: 0.5385\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 0s 486us/step - loss: 0.6303 - acc: 0.6154\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.6210 - acc: 0.6474\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 0s 511us/step - loss: 0.5832 - acc: 0.7051\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "40/40 [==============================] - 0s 199us/step\n",
      "Train Accuracy: 0.8269230815080496\n",
      "Train Sensitivities & Specificities : 0.7058823529411765, 0.9204545454545454\n",
      "Test Accuracy: 0.6\n",
      "Test Sensitivities & Specificities : 0.5555555555555556, 0.6363636363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\saving.py:126: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[4]+'  ######################################')\n",
    "\n",
    "keep_prob_5 = 0.5\n",
    "\n",
    "input_m_5 = Input(shape=(features_5,))\n",
    "m_5_dp = Dropout(keep_prob_5)(input_m_5)\n",
    "\n",
    "for i in [100, 150]:\n",
    "  m_5 = Dense(i,activation='relu')(m_5_dp)\n",
    "\n",
    "m_5_dp = Dropout(keep_prob_5)(m_5)\n",
    "m_5_final = m_5_dp\n",
    "output_m_5 = Dense(1, activation=\"sigmoid\")(m_5_final)\n",
    "model_5 = Model(inputs=input_m_5,outputs=output_m_5)\n",
    "\n",
    "model_5.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_5.fit(x_val_5, y_val_5, epochs=20, batch_size=10)\n",
    "\n",
    "m_5_tr_loss,m_5_tr_accuracy=model_5.evaluate(x_val_5,y_val_5)\n",
    "m_5_loss,m_5_accuracy= model_5.evaluate(test_x_val_5,test_y_val_5)\n",
    "m_5_predictions = model_5.predict(x_val_5)\n",
    "labeled_m_5_predictions = np.where(m_5_predictions > 0.5, 1, 0).flatten()\n",
    "m_5_tr_sensitivity, m_5_tr_specificity = check_correct(labeled_m_5_predictions, y_val_5)\n",
    "m_5_test_predictions = model_5.predict(test_x_val_5)\n",
    "labeled_m_5_test_predictions = np.where(m_5_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_5_sensitivity, m_5_specificity = check_correct(labeled_m_5_test_predictions, test_y_val_5)\n",
    "#m_5_test_predictions = m_5_test_predictions.flatten()\n",
    "m_5_test_predictions_flat = m_5_test_predictions[:,0]\n",
    "\n",
    "df_5 = pd.DataFrame(data={\"patient\":list(test_data_5.index), \"hypothesis_5\": list(m_5_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_m_5_test_predictions), \"Platinum_Status\":list(test_y_val_5)})\n",
    "df_5.to_csv(\"../result/prediction_result_m_5.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_5\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_5_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_5_tr_sensitivity)+\", \"+str(m_5_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_5_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_5_sensitivity)+\", \"+str(m_5_specificity))\n",
    "\n",
    "model_5.save(\"../models/Ovary/m_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  inter_OV_SNV_ch  ######################################\n",
      "Epoch 1/20\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 0.7156 - acc: 0.4295\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 0s 614us/step - loss: 0.6918 - acc: 0.5000\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.6712 - acc: 0.5641\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 0s 607us/step - loss: 0.6702 - acc: 0.5833\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 0s 646us/step - loss: 0.6380 - acc: 0.6795\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.6348 - acc: 0.6603\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 0s 627us/step - loss: 0.6369 - acc: 0.6603\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 0s 639us/step - loss: 0.5865 - acc: 0.7308\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 0s 607us/step - loss: 0.6059 - acc: 0.6474\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.5886 - acc: 0.6795\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.5472 - acc: 0.7244\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 0s 614us/step - loss: 0.5571 - acc: 0.7308\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 0s 575us/step - loss: 0.5543 - acc: 0.7308\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.5300 - acc: 0.7692\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.5198 - acc: 0.7821\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 0s 575us/step - loss: 0.4827 - acc: 0.8077\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 0s 620us/step - loss: 0.4953 - acc: 0.8077\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 0s 627us/step - loss: 0.4834 - acc: 0.7949\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.4533 - acc: 0.8526\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 0s 569us/step - loss: 0.4590 - acc: 0.8013\n",
      "156/156 [==============================] - 1s 7ms/step\n",
      "40/40 [==============================] - 0s 249us/step\n",
      "Train Accuracy: 0.916666662081694\n",
      "Train Sensitivities & Specificities : 0.8088235294117647, 1.0\n",
      "Test Accuracy: 0.6\n",
      "Test Sensitivities & Specificities : 0.4444444444444444, 0.7272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\saving.py:126: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[5]+'  ######################################')\n",
    "\n",
    "keep_prob_6 = 0.5\n",
    "\n",
    "input_m_6 = Input(shape=(features_6,))\n",
    "m_6_dp = Dropout(keep_prob_6)(input_m_6)\n",
    "\n",
    "for i in [100, 150]:\n",
    "  m_6 = Dense(i,activation='relu')(m_6_dp)\n",
    "\n",
    "m_6_dp = Dropout(keep_prob_6)(m_6)\n",
    "m_6_final = m_6_dp\n",
    "output_m_6 = Dense(1, activation=\"sigmoid\")(m_6_final)\n",
    "model_6 = Model(inputs=input_m_6,outputs=output_m_6)\n",
    "\n",
    "model_6.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_6.fit(x_val_6, y_val_6, epochs=20, batch_size=10)\n",
    "\n",
    "m_6_tr_loss,m_6_tr_accuracy=model_6.evaluate(x_val_6,y_val_6)\n",
    "m_6_loss,m_6_accuracy= model_6.evaluate(test_x_val_6,test_y_val_6)\n",
    "\n",
    "m_6_predictions = model_6.predict(x_val_6)\n",
    "labeled_m_6_predictions = np.where(m_6_predictions > 0.5, 1, 0).flatten()\n",
    "m_6_tr_sensitivity, m_6_tr_specificity = check_correct(labeled_m_6_predictions, y_val_6)\n",
    "m_6_test_predictions = model_6.predict(test_x_val_6)\n",
    "labeled_m_6_test_predictions = np.where(m_6_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_6_sensitivity, m_6_specificity = check_correct(labeled_m_6_test_predictions, test_y_val_6)\n",
    "#m_6_test_predictions = m_6_test_predictions.flatten()\n",
    "m_6_test_predictions_flat = m_6_test_predictions[:,0]\n",
    "\n",
    "df_6 = pd.DataFrame(data={\"patient\":list(test_data_6.index), \"hypothesis_6\": list(m_6_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_m_6_test_predictions), \"Platinum_Status\":list(test_y_val_6)})\n",
    "df_6.to_csv(\"../result/prediction_result_m_6.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_6\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_6_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_6_tr_sensitivity)+\", \"+str(m_6_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_6_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_6_sensitivity)+\", \"+str(m_6_specificity))\n",
    "\n",
    "model_6.save(\"../models/Ovary/m_6.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating seperate model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< inter_OV_Var_200 > tr: 0.8717948672098991, ts: 0.325\n",
      "< inter_OV_Annotation3000_100 > tr: 0.6474359004925458, ts: 0.575\n",
      "< inter_OV_CV_400 > tr: 1.0, ts: 0.65\n",
      "< inter_OV_new_Diff_400 > tr: 0.9487179487179487, ts: 0.55\n",
      "< inter_OV_Clin > tr: 0.8269230815080496, ts: 0.6\n",
      "< inter_OV_SNV_ch > tr: 0.916666662081694, ts: 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"< \"+types[0]+\" > tr: \"+str(m_1_tr_accuracy)+\", ts: \"+str(m_1_accuracy))\n",
    "print(\"< \"+types[1]+\" > tr: \"+str(m_2_tr_accuracy)+\", ts: \"+str(m_2_accuracy))\n",
    "print(\"< \"+types[2]+\" > tr: \"+str(m_3_tr_accuracy)+\", ts: \"+str(m_3_accuracy))\n",
    "print(\"< \"+types[3]+\" > tr: \"+str(m_4_tr_accuracy)+\", ts: \"+str(m_4_accuracy))\n",
    "print(\"< \"+types[4]+\" > tr: \"+str(m_5_tr_accuracy)+\", ts: \"+str(m_5_accuracy))\n",
    "print(\"< \"+types[5]+\" > tr: \"+str(m_6_tr_accuracy)+\", ts: \"+str(m_6_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building original ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################## DNN Ensemble ##################################\n",
      "[1, 2, 3, 5, 6]\n",
      "inter_OV_Var_200\n",
      "inter_OV_Annotation3000_100\n",
      "inter_OV_CV_400\n",
      "inter_OV_Clin\n",
      "inter_OV_SNV_ch\n",
      "#############################################################################################\n",
      "Epoch 1/5\n",
      "156/156 [==============================]156/156 [==============================] - 4s 25ms/step - loss: 0.6814 - acc: 0.5513\n",
      "\n",
      "Epoch 2/5\n",
      "156/156 [==============================]156/156 [==============================] - 0s 3ms/step - loss: 0.6481 - acc: 0.5641\n",
      "\n",
      "Epoch 3/5\n",
      "156/156 [==============================]156/156 [==============================] - 0s 3ms/step - loss: 0.6007 - acc: 0.5641\n",
      "\n",
      "Epoch 4/5\n",
      "156/156 [==============================]156/156 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.5641\n",
      "\n",
      "Epoch 5/5\n",
      "156/156 [==============================]156/156 [==============================] - 0s 3ms/step - loss: 0.4867 - acc: 0.5897\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x218febbccc0>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = [1, 2, 3, 5, 6]\n",
    "print(\"################################## DNN Ensemble ##################################\")\n",
    "print(select)\n",
    "for type_i in select:\n",
    "    print(types[type_i-1])\n",
    "print(\"#############################################################################################\")\n",
    "\n",
    "m_1_predictions = model_1.predict(x_val_1)\n",
    "m_2_predictions = model_2.predict(x_val_2)\n",
    "m_3_predictions = model_3.predict(x_val_3)\n",
    "m_4_predictions = model_4.predict(x_val_4)\n",
    "m_5_predictions = model_5.predict(x_val_5)\n",
    "m_6_predictions = model_6.predict(x_val_6)\n",
    "m_predictions = [m_1_predictions, m_2_predictions, m_3_predictions, m_4_predictions, m_5_predictions, m_6_predictions]\n",
    "m_predictions_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_predictions_select.append(m_predictions[select[i]-1])\n",
    "    \n",
    "ensemble_x_val = np.concatenate(m_predictions_select, axis=1)\n",
    "\n",
    "ensemble_model = keras.Sequential([\n",
    "    keras.layers.Dense(3,input_shape=(len(select),),name=\"input_layer\"),\n",
    "    keras.layers.Dense(2,activation=\"relu\"),        \n",
    "    keras.layers.Dense(1,activation='sigmoid',name=\"output_layer\")])\n",
    "\n",
    "ensemble_model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ensemble_model.fit(ensemble_x_val, y_val_1, epochs=5, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _DNN Combiner_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================]156/156 [==============================] - 0s 70us/step\n",
      "\n",
      "40/40 [==============================]40/40 [==============================] - 0s 125us/step\n",
      "\n",
      "Train Accuracy: 0.9423076953643408\n",
      "Train Sensitivities & Specificities : 0.8676470588235294, 1.0\n",
      "Test Accuracy: 0.575\n",
      "Test Sensitivities & Specificities : 0.1111111111111111, 0.9545454545454546\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "m_1_test_predictions = model_1.predict(test_x_val_1)\n",
    "m_2_test_predictions = model_2.predict(test_x_val_2)\n",
    "m_3_test_predictions = model_3.predict(test_x_val_3)\n",
    "m_4_test_predictions = model_4.predict(test_x_val_4)\n",
    "m_5_test_predictions = model_5.predict(test_x_val_5)\n",
    "m_6_test_predictions = model_6.predict(test_x_val_6)\n",
    "m_test_predictions = [m_1_test_predictions, m_2_test_predictions, m_3_test_predictions, m_4_test_predictions, m_5_test_predictions, m_6_test_predictions]\n",
    "m_test_predictions_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_test_predictions_select.append(m_test_predictions[select[i]-1])\n",
    "\n",
    "ensemble_test_x_val = np.concatenate(m_test_predictions_select, axis=1)\n",
    "\n",
    "em_tr_loss,em_tr_accuracy= ensemble_model.evaluate(ensemble_x_val,y_val_1)\n",
    "em_loss,em_accuracy= ensemble_model.evaluate(ensemble_test_x_val,test_y_val_1)\n",
    "\n",
    "ensemble_predictions = ensemble_model.predict(ensemble_x_val)\n",
    "labeled_ensemble_predictions = np.where(ensemble_predictions > 0.5, 1, 0).flatten()\n",
    "ensemble_tr_sensitivity, ensemble_tr_specificity = check_correct(labeled_ensemble_predictions, y_val_1)\n",
    "\n",
    "ensemble_test_predictions = ensemble_model.predict(ensemble_test_x_val)\n",
    "labeled_ensemble_test_predictions = np.where(ensemble_test_predictions > 0.5, 1, 0).flatten()\n",
    "ensemble_sensitivity, ensemble_specificity = check_correct(labeled_ensemble_test_predictions, test_y_val_1)\n",
    "\n",
    "ensemble_test_predictions_flat = ensemble_test_predictions[:,0]\n",
    "\n",
    "df_em = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis_1\": list(ensemble_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_ensemble_test_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "df_em.to_csv(\"../result/prediction_result_EM_DNN.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(ensemble_tr_sensitivity)+\", \"+str(ensemble_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(em_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(ensemble_sensitivity)+\", \"+str(ensemble_specificity))\n",
    "\n",
    "ensemble_model.save(\"../models/Ovary/EM_DNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _mean_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy for mean ensemble : 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy for mean ensemble : 0.625\n",
      "Test Sensitivities & Specificities : 0.3888888888888889, 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "mean_tr_predictions=sum(m_predictions_select)/len(select)\n",
    "mean_em_labeled_tr_predictions = np.where(mean_tr_predictions > 0.5, 1, 0).flatten()\n",
    "mean_em_tr_accuracy = sum(mean_em_labeled_tr_predictions==y_val_1.values)/len(y_val_1)\n",
    "mean_ensemble_tr_sensitivity, mean_ensemble_tr_specificity = check_correct(mean_em_labeled_tr_predictions, y_val_1)\n",
    "\n",
    "mean_predictions=sum(m_test_predictions_select)/len(select)\n",
    "mean_em_labeled_predictions = np.where(mean_predictions > 0.5, 1, 0).flatten()\n",
    "mean_em_accuracy = sum(mean_em_labeled_predictions==test_y_val_1.values)/len(test_y_val_1)\n",
    "mean_ensemble_sensitivity, mean_ensemble_specificity = check_correct(mean_em_labeled_predictions, test_y_val_1)\n",
    "\n",
    "mean_ensemble_test_predictions_flat = mean_predictions[:,0]\n",
    "\n",
    "df_em = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis_1\": list(mean_ensemble_test_predictions_flat), \n",
    "  \"prediction\":list(mean_em_labeled_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "df_em.to_csv(\"../result/prediction_result_EM_mean.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "print(\"Train Accuracy for mean ensemble : {}\".format(mean_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(mean_ensemble_tr_sensitivity)+\", \"+str(mean_ensemble_tr_specificity))\n",
    "print(\"Test Accuracy for mean ensemble : {}\".format(mean_em_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(mean_ensemble_sensitivity)+\", \"+str(mean_ensemble_specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferred Ensemble Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making new input data for t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 750)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = Model(inputs=[input_m_1], outputs=[m_1_final])\n",
    "results_m_1 = model.predict([x_val_1])\n",
    "\n",
    "model = Model(inputs=[input_m_2], outputs=[m_2_final])\n",
    "results_m_2 = model.predict([x_val_2])\n",
    "\n",
    "model = Model(inputs=[input_m_3], outputs=[m_3_final])\n",
    "results_m_3 = model.predict([x_val_3])\n",
    "\n",
    "model = Model(inputs=[input_m_4], outputs=[m_4_final])\n",
    "results_m_4 = model.predict([x_val_4])\n",
    "\n",
    "model = Model(inputs=[input_m_5], outputs=[m_5_final])\n",
    "results_m_5 = model.predict([x_val_5])\n",
    "\n",
    "model = Model(inputs=[input_m_6], outputs=[m_6_final])\n",
    "results_m_6 = model.predict([x_val_6])\n",
    "\n",
    "results_m_sum = [results_m_1, results_m_2, results_m_3, results_m_4, results_m_5, results_m_6]\n",
    "results_m_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    results_m_select.append(results_m_sum[select[i]-1])\n",
    "\n",
    "t_ensemble_x_val = np.concatenate(results_m_select, axis=1)\n",
    "print(t_ensemble_x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling t-ensemble  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "156/156 [==============================] - 3s 16ms/step - loss: 0.4931 - acc: 0.8782\n",
      "Epoch 2/2\n",
      "156/156 [==============================] - 0s 1ms/step - loss: 0.1562 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218ec021630>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ensemble_input = Input(shape=(t_ensemble_x_val.shape[1],))\n",
    "t_ensemble_h1 = Dense(20,activation='relu')(t_ensemble_input)\n",
    "t_ensemble_h2 = Dense(10,activation='relu')(t_ensemble_h1)\n",
    "t_ensemble_h3 = Dense(5,activation='relu')(t_ensemble_h2)\n",
    "t_ensemble_output = Dense(1,activation='sigmoid')(t_ensemble_h3)\n",
    "\n",
    "t_ensemble_model = Model(inputs=[t_ensemble_input],outputs=[t_ensemble_output])\n",
    "t_ensemble_model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "t_ensemble_model.fit(t_ensemble_x_val, y_val_1, epochs=2,batch_size=5)\n",
    "ensemble_model.save(\"../models/Ovary/t_EM_DNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 112us/step\n",
      "40/40 [==============================] - 0s 224us/step\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../result/prediction_result_EM_t.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-324-acaaf452eca9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m df_t_EM = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis_1\": list(t_ensemble_test_predictions_flat), \n\u001b[0;32m     40\u001b[0m   \"prediction\":list(labeled_t_ensemble_test_predictions), \"Platinum_Status\":list(test_y_val_1)})\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mdf_t_EM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../result/prediction_result_EM_t.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"patient\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hypothesis_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Platinum_Status\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train Accuracy: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_em_tr_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../result/prediction_result_EM_t.csv'"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input_m_1], outputs=[m_1_final])\n",
    "test_results_m_1 = model.predict([test_x_val_1])\n",
    "\n",
    "model = Model(inputs=[input_m_2], outputs=[m_2_final])\n",
    "test_results_m_2 = model.predict([test_x_val_2])\n",
    "\n",
    "model = Model(inputs=[input_m_3], outputs=[m_3_final])\n",
    "test_results_m_3 = model.predict([test_x_val_3])\n",
    "\n",
    "model = Model(inputs=[input_m_4], outputs=[m_4_final])\n",
    "test_results_m_4 = model.predict([test_x_val_4])\n",
    "\n",
    "model = Model(inputs=[input_m_5], outputs=[m_5_final])\n",
    "test_results_m_5 = model.predict([test_x_val_5])\n",
    "\n",
    "model = Model(inputs=[input_m_6], outputs=[m_6_final])\n",
    "test_results_m_6 = model.predict([test_x_val_6])\n",
    "\n",
    "test_results_m_sum = [test_results_m_1, test_results_m_2, test_results_m_3, test_results_m_4, test_results_m_5, test_results_m_6]\n",
    "test_results_m_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    test_results_m_select.append(test_results_m_sum[select[i]-1])\n",
    "\n",
    "t_ensemble_test_x_val = np.concatenate(test_results_m_select, axis=1)\n",
    "t_em_tr_accuracy = t_ensemble_model.evaluate(t_ensemble_x_val,y_val_1)[1]\n",
    "t_em_accuracy = t_ensemble_model.evaluate(t_ensemble_test_x_val,test_y_val_1)[1]\n",
    "\n",
    "t_ensemble_predictions = t_ensemble_model.predict(t_ensemble_x_val)\n",
    "labeled_t_ensemble_predictions = np.where(t_ensemble_predictions > 0.5, 1, 0).flatten()\n",
    "t_ensemble_tr_sensitivity, t_ensemble_tr_specificity = check_correct(labeled_t_ensemble_predictions, y_val_1)\n",
    "\n",
    "t_ensemble_test_predictions = t_ensemble_model.predict(t_ensemble_test_x_val)\n",
    "labeled_t_ensemble_test_predictions = np.where(t_ensemble_test_predictions > 0.5, 1, 0).flatten()\n",
    "t_ensemble_sensitivity, t_ensemble_specificity = check_correct(labeled_t_ensemble_test_predictions, test_y_val_1)\n",
    "\n",
    "t_ensemble_test_predictions_flat = t_ensemble_test_predictions[:,0]\n",
    "\n",
    "df_t_EM = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis_1\": list(t_ensemble_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_t_ensemble_test_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "df_t_EM.to_csv(\"../result/prediction_result_EM_t.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(t_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(t_ensemble_tr_sensitivity)+\", \"+str(t_ensemble_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(t_em_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(t_ensemble_sensitivity)+\", \"+str(t_ensemble_specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< model1 > tr: 0.8717948672098991, ts: 0.325\n",
      "< model2 > tr: 0.6474359004925458, ts: 0.575\n",
      "< model3 > tr: 1.0, ts: 0.65\n",
      "< model5 > tr: 0.8269230815080496, ts: 0.6\n",
      "< model6 > tr: 0.916666662081694, ts: 0.6\n",
      "< mean-em > tr: 1.0, ts: 0.625\n",
      "< d-comb em > tr: 0.9423076953643408, ts: 0.575\n",
      "< t-em > tr: 1.0, ts: 0.575\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "tr_accuracy_list = [m_1_tr_accuracy, m_2_tr_accuracy, m_3_tr_accuracy, m_4_tr_accuracy, m_5_tr_accuracy, m_6_tr_accuracy]\n",
    "ts_accuracy_list = [m_1_accuracy, m_2_accuracy, m_3_accuracy, m_4_accuracy, m_5_accuracy, m_6_accuracy]\n",
    "tr_accuracy_select = []\n",
    "ts_accuracy_select = []\n",
    "\n",
    "for i in select:\n",
    "    label.append(\"model\"+str(i))\n",
    "    tr_accuracy_select.append(tr_accuracy_list[i-1])\n",
    "    ts_accuracy_select.append(ts_accuracy_list[i-1])\n",
    "\n",
    "label = label+[\"mean-em\",\"d-comb em\",\"t-em\"]\n",
    "tr_accuracy_select= tr_accuracy_select + [mean_em_tr_accuracy, em_tr_accuracy, t_em_tr_accuracy]\n",
    "ts_accuracy_select= ts_accuracy_select + [mean_em_accuracy, em_accuracy, t_em_accuracy]\n",
    "\n",
    "for model_num in range(len(label)):\n",
    "    print(\"< \"+label[model_num]+\" > tr: \"+str(tr_accuracy_select[model_num])+\", ts: \"+str(ts_accuracy_select[model_num]))\n",
    "\n",
    "#label = [\"model1\",\"model2\",\"model3\",\"mean-em\",\"d-comb em\",\"t-em\"]\n",
    "#accuracy = [m1_accuracy,m2_accuracy,m3_accuracy,mean_em_accuracy,em_accuracy,t_em_accuracy ]\n",
    "#print(\"model1: \"+str(accuracy[0])+\"\\nmodel2: \"+str(accuracy[1])+\"\\nmodel3: \"+str(accuracy[2])+\"\\nmean-em: \"+str(accuracy[3])+\"\\nd-comb em: \"+str(accuracy[4])+\"\\nt-em: \"+str(accuracy[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def plot_bar_x():\n",
    "    # this is for plotting purpose\n",
    "    plt.figure(figsize=(30,20))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([min(m_1_accuracy,m_2_accuracy,m_3_accuracy,mean_em_accuracy,em_accuracy,t_em_accuracy)-0.02,1])\n",
    "    index = np.arange(len(label))\n",
    "    plt.bar(index, accuracy,color=['red', 'orange', 'yellow', \"green\",'blue', 'purple'],alpha=0.5,width=0.3)\n",
    "    plt.xlabel('Method', fontsize=35)\n",
    "    plt.ylabel('Accuracy', fontsize=35)\n",
    "    plt.yticks(fontsize=30)    \n",
    "    plt.xticks(index, label, fontsize=30, rotation=90)\n",
    "    plt.title('Performance Comparison for each Ensemble Model',fontsize=40)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-331-a28903a7e4e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_bar_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-330-dfa3459f882e>\u001b[0m in \u001b[0;36mplot_bar_x\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_1_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_2_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_3_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_em_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mem_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_em_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'orange'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yellow'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"green\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'purple'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Method'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "plot_bar_x()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
