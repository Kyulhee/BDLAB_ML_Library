{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importing packages & Defining methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense    #using set model component\n",
    "from keras.models import Model    #using set model \n",
    "from keras.utils import plot_model    #show model structure\n",
    "from keras import layers as Layer\n",
    "import keras \n",
    "from lib import dataProcess as dp\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pydot\n",
    "# prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Defining methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading data & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Path selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose the limma_option (1 or 2):\n",
      "[1] before_limma\n",
      "[2] limma\n",
      "2\n",
      "you select limma\n",
      "\n",
      "choose the method (1 or 2):\n",
      "[1] old\n",
      "[2] new\n",
      "2\n",
      "you select new\n",
      "\n",
      "choose the geneset (1 or 2):\n",
      "[1] gene_set1\n",
      "[2] gene_set2\n",
      "1\n",
      "you select gene_set1\n",
      "\n",
      "###################################################################\n",
      "path: ../../Data/new_set/\n",
      "save_model_path: ../models/new_set/\n",
      "save_result_path: ../results/new_set/\n"
     ]
    }
   ],
   "source": [
    "methods = [\"old\", \"new\"]\n",
    "genesets = [\"gene_set1\", \"gene_set2\"]\n",
    "limma_options = [\"before_limma\", \"limma\"]\n",
    "\n",
    "limma_option = limma_options[int(input(\"choose the limma_option (1 or 2):\\n[1] before_limma\\n[2] limma\\n\"))-1]\n",
    "print(\"you select \"+limma_option+\"\\n\")\n",
    "method = methods[int(input(\"choose the method (1 or 2):\\n[1] old\\n[2] new\\n\"))-1]\n",
    "print(\"you select \"+method+\"\\n\")\n",
    "geneset = genesets[int(input(\"choose the geneset (1 or 2):\\n[1] gene_set1\\n[2] gene_set2\\n\"))-1]\n",
    "print(\"you select \"+geneset+\"\\n\")\n",
    "\n",
    "path = \"../../Data/\"+method+\"_set/\"\n",
    "save_model_path = \"../models/\"+method+\"_set/\"\n",
    "save_result_path = \"../results/\"+method+\"_set/\"\n",
    "\n",
    "print(\"###################################################################\")\n",
    "print(\"path: \"+path)\n",
    "print(\"save_model_path: \"+save_model_path)\n",
    "print(\"save_result_path: \"+save_result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Read data files & Dividing into train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\test\\mucinous_training\\TCGA_mucinous_DNN_space\\codes\\lib\\dataProcess.py:133: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  ydata = data.loc[:, key].as_matrix()\n",
      "C:\\test\\mucinous_training\\TCGA_mucinous_DNN_space\\codes\\lib\\dataProcess.py:134: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  xdata = data.iloc[:, x_start:x_end].as_matrix()\n",
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv(path+limma_option+\"_TCGA_inter_nonmucinous_\"+method+\"_\"+geneset+\"_data.csv\")\n",
    "test_data=pd.read_csv(path+limma_option+\"_TCGA_inter_mucinous_\"+method+\"_\"+geneset+\"_data.csv\")\n",
    "cli_data=pd.read_csv(path+limma_option+\"_TCGA_inter_clin_\"+method+\"_\"+geneset+\"_data.csv\")\n",
    "\n",
    "#train_data=train_data.sample(frac=1)\n",
    "train_x, train_y = dp.divide_xy_test(train_data, 'result',  1, -1)\n",
    "test_x, test_y=dp.divide_xy_test(test_data, 'result',  1, -1)\n",
    "cli_x = cli_data.iloc[:, 1:].as_matrix()\n",
    "train_y1 = dp.one_hot_encoder_train(train_y)\n",
    "test_y1 = dp.one_hot_encoder_test(train_y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: (1452, 561)\n",
      "test data: (82, 561)\n",
      "clin data: (10, 561)\n"
     ]
    }
   ],
   "source": [
    "print(\"train data: \"+str(train_x.shape))\n",
    "print(\"test data: \"+str(test_x.shape))\n",
    "print(\"clin data: \"+str(cli_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ input dim is 561 ################\n"
     ]
    }
   ],
   "source": [
    "if train_x.shape[1] == test_x.shape[1] and test_x.shape[1] == cli_x.shape[1]:\n",
    "    input_dim = train_x.shape[1]\n",
    "    print(\"################ input dim is \"+str(input_dim)+\" ################\")\n",
    "else:\n",
    "    print(\"dimensions are not equal. please check your dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geneset_merged=keras.layers.Input(shape=(input_dim,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Establishing & training/testing the DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Establishing DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes_list = [[500,300,100]]\n",
    "        \n",
    "input_m = keras.layers.Input(shape=(input_dim,))\n",
    "\n",
    "h1_m3 = keras.layers.Dense(500,activation=\"relu\")(input_m)\n",
    "h1_d = keras.layers.Dropout(0.3,)(h1_m3)\n",
    "h2_m3 = keras.layers.Dense(300,activation=\"relu\")(h1_d)\n",
    "h2_d = keras.layers.Dropout(0.3,)(h2_m3)\n",
    "h3_m3 = keras.layers.Dense(100,activation=\"relu\")(h2_d)\n",
    "h3_d = keras.layers.Dropout(0.3,)(h3_m3)\n",
    "                \n",
    "early_stopping = EarlyStopping(patience = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 561)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               281000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 462,006\n",
      "Trainable params: 462,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predictions = Dense(6, activation='softmax', name='predictions')(h3_d)\n",
    "model1 = Model(inputs = input_m, output = predictions)\n",
    "adam = keras.optimizers.Adam()\n",
    "model1.compile(optimizer=adam, loss ='categorical_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Training & Testing the DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9116783, 0.9268293]\n",
      "=============================================Complete Test=================================\n"
     ]
    }
   ],
   "source": [
    "#plot_model(model, to_file='model.png')\n",
    "model1.fit(x=train_x, y=train_y1,callbacks=[early_stopping], epochs = 50,batch_size=25, verbose=0)\n",
    "print(\"train acc: \"+str(model1.evaluate(train_x,train_y1, verbose=0)[1])+\", test acc: \"+str(model1.evaluate(test_x,test_y1, verbose=0)[1]))\n",
    "print(\"=============================================Complete Train=================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c5021cf560fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_model_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlimma_option\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgeneset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_model_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlimma_option\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgeneset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_model_path' is not defined"
     ]
    }
   ],
   "source": [
    "print(save_model_path+limma_option+method+\"_\"+geneset+\"_model.h5\")\n",
    "model1.save(save_model_path+limma_option+\"_\"+method+\"_\"+geneset+\"_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Predict train & test & clinical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h=model1.predict(train_x, batch_size=None, verbose=0, steps=None)\n",
    "test_h=model1.predict(test_x, batch_size=None, verbose=0, steps=None)\n",
    "cli_h=model1.predict(cli_x, batch_size=None, verbose=0, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p=[]\n",
    "for i in range(len(train_h)):\n",
    "    train=train_h[i].tolist()\n",
    "    train_p.append(train.index(max(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p=[]\n",
    "for i in range(len(test_h)):\n",
    "    test=test_h[i].tolist()\n",
    "    test_p.append(test.index(max(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_p=[]\n",
    "for i in range(len(cli_h)):\n",
    "    cli=cli_h[i].tolist()\n",
    "    cli_p.append(cli.index(max(cli)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Making result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_h=df(train_h)\n",
    "df_train_h.columns=['CESC','COAD','PAAD','STAD','UCEC','UCS']\n",
    "\n",
    "df_train_p=df(train_p)\n",
    "df_train_p.columns=['prediction']\n",
    "\n",
    "df_train_y=df(train_y)\n",
    "df_train_y.columns=['y']\n",
    "\n",
    "pd.concat([train_data['sample'],df_train_h,df_train_p,df_train_y],axis=1).to_csv(save_result_path+limma_option+\"_nonmucinous_\"+method+\"_\"+geneset+\"_train_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_h=df(test_h)\n",
    "df_test_h.columns=['CESC','COAD','PAAD','STAD','UCEC','UCS']\n",
    "\n",
    "df_test_p=df(test_p)\n",
    "df_test_p.columns=['prediction']\n",
    "\n",
    "df_test_y=df(test_y)\n",
    "df_test_y.columns=['y']\n",
    "\n",
    "pd.concat([test_data['sample'],df_test_h,df_test_p,df_test_y],axis=1).to_csv(save_result_path+limma_option+\"_mucinous_\"+method+\"_\"+geneset+\"_test_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cli_h=df(cli_h)\n",
    "df_cli_h.columns=['CESC','COAD','PAAD','STAD','UCEC','UCS']\n",
    "\n",
    "df_cli_p=df(cli_p)\n",
    "df_cli_p.columns=['prediction']\n",
    "\n",
    "pd.concat([cli_data['sample'],df_cli_h,df_cli_p],axis=1).to_csv(save_result_path+limma_option+\"_clin_\"+method+\"_\"+geneset+\"_clin_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
