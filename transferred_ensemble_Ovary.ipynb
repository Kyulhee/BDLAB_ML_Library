{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dropout, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] file_name:  OV_Annotation3000_400_idx12 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[2] file_name:  OV_CV_400_idx12 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[3] file_name:  OV_Var_400_idx12 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[4] file_name:  OV_new_Diff_400_idx12 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[5] file_name:  OV_Clin_idx12 \n",
      "sample : 287  \n",
      "features : 35\n",
      "[6] file_name:  OV_SNV_idx12 \n",
      "sample : 213  \n",
      "features : 6970\n"
     ]
    }
   ],
   "source": [
    "path = \"C://test/TC_subsamples_idx12/\"\n",
    "types = [\"OV_Annotation3000_400_idx12\", \"OV_CV_400_idx12\", \n",
    "         \"OV_Var_400_idx12\", \"OV_new_Diff_400_idx12\",\n",
    "         \"OV_Clin_idx12\", \n",
    "         \"OV_SNV_idx12\" \n",
    "         ]\n",
    "\n",
    "file_1 = path+types[0]+\".csv\"\n",
    "file_2 = path+types[1]+\".csv\"\n",
    "file_3 = path+types[2]+\".csv\"\n",
    "file_4 = path+types[3]+\".csv\"\n",
    "file_5 = path+types[4]+\".csv\"\n",
    "file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "sample_1,features_1 = data_1.shape\n",
    "sample_2,features_2 = data_2.shape\n",
    "sample_3,features_3 = data_3.shape\n",
    "sample_4,features_4 = data_4.shape\n",
    "sample_5,features_5 = data_5.shape\n",
    "sample_6,features_6 = data_6.shape\n",
    "\n",
    "# Data frame include index & Platinum_Status column, substract 2 to calculate real number of features \n",
    "[features_1, features_2, features_3, features_4, features_5, features_6] = [features_1-2, features_2-2, features_3-2, features_4-2, features_5-2, features_6-2]\n",
    "\n",
    "print(\"[1] file_name: \", types[0], \"\\nsample : {}  \\nfeatures : {}\".format(sample_1,features_1))\n",
    "print(\"[2] file_name: \", types[1], \"\\nsample : {}  \\nfeatures : {}\".format(sample_2,features_2))\n",
    "print(\"[3] file_name: \", types[2], \"\\nsample : {}  \\nfeatures : {}\".format(sample_3,features_3))\n",
    "print(\"[4] file_name: \", types[3], \"\\nsample : {}  \\nfeatures : {}\".format(sample_4,features_4))\n",
    "print(\"[5] file_name: \", types[4], \"\\nsample : {}  \\nfeatures : {}\".format(sample_5,features_5))\n",
    "print(\"[6] file_name: \", types[5], \"\\nsample : {}  \\nfeatures : {}\".format(sample_6,features_6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  OV_Annotation3000_400_idx12  ######################################\n",
      "(186, 400) (31, 400)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[0]+'  ######################################')\n",
    "\n",
    "train_data_1 = data_1.iloc[list(data_1.iloc[:,-1]!=1)]\n",
    "test_data_1 = data_1.iloc[list(data_1.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_1 = train_data_1.Platinum_Status\n",
    "x_val_1 = train_data_1.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_1 = test_data_1.Platinum_Status\n",
    "test_x_val_1 = test_data_1.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_1.shape, test_x_val_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  OV_CV_400_idx12  ######################################\n",
      "(186, 400) (31, 400)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[1]+'  ######################################')\n",
    "\n",
    "train_data_2 = data_2.iloc[list(data_2.iloc[:,-1]!=1)]\n",
    "test_data_2 = data_2.iloc[list(data_2.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_2 = train_data_2.Platinum_Status\n",
    "x_val_2 = train_data_2.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_2 = test_data_2.Platinum_Status\n",
    "test_x_val_2 = test_data_2.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_2.shape, test_x_val_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  OV_Var_400_idx12  ######################################\n",
      "(186, 400) (31, 400)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[2]+'  ######################################')\n",
    "\n",
    "train_data_3 = data_3.iloc[list(data_3.iloc[:,-1]!=1)]\n",
    "test_data_3 = data_3.iloc[list(data_3.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_3 = train_data_3.Platinum_Status\n",
    "x_val_3 = train_data_3.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_3 = test_data_3.Platinum_Status\n",
    "test_x_val_3 = test_data_3.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_3.shape, test_x_val_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  OV_new_Diff_400_idx12  ######################################\n",
      "(186, 400) (31, 400)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[3]+'  ######################################')\n",
    "\n",
    "train_data_4 = data_4.iloc[list(data_4.iloc[:,-1]!=1)]\n",
    "test_data_4 = data_4.iloc[list(data_4.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_4 = train_data_4.Platinum_Status\n",
    "x_val_4 = train_data_4.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_4 = test_data_4.Platinum_Status\n",
    "test_x_val_4 = test_data_4.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_4.shape, test_x_val_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  OV_Clin_idx12  ######################################\n",
      "(256, 35) (31, 35)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[4]+'  ######################################')\n",
    "\n",
    "train_data_5 = data_5.iloc[list(data_5.iloc[:,-1]!=1)]\n",
    "test_data_5 = data_5.iloc[list(data_5.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_5 = train_data_5.Platinum_Status\n",
    "x_val_5 = train_data_5.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_5 = test_data_5.Platinum_Status\n",
    "test_x_val_5 = test_data_5.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_5.shape, test_x_val_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################  OV_SNV_idx12  ######################################\n",
      "(182, 6970) (31, 6970)\n"
     ]
    }
   ],
   "source": [
    "print('######################################  '+types[5]+'  ######################################')\n",
    "\n",
    "train_data_6 = data_6.iloc[list(data_6.iloc[:,-1]!=1)]\n",
    "test_data_6 = data_6.iloc[list(data_6.iloc[:,-1]==1)]\n",
    "\n",
    "y_val_6 = train_data_6.Platinum_Status\n",
    "x_val_6 = train_data_6.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "test_y_val_6 = test_data_6.Platinum_Status\n",
    "test_x_val_6 = test_data_6.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "print(x_val_6.shape, test_x_val_6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Seperate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building seperate model for ensemble(model 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_1, features_2, features_3, features_4, features_5, features_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('######################################  '+types[0]+'  ######################################')\n",
    "\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "input_drop_out_1 = 0.1\n",
    "drop_out_1 = 0.3\n",
    "layers = [100, 50, 40, 10]\n",
    "m_1_tr_loss_best = 100 # for saving best loss value \n",
    "best_model_1=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "input_m_1 = Input(shape=(features_1,))\n",
    "m_1_dp = Dropout(input_drop_out_1)(input_m_1)\n",
    "for i in layers:\n",
    "    m_1 = Dense(i,activation='relu')(m_1_dp)\n",
    "    m_1_dp = Dropout(drop_out_1)(m_1)\n",
    "m_1_final = m_1_dp\n",
    "output_m_1 = Dense(1, activation=\"sigmoid\")(m_1_final)\n",
    "model_1 = Model(inputs=input_m_1,outputs=output_m_1)\n",
    "model_1.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    model_1.fit(x_val_1, y_val_1, batch_size=5, nb_epoch=1)\n",
    "    m_1_tr_loss=model_1.evaluate(x_val_1,y_val_1)[0]\n",
    "    if m_1_tr_loss < m_1_tr_loss_best: # new best model. count reset.\n",
    "        m_1_tr_loss_best = m_1_tr_loss\n",
    "        count=0\n",
    "        best_model_1 = model_1\n",
    "    if count>3: # no increase three time. stop.\n",
    "        model_1 = best_model_1\n",
    "        break\n",
    "    else: count=count+1\n",
    "\n",
    "m_1_tr_loss,m_1_tr_accuracy=model_1.evaluate(x_val_1,y_val_1)\n",
    "m_1_loss,m_1_accuracy= model_1.evaluate(test_x_val_1,test_y_val_1)\n",
    "    \n",
    "    \n",
    "# 4) m_1 train & test prediction table + sensitivity / specificity\n",
    "m_1_tr_predictions = model_1.predict(x_val_1)\n",
    "labeled_m_1_tr_predictions = np.where(m_1_tr_predictions > 0.5, 1, 0).flatten()\n",
    "m_1_tr_sensitivity, m_1_tr_specificity = check_correct(labeled_m_1_tr_predictions, y_val_1)\n",
    "m_1_tr_predictions_flat = m_1_tr_predictions[:,0]\n",
    "\n",
    "m_1_test_predictions = model_1.predict(test_x_val_1)\n",
    "labeled_m_1_test_predictions = np.where(m_1_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_1_sensitivity, m_1_specificity = check_correct(labeled_m_1_test_predictions, test_y_val_1)\n",
    "m_1_test_predictions_flat = m_1_test_predictions[:,0]\n",
    "\n",
    "\n",
    "# 5) m_1 auc\n",
    "tr_df_1 = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(m_1_tr_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_1_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_1.to_csv(\"../result/prediction_result_m_1_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "ts_df_1 = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(m_1_test_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_1_test_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_1.to_csv(\"../result/prediction_result_m_1_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_1, test_y_val_1)\n",
    "y_pred = np.append(labeled_m_1_tr_predictions, labeled_m_1_test_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_1, labeled_m_1_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_1, labeled_m_1_test_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_1_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_1_tr_sensitivity)+\", \"+str(m_1_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_1_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_1_sensitivity)+\", \"+str(m_1_specificity))\n",
    "\n",
    "# 6) save model\n",
    "model_1.save(\"../models/Ovary/m_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('######################################  '+types[1]+'  ######################################')\n",
    "\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "input_drop_out_2 = 0.1\n",
    "drop_out_2 = 0.3\n",
    "layers = [100, 50, 40, 10]\n",
    "m_2_tr_loss_best = 100 # for saving best loss value \n",
    "best_model_2=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "input_m_2 = Input(shape=(features_2,))\n",
    "m_2_dp = Dropout(input_drop_out_2)(input_m_2)\n",
    "for i in layers:\n",
    "    m_2 = Dense(i,activation='relu')(m_2_dp)\n",
    "    m_2_dp = Dropout(drop_out_2)(m_2)\n",
    "m_2_final = m_2_dp\n",
    "output_m_2 = Dense(1, activation=\"sigmoid\")(m_2_final)\n",
    "model_2 = Model(inputs=input_m_2,outputs=output_m_2)\n",
    "model_2.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    model_2.fit(x_val_2, y_val_2, batch_size=5, nb_epoch=1)\n",
    "    m_2_tr_loss=model_2.evaluate(x_val_2,y_val_2)[0]\n",
    "    if m_2_tr_loss < m_2_tr_loss_best: # new best model. count reset.\n",
    "        m_2_tr_loss_best = m_2_tr_loss\n",
    "        count=0\n",
    "        best_model_2 = model_2\n",
    "    if count>3: # no increase three time. stop.\n",
    "        model_2 = best_model_2\n",
    "        break\n",
    "    else: count=count+1\n",
    "\n",
    "m_2_tr_loss,m_2_tr_accuracy=model_2.evaluate(x_val_2,y_val_2)\n",
    "m_2_loss,m_2_accuracy= model_2.evaluate(test_x_val_2,test_y_val_2)\n",
    "    \n",
    "    \n",
    "# 4) m_2 train & test prediction table + sensitivity / specificity\n",
    "m_2_tr_predictions = model_2.predict(x_val_2)\n",
    "labeled_m_2_tr_predictions = np.where(m_2_tr_predictions > 0.5, 1, 0).flatten()\n",
    "m_2_tr_sensitivity, m_2_tr_specificity = check_correct(labeled_m_2_tr_predictions, y_val_2)\n",
    "m_2_tr_predictions_flat = m_2_tr_predictions[:,0]\n",
    "\n",
    "m_2_test_predictions = model_2.predict(test_x_val_2)\n",
    "labeled_m_2_test_predictions = np.where(m_2_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_2_sensitivity, m_2_specificity = check_correct(labeled_m_2_test_predictions, test_y_val_2)\n",
    "m_2_test_predictions_flat = m_2_test_predictions[:,0]\n",
    "\n",
    "\n",
    "# 5) m_2 auc\n",
    "tr_df_2 = pd.DataFrame(data={\"patient\":list(train_data_2.index), \"hypothesis 1\": list(m_2_tr_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_2_tr_predictions), \"Platinum_Status\":list(y_val_2)})\n",
    "tr_df_2.to_csv(\"../result/prediction_result_m_2_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "ts_df_2 = pd.DataFrame(data={\"patient\":list(test_data_2.index), \"hypothesis 1\": list(m_2_test_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_2_test_predictions), \"Platinum_Status\":list(test_y_val_2)})\n",
    "ts_df_2.to_csv(\"../result/prediction_result_m_2_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_2, test_y_val_2)\n",
    "y_pred = np.append(labeled_m_2_tr_predictions, labeled_m_2_test_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_2, labeled_m_2_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_2, labeled_m_2_test_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_2_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_2_tr_sensitivity)+\", \"+str(m_2_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_2_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_2_sensitivity)+\", \"+str(m_2_specificity))\n",
    "\n",
    "# 6) save model\n",
    "model_2.save(\"../models/Ovary/m_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('######################################  '+types[2]+'  ######################################')\n",
    "\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "input_drop_out_3 = 0.1\n",
    "drop_out_3 = 0.3\n",
    "layers = [100, 50, 40, 10]\n",
    "m_3_tr_loss_best = 100 # for saving best loss value \n",
    "best_model_3=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "input_m_3 = Input(shape=(features_3,))\n",
    "m_3_dp = Dropout(input_drop_out_3)(input_m_3)\n",
    "for i in layers:\n",
    "    m_3 = Dense(i,activation='relu')(m_3_dp)\n",
    "    m_3_dp = Dropout(drop_out_3)(m_3)\n",
    "m_3_final = m_3_dp\n",
    "output_m_3 = Dense(1, activation=\"sigmoid\")(m_3_final)\n",
    "model_3 = Model(inputs=input_m_3,outputs=output_m_3)\n",
    "model_3.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    model_3.fit(x_val_3, y_val_3, batch_size=5, nb_epoch=1)\n",
    "    m_3_tr_loss=model_3.evaluate(x_val_3,y_val_3)[0]\n",
    "    if m_3_tr_loss < m_3_tr_loss_best: # new best model. count reset.\n",
    "        m_3_tr_loss_best = m_3_tr_loss\n",
    "        count=0\n",
    "        best_model_3 = model_3\n",
    "    if count>3: # no increase three time. stop.\n",
    "        model_3 = best_model_3\n",
    "        break\n",
    "    else: count=count+1\n",
    "\n",
    "m_3_tr_loss,m_3_tr_accuracy=model_3.evaluate(x_val_3,y_val_3)\n",
    "m_3_loss,m_3_accuracy= model_3.evaluate(test_x_val_3,test_y_val_3)\n",
    "    \n",
    "    \n",
    "# 4) m_3 train & test prediction table + sensitivity / specificity\n",
    "m_3_tr_predictions = model_3.predict(x_val_3)\n",
    "labeled_m_3_tr_predictions = np.where(m_3_tr_predictions > 0.5, 1, 0).flatten()\n",
    "m_3_tr_sensitivity, m_3_tr_specificity = check_correct(labeled_m_3_tr_predictions, y_val_3)\n",
    "m_3_tr_predictions_flat = m_3_tr_predictions[:,0]\n",
    "\n",
    "m_3_test_predictions = model_3.predict(test_x_val_3)\n",
    "labeled_m_3_test_predictions = np.where(m_3_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_3_sensitivity, m_3_specificity = check_correct(labeled_m_3_test_predictions, test_y_val_3)\n",
    "m_3_test_predictions_flat = m_3_test_predictions[:,0]\n",
    "\n",
    "\n",
    "# 5) m_3 auc\n",
    "tr_df_3 = pd.DataFrame(data={\"patient\":list(train_data_3.index), \"hypothesis 1\": list(m_3_tr_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_3_tr_predictions), \"Platinum_Status\":list(y_val_3)})\n",
    "tr_df_3.to_csv(\"../result/prediction_result_m_3_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "ts_df_3 = pd.DataFrame(data={\"patient\":list(test_data_3.index), \"hypothesis 1\": list(m_3_test_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_3_test_predictions), \"Platinum_Status\":list(test_y_val_3)})\n",
    "ts_df_3.to_csv(\"../result/prediction_result_m_3_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_3, test_y_val_3)\n",
    "y_pred = np.append(labeled_m_3_tr_predictions, labeled_m_3_test_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_3, labeled_m_3_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_3, labeled_m_3_test_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_3_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_3_tr_sensitivity)+\", \"+str(m_3_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_3_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_3_sensitivity)+\", \"+str(m_3_specificity))\n",
    "\n",
    "# 6) save model\n",
    "model_3.save(\"../models/Ovary/m_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('######################################  '+types[3]+'  ######################################')\n",
    "\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "input_drop_out_4 = 0.1\n",
    "drop_out_4 = 0.3\n",
    "layers = [100, 50, 40, 10]\n",
    "m_4_tr_loss_best = 100 # for saving best loss value \n",
    "best_model_4=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "input_m_4 = Input(shape=(features_4,))\n",
    "m_4_dp = Dropout(input_drop_out_4)(input_m_4)\n",
    "for i in layers:\n",
    "    m_4 = Dense(i,activation='relu')(m_4_dp)\n",
    "    m_4_dp = Dropout(drop_out_4)(m_4)\n",
    "m_4_final = m_4_dp\n",
    "output_m_4 = Dense(1, activation=\"sigmoid\")(m_4_final)\n",
    "model_4 = Model(inputs=input_m_4,outputs=output_m_4)\n",
    "model_4.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    model_4.fit(x_val_4, y_val_4, batch_size=5, nb_epoch=1)\n",
    "    m_4_tr_loss=model_4.evaluate(x_val_4,y_val_4)[0]\n",
    "    if m_4_tr_loss < m_4_tr_loss_best: # new best model. count reset.\n",
    "        m_4_tr_loss_best = m_4_tr_loss\n",
    "        count=0\n",
    "        best_model_4 = model_4\n",
    "    if count>3: # no increase three time. stop.\n",
    "        model_4 = best_model_4\n",
    "        break\n",
    "    else: count=count+1\n",
    "\n",
    "m_4_tr_loss,m_4_tr_accuracy=model_4.evaluate(x_val_4,y_val_4)\n",
    "m_4_loss,m_4_accuracy= model_4.evaluate(test_x_val_4,test_y_val_4)\n",
    "    \n",
    "    \n",
    "# 4) m_4 train & test prediction table + sensitivity / specificity\n",
    "m_4_tr_predictions = model_4.predict(x_val_4)\n",
    "labeled_m_4_tr_predictions = np.where(m_4_tr_predictions > 0.5, 1, 0).flatten()\n",
    "m_4_tr_sensitivity, m_4_tr_specificity = check_correct(labeled_m_4_tr_predictions, y_val_4)\n",
    "m_4_tr_predictions_flat = m_4_tr_predictions[:,0]\n",
    "\n",
    "m_4_test_predictions = model_4.predict(test_x_val_4)\n",
    "labeled_m_4_test_predictions = np.where(m_4_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_4_sensitivity, m_4_specificity = check_correct(labeled_m_4_test_predictions, test_y_val_4)\n",
    "m_4_test_predictions_flat = m_4_test_predictions[:,0]\n",
    "\n",
    "\n",
    "# 5) m_4 auc\n",
    "tr_df_4 = pd.DataFrame(data={\"patient\":list(train_data_4.index), \"hypothesis 1\": list(m_4_tr_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_4_tr_predictions), \"Platinum_Status\":list(y_val_4)})\n",
    "tr_df_4.to_csv(\"../result/prediction_result_m_4_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "ts_df_4 = pd.DataFrame(data={\"patient\":list(test_data_4.index), \"hypothesis 1\": list(m_4_test_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_4_test_predictions), \"Platinum_Status\":list(test_y_val_4)})\n",
    "ts_df_4.to_csv(\"../result/prediction_result_m_4_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_4, test_y_val_4)\n",
    "y_pred = np.append(labeled_m_4_tr_predictions, labeled_m_4_test_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_4, labeled_m_4_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_4, labeled_m_4_test_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_4_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_4_tr_sensitivity)+\", \"+str(m_4_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_4_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_4_sensitivity)+\", \"+str(m_4_specificity))\n",
    "\n",
    "# 6) save model\n",
    "model_4.save(\"../models/Ovary/m_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('######################################  '+types[4]+'  ######################################')\n",
    "\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "input_drop_out_5 = 0.1\n",
    "drop_out_5 = 0.3\n",
    "layers = [100, 50, 40, 10]\n",
    "m_5_tr_loss_best = 100 # for saving best loss value \n",
    "best_model_5=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "input_m_5 = Input(shape=(features_5,))\n",
    "m_5_dp = Dropout(input_drop_out_5)(input_m_5)\n",
    "for i in layers:\n",
    "    m_5 = Dense(i,activation='relu')(m_5_dp)\n",
    "    m_5_dp = Dropout(drop_out_5)(m_5)\n",
    "m_5_final = m_5_dp\n",
    "output_m_5 = Dense(1, activation=\"sigmoid\")(m_5_final)\n",
    "model_5 = Model(inputs=input_m_5,outputs=output_m_5)\n",
    "model_5.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    model_5.fit(x_val_5, y_val_5, batch_size=5, nb_epoch=1)\n",
    "    m_5_tr_loss=model_5.evaluate(x_val_5,y_val_5)[0]\n",
    "    if m_5_tr_loss < m_5_tr_loss_best: # new best model. count reset.\n",
    "        m_5_tr_loss_best = m_5_tr_loss\n",
    "        count=0\n",
    "        best_model_5 = model_5\n",
    "    if count>3: # no increase three time. stop.\n",
    "        model_5 = best_model_5\n",
    "        break\n",
    "    else: count=count+1\n",
    "\n",
    "m_5_tr_loss,m_5_tr_accuracy=model_5.evaluate(x_val_5,y_val_5)\n",
    "m_5_loss,m_5_accuracy= model_5.evaluate(test_x_val_5,test_y_val_5)\n",
    "    \n",
    "    \n",
    "# 4) m_5 train & test prediction table + sensitivity / specificity\n",
    "m_5_tr_predictions = model_5.predict(x_val_5)\n",
    "labeled_m_5_tr_predictions = np.where(m_5_tr_predictions > 0.5, 1, 0).flatten()\n",
    "m_5_tr_sensitivity, m_5_tr_specificity = check_correct(labeled_m_5_tr_predictions, y_val_5)\n",
    "m_5_tr_predictions_flat = m_5_tr_predictions[:,0]\n",
    "\n",
    "m_5_test_predictions = model_5.predict(test_x_val_5)\n",
    "labeled_m_5_test_predictions = np.where(m_5_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_5_sensitivity, m_5_specificity = check_correct(labeled_m_5_test_predictions, test_y_val_5)\n",
    "m_5_test_predictions_flat = m_5_test_predictions[:,0]\n",
    "\n",
    "\n",
    "# 5) m_5 auc\n",
    "tr_df_5 = pd.DataFrame(data={\"patient\":list(train_data_5.index), \"hypothesis 1\": list(m_5_tr_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_5_tr_predictions), \"Platinum_Status\":list(y_val_5)})\n",
    "tr_df_5.to_csv(\"../result/prediction_result_m_5_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "ts_df_5 = pd.DataFrame(data={\"patient\":list(test_data_5.index), \"hypothesis 1\": list(m_5_test_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_5_test_predictions), \"Platinum_Status\":list(test_y_val_5)})\n",
    "ts_df_5.to_csv(\"../result/prediction_result_m_5_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_5, test_y_val_5)\n",
    "y_pred = np.append(labeled_m_5_tr_predictions, labeled_m_5_test_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_5, labeled_m_5_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_5, labeled_m_5_test_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_5_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_5_tr_sensitivity)+\", \"+str(m_5_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_5_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_5_sensitivity)+\", \"+str(m_5_specificity))\n",
    "\n",
    "# 6) save model\n",
    "model_5.save(\"../models/Ovary/m_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('######################################  '+types[5]+'  ######################################')\n",
    "\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "input_drop_out_6 = 0.1\n",
    "drop_out_6 = 0.3\n",
    "layers = [100, 50, 40, 10]\n",
    "m_6_tr_loss_best = 100 # for saving best loss value \n",
    "best_model_6=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "input_m_6 = Input(shape=(features_6,))\n",
    "m_6_dp = Dropout(input_drop_out_6)(input_m_6)\n",
    "for i in layers:\n",
    "    m_6 = Dense(i,activation='relu')(m_6_dp)\n",
    "    m_6_dp = Dropout(drop_out_6)(m_6)\n",
    "m_6_final = m_6_dp\n",
    "output_m_6 = Dense(1, activation=\"sigmoid\")(m_6_final)\n",
    "model_6 = Model(inputs=input_m_6,outputs=output_m_6)\n",
    "model_6.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    model_6.fit(x_val_6, y_val_6, batch_size=5, nb_epoch=1)\n",
    "    m_6_tr_loss=model_6.evaluate(x_val_6,y_val_6)[0]\n",
    "    if m_6_tr_loss < m_6_tr_loss_best: # new best model. count reset.\n",
    "        m_6_tr_loss_best = m_6_tr_loss\n",
    "        count=0\n",
    "        best_model_6 = model_6\n",
    "    if count>3: # no increase three time. stop.\n",
    "        model_6 = best_model_6\n",
    "        break\n",
    "    else: count=count+1\n",
    "\n",
    "m_6_tr_loss,m_6_tr_accuracy=model_6.evaluate(x_val_6,y_val_6)\n",
    "m_6_loss,m_6_accuracy= model_6.evaluate(test_x_val_6,test_y_val_6)\n",
    "    \n",
    "    \n",
    "# 4) m_6 train & test prediction table + sensitivity / specificity\n",
    "m_6_tr_predictions = model_6.predict(x_val_6)\n",
    "labeled_m_6_tr_predictions = np.where(m_6_tr_predictions > 0.5, 1, 0).flatten()\n",
    "m_6_tr_sensitivity, m_6_tr_specificity = check_correct(labeled_m_6_tr_predictions, y_val_6)\n",
    "m_6_tr_predictions_flat = m_6_tr_predictions[:,0]\n",
    "\n",
    "m_6_test_predictions = model_6.predict(test_x_val_6)\n",
    "labeled_m_6_test_predictions = np.where(m_6_test_predictions > 0.5, 1, 0).flatten()\n",
    "m_6_sensitivity, m_6_specificity = check_correct(labeled_m_6_test_predictions, test_y_val_6)\n",
    "m_6_test_predictions_flat = m_6_test_predictions[:,0]\n",
    "\n",
    "\n",
    "# 5) m_6 auc\n",
    "tr_df_6 = pd.DataFrame(data={\"patient\":list(train_data_6.index), \"hypothesis 1\": list(m_6_tr_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_6_tr_predictions), \"Platinum_Status\":list(y_val_6)})\n",
    "tr_df_6.to_csv(\"../result/prediction_result_m_6_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "ts_df_6 = pd.DataFrame(data={\"patient\":list(test_data_6.index), \"hypothesis 1\": list(m_6_test_predictions_flat), \n",
    "                        \"prediction\":list(labeled_m_6_test_predictions), \"Platinum_Status\":list(test_y_val_6)})\n",
    "ts_df_6.to_csv(\"../result/prediction_result_m_6_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_6, test_y_val_6)\n",
    "y_pred = np.append(labeled_m_6_tr_predictions, labeled_m_6_test_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_6, labeled_m_6_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_6, labeled_m_6_test_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_6_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_6_tr_sensitivity)+\", \"+str(m_6_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_6_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_6_sensitivity)+\", \"+str(m_6_specificity))\n",
    "\n",
    "# 6) save model\n",
    "model_6.save(\"../models/Ovary/m_6.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating seperate model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"< \"+types[0]+\" > tr: \"+str(m_1_tr_accuracy)+\", ts: \"+str(m_1_accuracy))\n",
    "print(\"< \"+types[1]+\" > tr: \"+str(m_2_tr_accuracy)+\", ts: \"+str(m_2_accuracy))\n",
    "print(\"< \"+types[2]+\" > tr: \"+str(m_3_tr_accuracy)+\", ts: \"+str(m_3_accuracy))\n",
    "print(\"< \"+types[3]+\" > tr: \"+str(m_4_tr_accuracy)+\", ts: \"+str(m_4_accuracy))\n",
    "print(\"< \"+types[4]+\" > tr: \"+str(m_5_tr_accuracy)+\", ts: \"+str(m_5_accuracy))\n",
    "print(\"< \"+types[5]+\" > tr: \"+str(m_6_tr_accuracy)+\", ts: \"+str(m_6_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select models & using saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "select = [1, 2, 3, 4, 5, 6]\n",
    "print(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1_name = \"Annot_3000_400_0.h5\"\n",
    "m_2_name = \"CV_400_0.h5\"\n",
    "m_3_name = \"Var_400_0.h5\"\n",
    "m_4_name = \"new_Diff_400_0.h5\"\n",
    "m_5_name = \"Clin_2.h5\"\n",
    "m_6_name = \"SNV_1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using saved model?: y\n",
      "######################################### Using saving models #########################################\n",
      "[1] file_name:  inter_by_names_Annotation3000_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[2] file_name:  inter_by_names_CV_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[3] file_name:  inter_by_names_Var_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[4] file_name:  inter_by_names_new_Diff_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[5] file_name:  inter_OV_Clin \n",
      "sample : 153  \n",
      "features : 35\n",
      "[6] file_name:  inter_OV_SNV \n",
      "sample : 153  \n",
      "features : 6970\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 193us/step\n",
      "inter_by_names_Annotation3000_400\n",
      "Train Accuracy: 0.9262295091738466\n",
      "Test Accuracy: 0.774193525314331\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 225us/step\n",
      "inter_by_names_CV_400\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.6451612710952759\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 160us/step\n",
      "inter_by_names_Var_400\n",
      "Train Accuracy: 0.9426229449569202\n",
      "Test Accuracy: 0.7096773982048035\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 129us/step\n",
      "inter_by_names_new_Diff_400\n",
      "Train Accuracy: 0.9508196662683956\n",
      "Test Accuracy: 0.8387096524238586\n",
      "122/122 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 289us/step\n",
      "inter_OV_Clin\n",
      "Train Accuracy: 0.7704918062100645\n",
      "Test Accuracy: 0.7419354915618896\n",
      "122/122 [==============================] - 1s 4ms/step\n",
      "31/31 [==============================] - 0s 161us/step\n",
      "inter_OV_SNV\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.774193525314331\n"
     ]
    }
   ],
   "source": [
    "ch = input(\"using saved model?: \")\n",
    "\n",
    "# typing 'y' for using saved model, 'n' for using recently trained model.\n",
    "if ch=='y':\n",
    "    print(\"######################################### Using saving models #########################################\")\n",
    "    model_path = \"G:/내 드라이브/Class/6과 7 사이(hell)/Lab/TCGA 난소암/Best_Models/18.09.15/\"\n",
    "\n",
    "    path = \"C:/test/TC_intersect_subsamples_by_names/\"\n",
    "    \n",
    "    # change 'types' and 'load_model' part for using another models.\n",
    "    types = [\"inter_by_names_Annotation3000_400\", \"inter_by_names_CV_400\", \n",
    "             \"inter_by_names_Var_400\", \"inter_by_names_new_Diff_400\",\n",
    "             \"inter_OV_Clin\", \n",
    "             \"inter_OV_SNV\" \n",
    "             ]\n",
    "\n",
    "    file_1 = path+types[0]+\".csv\"\n",
    "    file_2 = path+types[1]+\".csv\"\n",
    "    file_3 = path+types[2]+\".csv\"\n",
    "    file_4 = path+types[3]+\".csv\"\n",
    "    file_5 = path+types[4]+\".csv\"\n",
    "    file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "    idx_col = 0\n",
    "\n",
    "    data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "    data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "    data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "    data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "    data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "    data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "    sample_1,features_1 = data_1.shape\n",
    "    sample_2,features_2 = data_2.shape\n",
    "    sample_3,features_3 = data_3.shape\n",
    "    sample_4,features_4 = data_4.shape\n",
    "    sample_5,features_5 = data_5.shape\n",
    "    sample_6,features_6 = data_6.shape\n",
    "\n",
    "    # Data frame include index & Platinum_Status column, substract 2 to calculate real number of features \n",
    "    [features_1, features_2, features_3, features_4, features_5, features_6] = [features_1-2, features_2-2, features_3-2, features_4-2, features_5-2, features_6-2]\n",
    "    \n",
    "\n",
    "    print(\"[1] file_name: \", types[0], \"\\nsample : {}  \\nfeatures : {}\".format(sample_1,features_1))\n",
    "    print(\"[2] file_name: \", types[1], \"\\nsample : {}  \\nfeatures : {}\".format(sample_2,features_2))\n",
    "    print(\"[3] file_name: \", types[2], \"\\nsample : {}  \\nfeatures : {}\".format(sample_3,features_3))\n",
    "    print(\"[4] file_name: \", types[3], \"\\nsample : {}  \\nfeatures : {}\".format(sample_4,features_4))\n",
    "    print(\"[5] file_name: \", types[4], \"\\nsample : {}  \\nfeatures : {}\".format(sample_5,features_5))\n",
    "    print(\"[6] file_name: \", types[5], \"\\nsample : {}  \\nfeatures : {}\".format(sample_6,features_6))\n",
    "    \n",
    "    train_data_1 = data_1.iloc[list(data_1.iloc[:,-1]!=1)]\n",
    "    test_data_1 = data_1.iloc[list(data_1.iloc[:,-1]==1)]\n",
    "\n",
    "    y_val_1 = train_data_1.Platinum_Status\n",
    "    x_val_1 = train_data_1.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val_1 = test_data_1.Platinum_Status\n",
    "    test_x_val_1 = test_data_1.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    train_data_2 = data_2.iloc[list(data_2.iloc[:,-1]!=1)]\n",
    "    test_data_2 = data_2.iloc[list(data_2.iloc[:,-1]==1)]\n",
    "\n",
    "    y_val_2 = train_data_2.Platinum_Status\n",
    "    x_val_2 = train_data_2.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val_2 = test_data_2.Platinum_Status\n",
    "    test_x_val_2 = test_data_2.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    train_data_3 = data_3.iloc[list(data_3.iloc[:,-1]!=1)]\n",
    "    test_data_3 = data_3.iloc[list(data_3.iloc[:,-1]==1)]\n",
    "\n",
    "    y_val_3 = train_data_3.Platinum_Status\n",
    "    x_val_3 = train_data_3.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val_3 = test_data_3.Platinum_Status\n",
    "    test_x_val_3 = test_data_3.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "\n",
    "    train_data_4 = data_4.iloc[list(data_4.iloc[:,-1]!=1)]\n",
    "    test_data_4 = data_4.iloc[list(data_4.iloc[:,-1]==1)]\n",
    "\n",
    "    y_val_4 = train_data_4.Platinum_Status\n",
    "    x_val_4 = train_data_4.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val_4 = test_data_4.Platinum_Status\n",
    "    test_x_val_4 = test_data_4.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    train_data_5 = data_5.iloc[list(data_5.iloc[:,-1]!=1)]\n",
    "    test_data_5 = data_5.iloc[list(data_5.iloc[:,-1]==1)]\n",
    "\n",
    "    y_val_5 = train_data_5.Platinum_Status\n",
    "    x_val_5 = train_data_5.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val_5 = test_data_5.Platinum_Status\n",
    "    test_x_val_5 = test_data_5.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    train_data_6 = data_6.iloc[list(data_6.iloc[:,-1]!=1)]\n",
    "    test_data_6 = data_6.iloc[list(data_6.iloc[:,-1]==1)]\n",
    "\n",
    "    y_val_6 = train_data_6.Platinum_Status\n",
    "    x_val_6 = train_data_6.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val_6 = test_data_6.Platinum_Status\n",
    "    test_x_val_6 = test_data_6.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    model_1_l = load_model(model_path+m_1_name)\n",
    "    m_1_l_tr_loss,m_1_l_tr_accuracy=model_1_l.evaluate(x_val_1,y_val_1)\n",
    "    m_1_l_loss,m_1_l_accuracy= model_1_l.evaluate(test_x_val_1,test_y_val_1)\n",
    "    model_1_l_new = Model(inputs = model_1_l.input, outputs=model_1_l.get_layer(model_1_l.layers[-2].name).output)\n",
    "    \n",
    "    print(types[0])\n",
    "    print(\"Train Accuracy: {}\".format(m_1_l_tr_accuracy))\n",
    "    print(\"Test Accuracy: {}\".format(m_1_l_accuracy))\n",
    "\n",
    "    model_2_l = load_model(model_path+m_2_name)\n",
    "    m_2_l_tr_loss,m_2_l_tr_accuracy=model_2_l.evaluate(x_val_2,y_val_2)\n",
    "    m_2_l_loss,m_2_l_accuracy= model_2_l.evaluate(test_x_val_2,test_y_val_2)\n",
    "    model_2_l_new = Model(inputs = model_2_l.input, outputs=model_2_l.get_layer(model_2_l.layers[-2].name).output)\n",
    "    \n",
    "    print(types[1])\n",
    "    print(\"Train Accuracy: {}\".format(m_2_l_tr_accuracy))\n",
    "    print(\"Test Accuracy: {}\".format(m_2_l_accuracy))\n",
    "\n",
    "    model_3_l = load_model(model_path+m_3_name)\n",
    "    m_3_l_tr_loss,m_3_l_tr_accuracy=model_3_l.evaluate(x_val_3,y_val_3)\n",
    "    m_3_l_loss,m_3_l_accuracy= model_3_l.evaluate(test_x_val_3,test_y_val_3)\n",
    "    model_3_l_new = Model(inputs = model_3_l.input, outputs=model_3_l.get_layer(model_3_l.layers[-2].name).output)\n",
    "    \n",
    "    print(types[2])\n",
    "    print(\"Train Accuracy: {}\".format(m_3_l_tr_accuracy))\n",
    "    print(\"Test Accuracy: {}\".format(m_3_l_accuracy))\n",
    "\n",
    "    model_4_l = load_model(model_path+m_4_name)\n",
    "    m_4_l_tr_loss,m_4_l_tr_accuracy=model_4_l.evaluate(x_val_4,y_val_4)\n",
    "    m_4_l_loss,m_4_l_accuracy= model_4_l.evaluate(test_x_val_4,test_y_val_4)\n",
    "    model_4_l_new = Model(inputs = model_4_l.input, outputs=model_4_l.get_layer(model_4_l.layers[-2].name).output)\n",
    "    \n",
    "    print(types[3])\n",
    "    print(\"Train Accuracy: {}\".format(m_4_l_tr_accuracy))\n",
    "    print(\"Test Accuracy: {}\".format(m_4_l_accuracy))\n",
    "\n",
    "    model_5_l = load_model(model_path+m_5_name)\n",
    "    m_5_l_tr_loss,m_5_l_tr_accuracy=model_5_l.evaluate(x_val_5,y_val_5)\n",
    "    m_5_l_loss,m_5_l_accuracy= model_5_l.evaluate(test_x_val_5,test_y_val_5)\n",
    "    model_5_l_new = Model(inputs = model_5_l.input, outputs=model_5_l.get_layer(model_5_l.layers[-2].name).output)\n",
    "    \n",
    "    print(types[4])\n",
    "    print(\"Train Accuracy: {}\".format(m_5_l_tr_accuracy))\n",
    "    print(\"Test Accuracy: {}\".format(m_5_l_accuracy))\n",
    "\n",
    "    model_6_l = load_model(model_path+m_6_name)\n",
    "    m_6_l_tr_loss,m_6_l_tr_accuracy=model_6_l.evaluate(x_val_6,y_val_6)\n",
    "    m_6_l_loss,m_6_l_accuracy= model_6_l.evaluate(test_x_val_6,test_y_val_6)\n",
    "    model_6_l_new = Model(inputs = model_6_l.input, outputs=model_6_l.get_layer(model_6_l.layers[-2].name).output)\n",
    "    \n",
    "    print(types[5])\n",
    "    print(\"Train Accuracy: {}\".format(m_6_l_tr_accuracy))\n",
    "    print(\"Test Accuracy: {}\".format(m_6_l_accuracy))\n",
    "    \n",
    "    m_1_predictions = model_1_l.predict(x_val_1)\n",
    "    m_2_predictions = model_2_l.predict(x_val_2)\n",
    "    m_3_predictions = model_3_l.predict(x_val_3)\n",
    "    m_4_predictions = model_4_l.predict(x_val_4)\n",
    "    m_5_predictions = model_5_l.predict(x_val_5)\n",
    "    m_6_predictions = model_6_l.predict(x_val_6)\n",
    "    \n",
    "    m_1_test_predictions = model_1_l.predict(test_x_val_1)\n",
    "    m_2_test_predictions = model_2_l.predict(test_x_val_2)\n",
    "    m_3_test_predictions = model_3_l.predict(test_x_val_3)\n",
    "    m_4_test_predictions = model_4_l.predict(test_x_val_4)\n",
    "    m_5_test_predictions = model_5_l.predict(test_x_val_5)\n",
    "    m_6_test_predictions = model_6_l.predict(test_x_val_6)\n",
    "    \n",
    "    \n",
    "elif ch=='n': \n",
    "    print(\"######################################### Using recently trained models #########################################\")\n",
    "    \n",
    "    m_1_predictions = model_1.predict(x_val_1)\n",
    "    m_2_predictions = model_2.predict(x_val_2)\n",
    "    m_3_predictions = model_3.predict(x_val_3)\n",
    "    m_4_predictions = model_4.predict(x_val_4)\n",
    "    m_5_predictions = model_5.predict(x_val_5)\n",
    "    m_6_predictions = model_6.predict(x_val_6)\n",
    "    \n",
    "    m_1_test_predictions = model_1.predict(test_x_val_1)\n",
    "    m_2_test_predictions = model_2.predict(test_x_val_2)\n",
    "    m_3_test_predictions = model_3.predict(test_x_val_3)\n",
    "    m_4_test_predictions = model_4.predict(test_x_val_4)\n",
    "    m_5_test_predictions = model_5.predict(test_x_val_5)\n",
    "    m_6_test_predictions = model_6.predict(test_x_val_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building original ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################## DNN em ##################################\n",
      "select: [1, 2, 3, 4, 5, 6]\n",
      "inter_by_names_Annotation3000_400\n",
      "inter_by_names_CV_400\n",
      "inter_by_names_Var_400\n",
      "inter_by_names_new_Diff_400\n",
      "inter_OV_Clin\n",
      "inter_OV_SNV\n",
      "#############################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.8280 - acc: 0.6639\n",
      "122/122 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 352us/step - loss: 0.7473 - acc: 0.6393\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 343us/step - loss: 0.8300 - acc: 0.5984\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 352us/step - loss: 0.7856 - acc: 0.6475\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 343us/step - loss: 0.7806 - acc: 0.6803\n",
      "122/122 [==============================] - 0s 221us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 335us/step - loss: 0.7955 - acc: 0.7131\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.7567 - acc: 0.600 - 0s 360us/step - loss: 0.7663 - acc: 0.6557\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 343us/step - loss: 0.7300 - acc: 0.7049\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 335us/step - loss: 0.7052 - acc: 0.7623\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.6803 - acc: 0.7459\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 343us/step - loss: 0.7013 - acc: 0.7131\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 425us/step - loss: 0.6887 - acc: 0.7131\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.7111 - acc: 0.7377\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.6398 - acc: 0.7295\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 360us/step - loss: 0.6854 - acc: 0.6967\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 360us/step - loss: 0.6982 - acc: 0.7377\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 335us/step - loss: 0.6049 - acc: 0.7705\n",
      "122/122 [==============================] - ETA:  - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.6539 - acc: 0.7377\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 343us/step - loss: 0.6357 - acc: 0.7459\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.6324 - acc: 0.7541\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.6940 - acc: 0.7295\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 360us/step - loss: 0.6339 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.6703 - acc: 0.7623\n",
      "122/122 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 335us/step - loss: 0.6783 - acc: 0.7459\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 344us/step - loss: 0.5940 - acc: 0.7951\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 450us/step - loss: 0.5936 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 356us/step - loss: 0.5906 - acc: 0.7951\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 364us/step - loss: 0.5977 - acc: 0.7869\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.5836 - acc: 0.7951\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 421us/step - loss: 0.5414 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 433us/step - loss: 0.5486 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 425us/step - loss: 0.5690 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 499us/step - loss: 0.5705 - acc: 0.7787\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.5324 - acc: 0.8279\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.5329 - acc: 0.8279\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 433us/step - loss: 0.5336 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 441us/step - loss: 0.5092 - acc: 0.8279\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 433us/step - loss: 0.4860 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.5301 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.4885 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 253us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.5075 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 360us/step - loss: 0.5158 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 319us/step - loss: 0.5265 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.5354 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 311us/step - loss: 0.5099 - acc: 0.7951\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.4843 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 343us/step - loss: 0.4833 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 339us/step - loss: 0.4856 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 204us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 388us/step - loss: 0.5129 - acc: 0.7787\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 360us/step - loss: 0.4590 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 311us/step - loss: 0.4141 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.4903 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 458us/step - loss: 0.4590 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 327us/step - loss: 0.4861 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 335us/step - loss: 0.4803 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 417us/step - loss: 0.5101 - acc: 0.7869\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 523us/step - loss: 0.4524 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.4503 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 441us/step - loss: 0.4623 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 499us/step - loss: 0.4650 - acc: 0.7951\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.4467 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 417us/step - loss: 0.4286 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.4113 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 499us/step - loss: 0.4436 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 425us/step - loss: 0.4900 - acc: 0.7787\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 417us/step - loss: 0.4445 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 556us/step - loss: 0.4896 - acc: 0.7951\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 433us/step - loss: 0.4849 - acc: 0.7951\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 482us/step - loss: 0.3827 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 536us/step - loss: 0.4244 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 372us/step - loss: 0.4261 - acc: 0.8279\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 421us/step - loss: 0.3927 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 523us/step - loss: 0.4177 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 221us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.4251 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 425us/step - loss: 0.4460 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.4225 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 548us/step - loss: 0.3999 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.4306 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.3961 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.4392 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 433us/step - loss: 0.4039 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.3909 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.4350 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 143us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 515us/step - loss: 0.4353 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 388us/step - loss: 0.4571 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.4493 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.3927 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 580us/step - loss: 0.4436 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 425us/step - loss: 0.4176 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.4283 - acc: 0.8279\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.4181 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 462us/step - loss: 0.3475 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 360us/step - loss: 0.4223 - acc: 0.7951\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 388us/step - loss: 0.3952 - acc: 0.8279\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.4528 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 229us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.3387 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.3781 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.4139 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.3439 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 360us/step - loss: 0.3376 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.3872 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 687us/step - loss: 0.3752 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 548us/step - loss: 0.4073 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 466us/step - loss: 0.4303 - acc: 0.7869\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.3690 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 450us/step - loss: 0.3354 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.4220 - acc: 0.8115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.3595 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.3310 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 662us/step - loss: 0.3184 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 110us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 458us/step - loss: 0.3997 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 454us/step - loss: 0.4162 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 478us/step - loss: 0.3841 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 163us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 474us/step - loss: 0.3692 - acc: 0.8279\n",
      "122/122 [==============================] - ETA:  - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 540us/step - loss: 0.3942 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 597us/step - loss: 0.3923 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 507us/step - loss: 0.3124 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 425us/step - loss: 0.3363 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 572us/step - loss: 0.3347 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 425us/step - loss: 0.3662 - acc: 0.8279\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.3555 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.3606 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 302us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 470us/step - loss: 0.3773 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 441us/step - loss: 0.3371 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 491us/step - loss: 0.3374 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.3247 - acc: 0.8279\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 450us/step - loss: 0.3581 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 433us/step - loss: 0.4337 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 695us/step - loss: 0.3328 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 113us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.4131 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 380us/step - loss: 0.3317 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.3456 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 192us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.3178 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.3570 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.3579 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 515us/step - loss: 0.3357 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 343us/step - loss: 0.3357 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.3376 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.3976 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 523us/step - loss: 0.3252 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 450us/step - loss: 0.3270 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.3718 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 605us/step - loss: 0.3620 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 380us/step - loss: 0.3425 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.3006 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.3262 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 499us/step - loss: 0.3502 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.3630 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.3693 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 369us/step - loss: 0.3283 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 544us/step - loss: 0.3029 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.4057 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 372us/step - loss: 0.3475 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.3372 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 111us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 540us/step - loss: 0.2957 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.4032 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.3428 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 474us/step - loss: 0.2859 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.3164 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.3253 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 352us/step - loss: 0.3450 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 531us/step - loss: 0.3407 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 425us/step - loss: 0.3066 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 163us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 474us/step - loss: 0.3631 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 417us/step - loss: 0.3581 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 221us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.3125 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.2675 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.3036 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 556us/step - loss: 0.3075 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 458us/step - loss: 0.3813 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.3255 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 548us/step - loss: 0.3243 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 94us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.3517 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 388us/step - loss: 0.2542 - acc: 0.9508\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.2469 - acc: 0.9180\n",
      "122/122 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 564us/step - loss: 0.2738 - acc: 0.9180\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 446us/step - loss: 0.2443 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 393us/step - loss: 0.2895 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.2652 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 433us/step - loss: 0.2545 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.2370 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.3228 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 629us/step - loss: 0.2800 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 433us/step - loss: 0.3428 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 388us/step - loss: 0.2771 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.2599 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 245us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 368us/step - loss: 0.2432 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.2892 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.3321 - acc: 0.800 - 0s 433us/step - loss: 0.2881 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 580us/step - loss: 0.3279 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.3322 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.2442 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.3408 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 192us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.2660 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.3158 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 482us/step - loss: 0.2870 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 135us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 523us/step - loss: 0.3729 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 119us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.2374 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.3109 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 384us/step - loss: 0.2905 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 376us/step - loss: 0.2600 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 392us/step - loss: 0.3144 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.3000 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 597us/step - loss: 0.3206 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 360us/step - loss: 0.2928 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 319us/step - loss: 0.2653 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 343us/step - loss: 0.2962 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 450us/step - loss: 0.2335 - acc: 0.9344\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 401us/step - loss: 0.2100 - acc: 0.9344\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 409us/step - loss: 0.2393 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 352us/step - loss: 0.2652 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 139us/step\n"
     ]
    }
   ],
   "source": [
    "print(\"################################## DNN em ##################################\")\n",
    "print(\"select: \"+str(select))\n",
    "for type_i in select:\n",
    "    print(types[type_i-1])\n",
    "print(\"#############################################################################################\")\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "input_drop_out_em = 0.3\n",
    "drop_out_em = 0.5\n",
    "layers = [5]\n",
    "em_tr_loss_best = 100 # for saving best loss value \n",
    "best_em_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "m_tr_predictions = [m_1_predictions, m_2_predictions, m_3_predictions, m_4_predictions, m_5_predictions, m_6_predictions]\n",
    "m_tr_predictions_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_tr_predictions_select.append(m_tr_predictions[select[i]-1])\n",
    "    #print(m_tr_predictions[select[i]-1].shape)\n",
    "    \n",
    "em_x_val = np.concatenate(m_tr_predictions_select, axis=1)\n",
    "\n",
    "input_em = Input(shape=(len(select),))\n",
    "em_m_dp = Dropout(input_drop_out_em)(input_em)\n",
    "for i in layers:\n",
    "    em_m = Dense(i,activation='relu')(em_m_dp)\n",
    "    em_m_dp = Dropout(drop_out_em)(em_m)\n",
    "em_m_final = em_m_dp\n",
    "output_em = Dense(1, activation=\"sigmoid\")(em_m_final)\n",
    "em_model = Model(inputs=input_em,outputs=output_em)\n",
    "em_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    em_model.fit(em_x_val, y_val_1, batch_size=10, nb_epoch=1)\n",
    "    em_tr_loss=em_model.evaluate(em_x_val,y_val_1)[0]\n",
    "    if em_tr_loss < em_tr_loss_best: # new best model. count reset.\n",
    "        em_tr_loss_best = em_tr_loss\n",
    "        count=0\n",
    "        best_em_model = em_model\n",
    "    if count>3: # no increase three time. stop.\n",
    "        em_model = best_em_model\n",
    "        break\n",
    "    else: count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _DNN Combiner_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 94us/step\n",
      "31/31 [==============================] - 0s 97us/step\n",
      "Overall AUC:  0.9171247357293868\n",
      "train AUC:  1.0\n",
      "test AUC:  0.595959595959596\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.6129032373428345\n",
      "Test Sensitivities & Specificities : 0.5555555555555556, 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "m_test_predictions = [m_1_test_predictions, m_2_test_predictions, m_3_test_predictions, m_4_test_predictions, m_5_test_predictions, m_6_test_predictions]\n",
    "m_test_predictions_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_test_predictions_select.append(m_test_predictions[select[i]-1])\n",
    "\n",
    "em_test_x_val = np.concatenate(m_test_predictions_select, axis=1)\n",
    "\n",
    "em_tr_loss,em_tr_accuracy= em_model.evaluate(em_x_val,y_val_1)\n",
    "em_loss,em_accuracy= em_model.evaluate(em_test_x_val,test_y_val_1)\n",
    "\n",
    "# tr predict & tr sensitivity / specificity\n",
    "em_tr_predictions = em_model.predict(em_x_val)\n",
    "labeled_em_tr_predictions = np.where(em_tr_predictions > 0.5, 1, 0).flatten()\n",
    "em_tr_sensitivity, em_tr_specificity = check_correct(labeled_em_tr_predictions, y_val_1)\n",
    "em_tr_predictions_flat = em_tr_predictions[:,0]\n",
    "\n",
    "# ts predict & tr sensitivity / specificity\n",
    "em_test_predictions = em_model.predict(em_test_x_val)\n",
    "labeled_em_test_predictions = np.where(em_test_predictions > 0.5, 1, 0).flatten()\n",
    "em_sensitivity, em_specificity = check_correct(labeled_em_test_predictions, test_y_val_1)\n",
    "em_test_predictions_flat = em_test_predictions[:,0]\n",
    "\n",
    "# 5) m_em auc\n",
    "tr_df_em = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(em_tr_predictions_flat), \n",
    "                        \"prediction\":list(labeled_em_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_em.to_csv(\"../result/prediction_result_DNN_em_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "ts_df_em = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(em_test_predictions_flat), \n",
    "                        \"prediction\":list(labeled_em_test_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_em.to_csv(\"../result/prediction_result_DNN_em_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_1, test_y_val_1)\n",
    "y_pred = np.append(labeled_em_tr_predictions, labeled_em_test_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_1, labeled_em_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_1, labeled_em_test_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(em_tr_sensitivity)+\", \"+str(em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(em_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(em_sensitivity)+\", \"+str(em_specificity))\n",
    "\n",
    "# 6) save model\n",
    "em_model.save(\"../models/Ovary/m_em.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _mean_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC:  0.8862579281183932\n",
      "train AUC:  0.9705882352941176\n",
      "test AUC:  0.5656565656565656\n",
      "Train Accuracy for mean em : 0.9836065573770492\n",
      "Train Sensitivities & Specificities : 0.9411764705882353, 1.0\n",
      "Test Accuracy for mean em : 0.7096774193548387\n",
      "Test Sensitivities & Specificities : 0.2222222222222222, 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "mean_em_tr_predictions=sum(m_tr_predictions_select)/len(select)\n",
    "labeled_mean_em_tr_predictions = np.where(mean_em_tr_predictions > 0.5, 1, 0).flatten()\n",
    "mean_em_tr_accuracy = sum(labeled_mean_em_tr_predictions==y_val_1.values)/len(y_val_1)\n",
    "mean_em_tr_sensitivity, mean_em_tr_specificity = check_correct(labeled_mean_em_tr_predictions, y_val_1)\n",
    "mean_em_tr_predictions_flat = mean_em_tr_predictions[:,0]\n",
    "\n",
    "mean_predictions=sum(m_test_predictions_select)/len(select)\n",
    "labeled_mean_em_predictions = np.where(mean_predictions > 0.5, 1, 0).flatten()\n",
    "mean_em_accuracy = sum(labeled_mean_em_predictions==test_y_val_1.values)/len(test_y_val_1)\n",
    "mean_em_sensitivity, mean_em_specificity = check_correct(labeled_mean_em_predictions, test_y_val_1)\n",
    "mean_em_test_predictions_flat = mean_predictions[:,0]\n",
    "\n",
    "tr_df_em_mean = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis_1\": list(mean_em_tr_predictions_flat), \n",
    "  \"prediction\":list(labeled_mean_em_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_em_mean.to_csv(\"../result/prediction_result_mean_em_tr.csv\", index=False, header=True, \n",
    "                     columns = [\"patient\", \"hypothesis_1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_em_mean = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis_1\": list(mean_em_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_mean_em_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_em_mean.to_csv(\"../result/prediction_result_mean_em_ts.csv\", index=False, header=True, \n",
    "                     columns = [\"patient\", \"hypothesis_1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_1, test_y_val_1)\n",
    "y_pred = np.append(labeled_mean_em_tr_predictions, labeled_mean_em_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_1, labeled_mean_em_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_1, labeled_mean_em_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy for mean em : {}\".format(mean_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(mean_em_tr_sensitivity)+\", \"+str(mean_em_tr_specificity))\n",
    "print(\"Test Accuracy for mean em : {}\".format(mean_em_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(mean_em_sensitivity)+\", \"+str(mean_em_specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferred Ensemble Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making new input data for t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 1310)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "results_m_1 = model_1_l_new.predict([x_val_1])\n",
    "results_m_2 = model_2_l_new.predict([x_val_2])\n",
    "results_m_3 = model_3_l_new.predict([x_val_3])\n",
    "results_m_4 = model_4_l_new.predict([x_val_4])\n",
    "results_m_5 = model_5_l_new.predict([x_val_5])\n",
    "results_m_6 = model_6_l_new.predict([x_val_6])\n",
    "\n",
    "results_m_sum = [results_m_1, results_m_2, results_m_3, results_m_4, results_m_5, results_m_6]\n",
    "results_m_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    results_m_select.append(results_m_sum[select[i]-1])\n",
    "\n",
    "t_em_x_val = np.concatenate(results_m_select, axis=1)\n",
    "print(t_em_x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling t-ensemble  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.5300 - acc: 0.7213\n",
      "122/122 [==============================] - 1s 6ms/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 944us/step - loss: 0.1518 - acc: 0.9180\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 932us/step - loss: 0.0533 - acc: 0.9836\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 0.0371 - acc: 0.9918\n",
      "122/122 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 163us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 0.0214 - acc: 0.9918\n",
      "122/122 [==============================] - 0s 213us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 924us/step - loss: 0.0064 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 997us/step - loss: 0.0063 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 956us/step - loss: 0.0125 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 168us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 134us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 989us/step - loss: 0.0063 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0077 - acc: 0.9918\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 932us/step - loss: 0.0107 - acc: 0.9918\n",
      "122/122 [==============================] - 0s 204us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3.6681e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 989us/step - loss: 0.0025 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 965us/step - loss: 0.0010 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 940us/step - loss: 0.0039 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 221us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 981us/step - loss: 0.0016 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 977us/step - loss: 0.0013 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 989us/step - loss: 0.0010 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 846us/step - loss: 0.0018 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 948us/step - loss: 0.0046 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 196us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 1.3713e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 163us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 989us/step - loss: 0.0017 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 7.8315e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 956us/step - loss: 6.8245e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 912us/step - loss: 5.8044e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 4.0682e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 965us/step - loss: 2.9945e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 924us/step - loss: 7.4668e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 924us/step - loss: 1.8375e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 924us/step - loss: 0.0016 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 899us/step - loss: 1.2390e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 916us/step - loss: 8.1884e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 2.1851e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 899us/step - loss: 1.8646e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 863us/step - loss: 1.0473e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 1.6927e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 899us/step - loss: 1.1372e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 940us/step - loss: 0.0011 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 7.4895e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 891us/step - loss: 1.5353e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 858us/step - loss: 6.2998e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 932us/step - loss: 1.7606e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 875us/step - loss: 8.0812e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 867us/step - loss: 4.7996e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 887us/step - loss: 1.1360e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 6.7847e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 842us/step - loss: 1.5130e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 889us/step - loss: 3.2269e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 846us/step - loss: 1.2966e-04 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 895us/step - loss: 4.4870e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 163us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 895us/step - loss: 1.7530e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 920us/step - loss: 7.7795e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 948us/step - loss: 2.7090e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 948us/step - loss: 1.3716e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 4.9543e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 965us/step - loss: 1.2491e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 948us/step - loss: 1.2478e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2.7864e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 965us/step - loss: 7.5121e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 903us/step - loss: 6.2921e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 4.7753e-06 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 969us/step - loss: 6.4514e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1.6481e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 981us/step - loss: 3.5664e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 163us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 907us/step - loss: 4.4979e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 940us/step - loss: 1.8152e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 957us/step - loss: 4.2935e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 948us/step - loss: 1.8977e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 4.2269e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2.6135e-04 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 4.1422e-05 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 131us/step\n"
     ]
    }
   ],
   "source": [
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "input_drop_out_t_em = 0.3\n",
    "drop_out_t_em = 0.5\n",
    "layers = [100, 50, 40]\n",
    "t_em_tr_loss_best = 100 # for saving best loss value \n",
    "best_t_em_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "input_t_em = Input(shape=(t_em_x_val.shape[1],))\n",
    "t_em_m_dp = Dropout(input_drop_out_t_em)(input_t_em)\n",
    "for i in layers:\n",
    "    t_em_m = Dense(i,activation='relu')(t_em_m_dp)\n",
    "    t_em_m_dp = Dropout(drop_out_em)(t_em_m)\n",
    "t_em_m_final = t_em_m_dp\n",
    "output_t_em = Dense(1, activation=\"sigmoid\")(t_em_m_final)\n",
    "t_em_model = Model(inputs=input_t_em,outputs=output_t_em)\n",
    "t_em_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    t_em_model.fit(t_em_x_val, y_val_1, batch_size=10, nb_epoch=1)\n",
    "    t_em_tr_loss=t_em_model.evaluate(t_em_x_val,y_val_1)[0]\n",
    "    if t_em_tr_loss < t_em_tr_loss_best: # new best model. count reset.\n",
    "        t_em_tr_loss_best = t_em_tr_loss\n",
    "        count=0\n",
    "        best_t_em_model = t_em_model\n",
    "    if count>3: # no increase three time. stop.\n",
    "        t_em_model = best_t_em_model\n",
    "        break\n",
    "    else: count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 147us/step\n",
      "31/31 [==============================] - 0s 129us/step\n",
      "Overall AUC:  0.9100422832980972\n",
      "train AUC:  1.0\n",
      "test AUC:  0.5631313131313131\n",
      "Train Accuracy for mean em : 0.9836065573770492\n",
      "Train Sensitivities & Specificities : 0.9411764705882353, 1.0\n",
      "Test Accuracy for mean em : 0.7096774193548387\n",
      "Test Sensitivities & Specificities : 0.2222222222222222, 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "test_results_m_1 = model_1_l_new.predict([test_x_val_1])\n",
    "test_results_m_2 = model_2_l_new.predict([test_x_val_2])\n",
    "test_results_m_3 = model_3_l_new.predict([test_x_val_3])\n",
    "test_results_m_4 = model_4_l_new.predict([test_x_val_4])\n",
    "test_results_m_5 = model_5_l_new.predict([test_x_val_5])\n",
    "test_results_m_6 = model_6_l_new.predict([test_x_val_6])\n",
    "\n",
    "test_results_m_sum = [test_results_m_1, test_results_m_2, test_results_m_3, test_results_m_4, test_results_m_5, test_results_m_6]\n",
    "test_results_m_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    test_results_m_select.append(test_results_m_sum[select[i]-1])\n",
    "\n",
    "t_em_test_x_val = np.concatenate(test_results_m_select, axis=1)\n",
    "t_em_tr_accuracy = t_em_model.evaluate(t_em_x_val,y_val_1)[1]\n",
    "t_em_accuracy = t_em_model.evaluate(t_em_test_x_val,test_y_val_1)[1]\n",
    "\n",
    "t_em_tr_predictions = t_em_model.predict(t_em_x_val)\n",
    "labeled_t_em_tr_predictions = np.where(t_em_tr_predictions > 0.5, 1, 0).flatten()\n",
    "t_em_tr_sensitivity, t_em_tr_specificity = check_correct(labeled_t_em_tr_predictions, y_val_1)\n",
    "t_em_tr_predictions_flat = t_em_tr_predictions[:,0]\n",
    "\n",
    "t_em_test_predictions = t_em_model.predict(t_em_test_x_val)\n",
    "labeled_t_em_test_predictions = np.where(t_em_test_predictions > 0.5, 1, 0).flatten()\n",
    "t_em_sensitivity, t_em_specificity = check_correct(labeled_t_em_test_predictions, test_y_val_1)\n",
    "t_em_test_predictions_flat = t_em_test_predictions[:,0]\n",
    "\n",
    "df_t_em_tr = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis_1\": list(t_em_tr_predictions_flat), \n",
    "  \"prediction\":list(labeled_t_em_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "df_t_em_tr.to_csv(\"../result/prediction_result_t_em_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "df_t_em_ts = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis_1\": list(t_em_test_predictions_flat), \n",
    "  \"prediction\":list(labeled_t_em_test_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "df_t_em_ts.to_csv(\"../result/prediction_result_t_em_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis_1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "y_true = np.append(y_val_1, test_y_val_1)\n",
    "y_pred = np.append(labeled_t_em_tr_predictions, labeled_t_em_test_predictions)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "fpr_train, tpr_train, threshold = metrics.roc_curve(y_val_1, labeled_t_em_tr_predictions)\n",
    "fpr_test, tpr_test, threshold = metrics.roc_curve(test_y_val_1, labeled_t_em_test_predictions)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"Overall AUC: \", roc_auc)\n",
    "print(\"train AUC: \", roc_auc_train)\n",
    "print(\"test AUC: \", roc_auc_test)\n",
    "\n",
    "print(\"Train Accuracy for mean em : {}\".format(mean_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(mean_em_tr_sensitivity)+\", \"+str(mean_em_tr_specificity))\n",
    "print(\"Test Accuracy for mean em : {}\".format(mean_em_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(mean_em_sensitivity)+\", \"+str(mean_em_specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm_1_tr_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-a301a9ac1dc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtr_accuracy_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mm_1_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_2_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_3_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_4_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_5_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_6_tr_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mts_accuracy_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mm_1_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_2_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_3_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_4_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_5_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_6_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtr_accuracy_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mts_accuracy_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm_1_tr_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "tr_accuracy_list = [m_1_tr_accuracy, m_2_tr_accuracy, m_3_tr_accuracy, m_4_tr_accuracy, m_5_tr_accuracy, m_6_tr_accuracy]\n",
    "ts_accuracy_list = [m_1_accuracy, m_2_accuracy, m_3_accuracy, m_4_accuracy, m_5_accuracy, m_6_accuracy]\n",
    "tr_accuracy_select = []\n",
    "ts_accuracy_select = []\n",
    "\n",
    "for i in select:\n",
    "    label.append(\"model\"+str(i))\n",
    "    tr_accuracy_select.append(tr_accuracy_list[i-1])\n",
    "    ts_accuracy_select.append(ts_accuracy_list[i-1])\n",
    "\n",
    "label = label+[\"mean-em\",\"d-comb em\",\"t-em\"]\n",
    "tr_accuracy_select= tr_accuracy_select + [mean_em_tr_accuracy, em_tr_accuracy, t_em_tr_accuracy]\n",
    "ts_accuracy_select= ts_accuracy_select + [mean_em_accuracy, em_accuracy, t_em_accuracy]\n",
    "\n",
    "for model_num in range(len(label)):\n",
    "    print(\"< \"+label[model_num]+\" > tr: \"+str(tr_accuracy_select[model_num])+\", ts: \"+str(ts_accuracy_select[model_num]))\n",
    "\n",
    "#label = [\"model1\",\"model2\",\"model3\",\"mean-em\",\"d-comb em\",\"t-em\"]\n",
    "#accuracy = [m1_accuracy,m2_accuracy,m3_accuracy,mean_em_accuracy,em_accuracy,t_em_accuracy ]\n",
    "#print(\"model1: \"+str(accuracy[0])+\"\\nmodel2: \"+str(accuracy[1])+\"\\nmodel3: \"+str(accuracy[2])+\"\\nmean-em: \"+str(accuracy[3])+\"\\nd-comb em: \"+str(accuracy[4])+\"\\nt-em: \"+str(accuracy[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def plot_bar_x():\n",
    "    # this is for plotting purpose\n",
    "    plt.figure(figsize=(30,20))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([min(m_1_accuracy,m_2_accuracy,m_3_accuracy,mean_em_accuracy,em_accuracy,t_em_accuracy)-0.02,1])\n",
    "    index = np.arange(len(label))\n",
    "    plt.bar(index, accuracy,color=['red', 'orange', 'yellow', \"green\",'blue', 'purple'],alpha=0.5,width=0.3)\n",
    "    plt.xlabel('Method', fontsize=35)\n",
    "    plt.ylabel('Accuracy', fontsize=35)\n",
    "    plt.yticks(fontsize=30)    \n",
    "    plt.xticks(index, label, fontsize=30, rotation=90)\n",
    "    plt.title('Performance Comparison for each Ensemble Model',fontsize=40)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "plot_bar_x()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
