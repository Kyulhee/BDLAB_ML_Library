{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Packages & Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Input, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, load_model, Sequential \n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity & specificity using Predicted Y & Real Y\n",
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide raw data into train / test & x_val / y_val\n",
    "def data_split(raw_data, index_col, test_index):\n",
    "    \n",
    "    train_data = raw_data.iloc[list(raw_data.iloc[:,index_col]!=test_index)]\n",
    "    test_data = raw_data.iloc[list(raw_data.iloc[:,index_col]==test_index)]\n",
    "    \n",
    "    y_val = train_data.Platinum_Status\n",
    "    x_val = train_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val = test_data.Platinum_Status\n",
    "    test_x_val = test_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    return train_data, test_data, y_val, x_val, test_y_val, test_x_val\n",
    "\n",
    "    # raw_data: have gene_expressions(maybe multiple columns), index column, Platinum_Status column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all of model performance \n",
    "# - predictions(probability) / labeled predictions(0/1) / Loss / Accuracy / Sensitivity / Specificity / AUC values of Train / Test dataset.\n",
    "# using trained models, or you can put predictions(probability) passively(in this case, Loss & Accuracy do not provided.)\n",
    "def model_performance(information=False, Input_Prediction_Passively=False, using_model=None, tr_predictions=None, ts_predictions=None, tr_x_val=None, tr_y_val=None, ts_x_val=None, ts_y_val=None, output_list=None):\n",
    "    \n",
    "    if information == True:            \n",
    "        print(\"options model_performance:\\n1) using_model: keras models that you want to check performance. \\\"Input_Prediction_Passive\\\" option for input prediction list instead using models.\\n3) tr_predictions & ts_predictions: prediction input passively. put this data only when not using keras model.\\n4) tr_x_val & ts_x_val: input samples of train/test samples.\\n4) tr_y_val & ts_y_val: results of train/test samples.\\n5) output_list: return values that you want to recieve.\\n CAUTION: Essential variable.\\n\\t tr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\\n\\n* CAUTION: if 'None' value is returned, please check your input tr inputs(None value for tr outputs) or ts inputs(None value for ts outputs).\") \n",
    "        return 0\n",
    "    elif information != False:\n",
    "        print(\"for using information options, please set 'information' variable for 'True'\")\n",
    "        return -1\n",
    "    \n",
    "    if using_model is None:\n",
    "        if Input_Prediction_Passively == False:\n",
    "            print(\"ERROR: There are no models for using.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\") \n",
    "            return -1\n",
    "        elif (tr_predictions is None) and (ts_predictions is None): # No model/prediction input. no performance should be calculated.\n",
    "                print(\"ERROR: Input prediction list instead using saved model.\")\n",
    "                return -1\n",
    "        else: # No model input, but Input_Prediction_Passively is True & input prediction is valid.\n",
    "            tr_loss,tr_accuracy= None, None\n",
    "            ts_loss,ts_accuracy= None, None\n",
    "            \n",
    "    elif Input_Prediction_Passively == True: # both of model/prediction putted, could cause confusing.\n",
    "        ch = input(\"You put both model and prediction. Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "        while 1:\n",
    "            if ch == 'p':\n",
    "                using_model = None\n",
    "                break\n",
    "            elif ch == 'm':\n",
    "                tr_predictions = None\n",
    "                ts_predictions = None\n",
    "                break\n",
    "            elif ch == 'e':\n",
    "                return 0\n",
    "            else:\n",
    "                print(\"you put worng option: \"+str(ch))\n",
    "            ch = input(\"Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "                \n",
    "    if output_list is None:\n",
    "        print(\"ERROR: There are no output_list for return.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\")\n",
    "        return -1\n",
    "    \n",
    "    if not(tr_x_val is None) and not(tr_y_val is None):\n",
    "        # predict tr result only when no tr_prediction input\n",
    "        if tr_predictions is None:\n",
    "            tr_loss,tr_accuracy= using_model.evaluate(tr_x_val,tr_y_val,verbose=0)\n",
    "            tr_predictions = using_model.predict(tr_x_val,verbose=0)\n",
    "        # tr sensitivity / specificity\n",
    "        labeled_tr_predictions = np.where(tr_predictions > 0.5, 1, 0).flatten()\n",
    "        tr_sensitivity, tr_specificity = check_correct(labeled_tr_predictions, tr_y_val)\n",
    "        tr_predictions_flat = tr_predictions[:,0]   \n",
    "        # roc(tr)\n",
    "        fpr_tr, tpr_tr, threshold_tr = metrics.roc_curve(tr_y_val, tr_predictions)\n",
    "        roc_auc_tr = metrics.auc(fpr_tr, tpr_tr)\n",
    "    \n",
    "    if not(ts_x_val is None) and not(ts_y_val is None):\n",
    "        # predict ts result only when no ts_prediction input\n",
    "        if ts_predictions is None:\n",
    "            ts_loss,ts_accuracy= using_model.evaluate(ts_x_val,ts_y_val,verbose=0)\n",
    "            ts_predictions = using_model.predict(ts_x_val,verbose=0)\n",
    "        labeled_ts_predictions = np.where(ts_predictions > 0.5, 1, 0).flatten()\n",
    "        ts_sensitivity, ts_specificity = check_correct(labeled_ts_predictions, ts_y_val)\n",
    "        ts_predictions_flat = ts_predictions[:,0]   \n",
    "        # roc(ts)\n",
    "        fpr_ts, tpr_ts, threshold_ts = metrics.roc_curve(ts_y_val, ts_predictions)\n",
    "        roc_auc_ts = metrics.auc(fpr_ts, tpr_ts)    \n",
    "    \n",
    "    if (not(tr_x_val is None) and not(tr_y_val is None)) and (not(ts_x_val is None) and not(ts_y_val is None)):\n",
    "        y_true = np.append(tr_y_val, ts_y_val)\n",
    "        y_pred = np.append(tr_predictions, ts_predictions)\n",
    "        fpr_total, tpr_total, threshold_total = metrics.roc_curve(y_true, y_pred)\n",
    "        roc_auc_total = metrics.auc(fpr_total, tpr_total)\n",
    "        \n",
    "        \n",
    "    return_list = []\n",
    "    \n",
    "    for output in output_list:\n",
    "        \n",
    "        if(output == \"tr_loss\"):\n",
    "            return_list.append(tr_loss)\n",
    "                               \n",
    "        elif(output == \"tr_accuracy\"):\n",
    "            return_list.append(tr_accuracy)\n",
    "                               \n",
    "        elif(output == \"tr_sensitivity\"):\n",
    "            return_list.append(tr_sensitivity)\n",
    "                               \n",
    "        elif(output == \"tr_specificity\"):\n",
    "            return_list.append(tr_specificity)\n",
    "                               \n",
    "        elif(output == \"tr_predictions\"):\n",
    "            return_list.append(tr_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_tr_predictions\"):\n",
    "            return_list.append(labeled_tr_predictions)\n",
    "                               \n",
    "        elif(output == \"tr_predictions_flat\"):\n",
    "            return_list.append(tr_predictions_flat)\n",
    "            \n",
    "        elif(output == \"roc_auc_tr\"):\n",
    "            return_list.append(roc_auc_tr)\n",
    "\n",
    "        elif(output == \"ts_loss\"):\n",
    "            return_list.append(ts_loss)\n",
    "                               \n",
    "        elif(output == \"ts_accuracy\"):\n",
    "            return_list.append(ts_accuracy)\n",
    "                               \n",
    "        elif(output == \"ts_sensitivity\"):\n",
    "            return_list.append(ts_sensitivity)\n",
    "                               \n",
    "        elif(output == \"ts_specificity\"):\n",
    "            return_list.append(ts_specificity)\n",
    "                               \n",
    "        elif(output == \"ts_predictions\"):\n",
    "            return_list.append(ts_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_ts_predictions\"):\n",
    "            return_list.append(labeled_ts_predictions)\n",
    "                               \n",
    "        elif(output == \"ts_predictions_flat\"):\n",
    "            return_list.append(ts_predictions_flat)\n",
    "        \n",
    "        elif(output == \"roc_auc_ts\"):\n",
    "            return_list.append(roc_auc_ts)\n",
    "            \n",
    "        elif(output == \"roc_auc_total\"):\n",
    "            return_list.append(roc_auc_total)\n",
    "                               \n",
    "        else:\n",
    "            print(\"There are no options <\"+str(output)+\">. Please refer these output options:\\ntr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\")\n",
    "            break\n",
    "    \n",
    "    if len(return_list)==1:\n",
    "        return_list = return_list[0]\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training one NN model using train X & Y values\n",
    "# Returns trained NN model\n",
    "def train_NN_model(tr_x_val, tr_y_val, val_x_val, val_y_val, n_epoch):\n",
    "    \n",
    "    # 1) parameter setting\n",
    "    lr=0.01\n",
    "    input_drop_out = 0\n",
    "    drop_out = 0.5\n",
    "    layers = [10]\n",
    "    BN = True\n",
    "    batch_size = 5\n",
    "    m_tr_loss_best = 100\n",
    "    \n",
    "    m_adam = optimizers.Adam(lr=lr)\n",
    "    # 2) model build\n",
    "    #m_input = Input(shape=(input_dim[1],))\n",
    "    m_input = Input(shape=(tr_x_val.shape[1],))\n",
    "    m_dp = Dropout(input_drop_out)(m_input)\n",
    "    if BN == True:\n",
    "        for i in layers:\n",
    "            m_h = Dense(i)(m_dp)\n",
    "            m_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(m_h)\n",
    "            m_dp = Activation(\"relu\")(m_bn)\n",
    "    else:        \n",
    "        for i in m_layers:\n",
    "            m_h = Dense(i,activation='relu')(m_dp)\n",
    "            m_dp = Dropout(drop_out)(m_h)\n",
    "    m_final = m_dp\n",
    "    m_output = Dense(1, activation=\"sigmoid\")(m_final)\n",
    "    m_model = Model(inputs=m_input,outputs=m_output)\n",
    "    m_model.compile(optimizer=m_adam, \n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    # Training method that maximize train accuracy does not fit into AdatBoost: because it makes too strong classifier\n",
    "#    while 1:\n",
    "#        m_model.fit(tr_x_val, tr_y_val, batch_size=batch_size, epochs=1, verbose = 0)\n",
    "#        m_tr_loss=m_model.evaluate(tr_x_val, tr_y_val, verbose = 0)[0]\n",
    "#        if m_tr_loss < m_tr_loss_best: # new best model. count reset.\n",
    "#            m_tr_loss_best = m_tr_loss\n",
    "#            count=0\n",
    "#            best_m_model = m_model\n",
    "#        if count>3: # no increase three time. stop.\n",
    "#            m_model = best_m_model\n",
    "#            break\n",
    "#        else: count=count+1\n",
    "    m_model.fit(tr_x_val, tr_y_val, batch_size=batch_size, epochs=n_epoch, verbose = 0, validation_data=(val_x_val, val_y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    return m_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Input Data & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Declaration of path name & type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"OV_six_fold_Annotation3000_400\", \n",
    "         \"OV_six_fold_CV_400\", \n",
    "         \"OV_six_fold_Var_400\", \"OV_six_fold_new_Diff_400\",\n",
    "         \"OV_six_fold_Clin\", \n",
    "         \"OV_six_fold_SNV\" \n",
    "         ]\n",
    "\n",
    "path = \"../../../TC_six_fold_subsamples/\"\n",
    "save_model_path = \"../best_models/model/\"\n",
    "save_prediction_path = \"../best_models/predictions/\"\n",
    "save_result_path = \"../best_models/results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Split data into train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] file_name:  OV_six_fold_Annotation3000_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[2] file_name:  OV_six_fold_CV_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[3] file_name:  OV_six_fold_Var_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[4] file_name:  OV_six_fold_new_Diff_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[5] file_name:  OV_six_fold_Clin \n",
      "sample : 287  \n",
      "features : 35\n",
      "[6] file_name:  OV_six_fold_SNV \n",
      "sample : 213  \n",
      "features : 13814\n"
     ]
    }
   ],
   "source": [
    "file_1 = path+types[0]+\".csv\"\n",
    "file_2 = path+types[1]+\".csv\"\n",
    "file_3 = path+types[2]+\".csv\"\n",
    "file_4 = path+types[3]+\".csv\"\n",
    "file_5 = path+types[4]+\".csv\"\n",
    "file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "full_data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "full_data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "full_data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "full_data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "full_data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "full_data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "inter_data_1 = full_data_1.iloc[list(full_data_1.iloc[:,-1]!=6)]\n",
    "inter_data_2 = full_data_2.iloc[list(full_data_2.iloc[:,-1]!=6)]\n",
    "inter_data_3 = full_data_3.iloc[list(full_data_3.iloc[:,-1]!=6)]\n",
    "inter_data_4 = full_data_4.iloc[list(full_data_4.iloc[:,-1]!=6)]\n",
    "inter_data_5 = full_data_5.iloc[list(full_data_5.iloc[:,-1]!=6)]\n",
    "inter_data_6 = full_data_6.iloc[list(full_data_6.iloc[:,-1]!=6)]\n",
    "\n",
    "print(\"[1] file_name: \", types[0], \"\\nsample : {}  \\nfeatures : {}\".format(full_data_1.shape[0],full_data_1.shape[1]-2))\n",
    "print(\"[2] file_name: \", types[1], \"\\nsample : {}  \\nfeatures : {}\".format(full_data_2.shape[0],full_data_2.shape[1]-2))\n",
    "print(\"[3] file_name: \", types[2], \"\\nsample : {}  \\nfeatures : {}\".format(full_data_3.shape[0],full_data_3.shape[1]-2))\n",
    "print(\"[4] file_name: \", types[3], \"\\nsample : {}  \\nfeatures : {}\".format(full_data_4.shape[0],full_data_4.shape[1]-2))\n",
    "print(\"[5] file_name: \", types[4], \"\\nsample : {}  \\nfeatures : {}\".format(full_data_5.shape[0],full_data_5.shape[1]-2))\n",
    "print(\"[6] file_name: \", types[5], \"\\nsample : {}  \\nfeatures : {}\".format(full_data_6.shape[0],full_data_6.shape[1]-2))\n",
    "\n",
    "\n",
    "# Split Train Test Data\n",
    "\n",
    "tr_data_1, ts_data_1, tr_y_1, tr_x_1, ts_y_1, ts_x_1 = data_split(raw_data = full_data_1, index_col = -1, test_index = 1)\n",
    "tr_data_2, ts_data_2, tr_y_2, tr_x_2, ts_y_2, ts_x_2 = data_split(raw_data = full_data_2, index_col = -1, test_index = 1)\n",
    "tr_data_3, ts_data_3, tr_y_3, tr_x_3, ts_y_3, ts_x_3 = data_split(raw_data = full_data_3, index_col = -1, test_index = 1)\n",
    "tr_data_4, ts_data_4, tr_y_4, tr_x_4, ts_y_4, ts_x_4 = data_split(raw_data = full_data_4, index_col = -1, test_index = 1)\n",
    "tr_data_5, ts_data_5, tr_y_5, tr_x_5, ts_y_5, ts_x_5 = data_split(raw_data = full_data_5, index_col = -1, test_index = 1)\n",
    "tr_data_6, ts_data_6, tr_y_6, tr_x_6, ts_y_6, ts_x_6 = data_split(raw_data = full_data_6, index_col = -1, test_index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x_1 = tr_x_1.iloc[:int(tr_x_1.shape[0]/10),:]\n",
    "tr_x_1 = tr_x_1.iloc[int(tr_x_1.shape[0]/10):,:]\n",
    "val_y_1 = tr_y_1.iloc[:int(tr_y_1.shape[0]/10)]\n",
    "tr_y_1 = tr_y_1.iloc[int(tr_y_1.shape[0]/10):]\n",
    "\n",
    "val_x_2 = tr_x_2.iloc[:int(tr_x_2.shape[0]/10),:]\n",
    "tr_x_2 = tr_x_2.iloc[int(tr_x_2.shape[0]/10):,:]\n",
    "val_y_2 = tr_y_2.iloc[:int(tr_y_2.shape[0]/10)]\n",
    "tr_y_2 = tr_y_2.iloc[int(tr_y_2.shape[0]/10):]\n",
    "\n",
    "val_x_3 = tr_x_3.iloc[:int(tr_x_3.shape[0]/10),:]\n",
    "tr_x_3 = tr_x_3.iloc[int(tr_x_3.shape[0]/10):,:]\n",
    "val_y_3 = tr_y_3.iloc[:int(tr_y_3.shape[0]/10)]\n",
    "tr_y_3 = tr_y_3.iloc[int(tr_y_3.shape[0]/10):]\n",
    "\n",
    "val_x_4 = tr_x_4.iloc[:int(tr_x_4.shape[0]/10),:]\n",
    "tr_x_4 = tr_x_4.iloc[int(tr_x_4.shape[0]/10):,:]\n",
    "val_y_4 = tr_y_4.iloc[:int(tr_y_4.shape[0]/10)]\n",
    "tr_y_4 = tr_y_4.iloc[int(tr_y_4.shape[0]/10):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x_list = [tr_x_1, tr_x_2, tr_x_3, tr_x_4]\n",
    "tr_y_list = [tr_y_1, tr_y_2, tr_y_3, tr_y_4]\n",
    "ts_x_list = [ts_x_1, ts_x_2, ts_x_3, ts_x_4]\n",
    "ts_y_list = [ts_y_1, ts_y_2, ts_y_3, ts_y_4]\n",
    "val_x_list = [val_x_1, val_x_2, val_x_3, val_x_4]\n",
    "val_y_list = [val_y_1, val_y_2, val_y_3, val_y_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training Models & Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Training models N stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_model_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1/5th step\n",
      "\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 4s 25ms/step - loss: 0.8114 - acc: 0.6250 - val_loss: 1.3072 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4737 - acc: 0.7679 - val_loss: 1.1544 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3187 - acc: 0.8929 - val_loss: 1.5228 - val_acc: 0.6111\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3052 - acc: 0.8750 - val_loss: 2.0179 - val_acc: 0.6111\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2633 - acc: 0.9048 - val_loss: 1.4941 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2601 - acc: 0.8988 - val_loss: 1.2898 - val_acc: 0.6667\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1309 - acc: 0.9583 - val_loss: 1.6354 - val_acc: 0.4444\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2202 - acc: 0.9167 - val_loss: 1.7875 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1475 - acc: 0.9464 - val_loss: 3.5440 - val_acc: 0.6111\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1660 - acc: 0.9226 - val_loss: 3.9259 - val_acc: 0.6111\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1419 - acc: 0.9524 - val_loss: 1.5248 - val_acc: 0.5556\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1503 - acc: 0.9524 - val_loss: 2.1105 - val_acc: 0.4444\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.018 (error: 0.018)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 4s 25ms/step - loss: 0.7776 - acc: 0.6488 - val_loss: 0.8080 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4619 - acc: 0.7857 - val_loss: 0.8835 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4296 - acc: 0.8095 - val_loss: 0.8441 - val_acc: 0.6111\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2767 - acc: 0.9107 - val_loss: 0.9849 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2399 - acc: 0.8929 - val_loss: 0.8234 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1880 - acc: 0.9226 - val_loss: 1.0241 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2089 - acc: 0.9167 - val_loss: 1.0815 - val_acc: 0.5556\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1621 - acc: 0.9524 - val_loss: 1.1436 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1187 - acc: 0.9524 - val_loss: 1.0975 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1485 - acc: 0.9464 - val_loss: 1.0998 - val_acc: 0.6667\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1341 - acc: 0.9524 - val_loss: 1.2161 - val_acc: 0.6111\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.0 (error: 0.0)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.8589 - acc: 0.6190 - val_loss: 1.8355 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4504 - acc: 0.7738 - val_loss: 1.0778 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3642 - acc: 0.8512 - val_loss: 1.0374 - val_acc: 0.4444\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2661 - acc: 0.8988 - val_loss: 1.4142 - val_acc: 0.6111\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1834 - acc: 0.9405 - val_loss: 1.5588 - val_acc: 0.3889\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0989 - acc: 0.9821 - val_loss: 2.2049 - val_acc: 0.6111\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1169 - acc: 0.9702 - val_loss: 2.2940 - val_acc: 0.4444\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0837 - acc: 0.9821 - val_loss: 2.7947 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2012 - acc: 0.9107 - val_loss: 2.3423 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1237 - acc: 0.9464 - val_loss: 2.2160 - val_acc: 0.6111\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1167 - acc: 0.9464 - val_loss: 1.8177 - val_acc: 0.6111\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1037 - acc: 0.9643 - val_loss: 2.6659 - val_acc: 0.6111\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1353 - acc: 0.9583 - val_loss: 1.7407 - val_acc: 0.3333\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.054 (error: 0.054)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 33ms/step - loss: 0.4843 - acc: 0.7917 - val_loss: 1.4423 - val_acc: 0.4444\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1978 - acc: 0.9405 - val_loss: 1.3114 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1818 - acc: 0.9286 - val_loss: 1.2191 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0765 - acc: 0.9702 - val_loss: 1.5189 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1136 - acc: 0.9583 - val_loss: 2.1124 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0944 - acc: 0.9702 - val_loss: 1.7642 - val_acc: 0.4444\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0888 - acc: 0.958 - 0s 3ms/step - loss: 0.0936 - acc: 0.9583 - val_loss: 2.1763 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2106 - acc: 0.9405 - val_loss: 1.6703 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0751 - acc: 0.9643 - val_loss: 1.5097 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - acc: 0.9762 - val_loss: 1.6018 - val_acc: 0.4444\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1972 - acc: 0.9702 - val_loss: 1.6834 - val_acc: 0.4444\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1164 - acc: 0.9405 - val_loss: 1.8717 - val_acc: 0.5556\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - acc: 0.9821 - val_loss: 2.2568 - val_acc: 0.5000\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.0 (error: 0.0)\n",
      "\n",
      "\t-> Selected: OV_six_fold_CV_400\n",
      "\t   tr_acc: 1.0\n",
      "\t   val_acc: 0.611\n",
      "\t   Weighted error: 0.0, Alpha: 8.0\n",
      "\n",
      "\n",
      "# 2/5th step\n",
      "\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.8380 - acc: 0.5714 - val_loss: 1.0429 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4436 - acc: 0.7619 - val_loss: 1.1794 - val_acc: 0.6111\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4112 - acc: 0.8274 - val_loss: 0.9444 - val_acc: 0.6111\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2968 - acc: 0.8690 - val_loss: 1.0351 - val_acc: 0.6667\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2491 - acc: 0.9048 - val_loss: 1.0690 - val_acc: 0.6667\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2534 - acc: 0.8869 - val_loss: 1.0984 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2789 - acc: 0.9048 - val_loss: 1.2995 - val_acc: 0.4444\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1800 - acc: 0.9345 - val_loss: 1.2383 - val_acc: 0.5000\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2122 - acc: 0.9167 - val_loss: 2.0336 - val_acc: 0.6667\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2627 - acc: 0.9048 - val_loss: 1.1891 - val_acc: 0.5556\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2240 - acc: 0.9226 - val_loss: 1.5524 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1619 - acc: 0.9464 - val_loss: 1.5180 - val_acc: 0.6667\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1931 - acc: 0.9107 - val_loss: 2.6502 - val_acc: 0.6667\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.131 (error: 0.131)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.7424 - acc: 0.6429 - val_loss: 0.7757 - val_acc: 0.6667\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4472 - acc: 0.7976 - val_loss: 0.7314 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4263 - acc: 0.8155 - val_loss: 0.8195 - val_acc: 0.5556\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2646 - acc: 0.9167 - val_loss: 0.8724 - val_acc: 0.5556\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2195 - acc: 0.9286 - val_loss: 1.1836 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2203 - acc: 0.9107 - val_loss: 1.3604 - val_acc: 0.4444\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1769 - acc: 0.9167 - val_loss: 1.3597 - val_acc: 0.5556\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2069 - acc: 0.9286 - val_loss: 1.0717 - val_acc: 0.6111\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1999 - acc: 0.9167 - val_loss: 1.1346 - val_acc: 0.6111\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1678 - acc: 0.9464 - val_loss: 1.2766 - val_acc: 0.5556\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1168 - acc: 0.9702 - val_loss: 1.3641 - val_acc: 0.5556\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1470 - acc: 0.9464 - val_loss: 1.4546 - val_acc: 0.5556\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.0 (error: 0.0)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 0.8110 - acc: 0.6369 - val_loss: 1.3564 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.4158 - acc: 0.8095 - val_loss: 1.1771 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3099 - acc: 0.8929 - val_loss: 1.5044 - val_acc: 0.5556\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2353 - acc: 0.9048 - val_loss: 2.1354 - val_acc: 0.5556\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1593 - acc: 0.9464 - val_loss: 1.8655 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1283 - acc: 0.9583 - val_loss: 1.8664 - val_acc: 0.4444\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1077 - acc: 0.9643 - val_loss: 2.4355 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1055 - acc: 0.9643 - val_loss: 2.3260 - val_acc: 0.4444\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2041 - acc: 0.9345 - val_loss: 2.9434 - val_acc: 0.4444\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0854 - acc: 0.9643 - val_loss: 2.8078 - val_acc: 0.5556\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2509 - acc: 0.9048 - val_loss: 3.8928 - val_acc: 0.5556\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1585 - acc: 0.9345 - val_loss: 2.1675 - val_acc: 0.4444\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.012 (error: 0.012)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 0.4854 - acc: 0.7440 - val_loss: 1.3428 - val_acc: 0.3889\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1847 - acc: 0.9345 - val_loss: 1.3871 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2404 - acc: 0.8988 - val_loss: 1.2855 - val_acc: 0.5556\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1291 - acc: 0.9464 - val_loss: 1.5022 - val_acc: 0.6111\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1160 - acc: 0.9643 - val_loss: 1.4379 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1127 - acc: 0.9643 - val_loss: 1.8730 - val_acc: 0.3889\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0932 - acc: 0.9643 - val_loss: 2.2862 - val_acc: 0.5556\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2516 - acc: 0.9286 - val_loss: 1.7600 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - acc: 0.9940 - val_loss: 2.1398 - val_acc: 0.6111\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1114 - acc: 0.9643 - val_loss: 1.9704 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0808 - acc: 0.9821 - val_loss: 1.5820 - val_acc: 0.6111\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0348 - acc: 0.9881 - val_loss: 1.9187 - val_acc: 0.5556\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1049 - acc: 0.9583 - val_loss: 2.1535 - val_acc: 0.3889\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.0 (error: 0.0)\n",
      "\n",
      "\t-> Selected: OV_six_fold_CV_400\n",
      "\t   tr_acc: 1.0\n",
      "\t   val_acc: 0.556\n",
      "\t   Weighted error: 0.0, Alpha: 8.0\n",
      "\n",
      "\n",
      "# 3/5th step\n",
      "\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.7708 - acc: 0.6131 - val_loss: 1.0728 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4821 - acc: 0.7619 - val_loss: 0.9902 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4025 - acc: 0.8274 - val_loss: 0.9766 - val_acc: 0.6111\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3352 - acc: 0.8810 - val_loss: 1.0204 - val_acc: 0.6111\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3357 - acc: 0.8750 - val_loss: 1.4665 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3692 - acc: 0.8274 - val_loss: 2.9683 - val_acc: 0.6111\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2959 - acc: 0.8750 - val_loss: 1.3981 - val_acc: 0.4444\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2184 - acc: 0.9286 - val_loss: 1.6446 - val_acc: 0.6111\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1706 - acc: 0.9464 - val_loss: 1.1347 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2021 - acc: 0.9226 - val_loss: 2.7170 - val_acc: 0.6111\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1976 - acc: 0.9107 - val_loss: 2.0758 - val_acc: 0.6111\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1790 - acc: 0.9464 - val_loss: 1.6501 - val_acc: 0.4444\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2530 - acc: 0.9345 - val_loss: 1.1450 - val_acc: 0.5556\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.012 (error: 0.012)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 6s 37ms/step - loss: 0.7287 - acc: 0.6786 - val_loss: 0.8824 - val_acc: 0.6111\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4479 - acc: 0.8095 - val_loss: 0.7412 - val_acc: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3387 - acc: 0.8571 - val_loss: 0.8454 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2503 - acc: 0.9107 - val_loss: 0.8678 - val_acc: 0.5556\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1997 - acc: 0.9167 - val_loss: 1.1235 - val_acc: 0.4444\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1372 - acc: 0.9464 - val_loss: 1.3786 - val_acc: 0.5556\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1158 - acc: 0.9524 - val_loss: 1.2065 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1848 - acc: 0.9107 - val_loss: 1.5473 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1388 - acc: 0.9643 - val_loss: 1.5251 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1284 - acc: 0.9583 - val_loss: 1.2421 - val_acc: 0.5556\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0925 - acc: 0.9762 - val_loss: 1.3828 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2430 - acc: 0.8988 - val_loss: 1.4633 - val_acc: 0.5000\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.006 (error: 0.006)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 32ms/step - loss: 0.7717 - acc: 0.6012 - val_loss: 1.0640 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4931 - acc: 0.7440 - val_loss: 1.5086 - val_acc: 0.6111\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3443 - acc: 0.8631 - val_loss: 1.4248 - val_acc: 0.5556\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2719 - acc: 0.9167 - val_loss: 1.3728 - val_acc: 0.4444\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2053 - acc: 0.9286 - val_loss: 1.9421 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1827 - acc: 0.9345 - val_loss: 1.8601 - val_acc: 0.4444\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1703 - acc: 0.9286 - val_loss: 2.3226 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1583 - acc: 0.9286 - val_loss: 2.3461 - val_acc: 0.3889\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0970 - acc: 0.9702 - val_loss: 2.3165 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1557 - acc: 0.9286 - val_loss: 2.0101 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0782 - acc: 0.9762 - val_loss: 2.6820 - val_acc: 0.6111\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.0 (error: 0.0)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.5754 - acc: 0.6964 - val_loss: 1.0457 - val_acc: 0.3889\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2507 - acc: 0.9048 - val_loss: 1.2884 - val_acc: 0.3333\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1736 - acc: 0.9524 - val_loss: 1.2132 - val_acc: 0.5556\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1678 - acc: 0.9226 - val_loss: 1.6789 - val_acc: 0.4444\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1229 - acc: 0.9464 - val_loss: 1.5544 - val_acc: 0.4444\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0540 - acc: 0.9821 - val_loss: 1.7147 - val_acc: 0.4444\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0671 - acc: 0.9702 - val_loss: 2.0212 - val_acc: 0.5556\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0952 - acc: 0.9702 - val_loss: 2.9327 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0505 - acc: 0.9881 - val_loss: 2.3342 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1052 - acc: 0.9702 - val_loss: 2.2414 - val_acc: 0.2778\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2027 - acc: 0.9286 - val_loss: 2.7100 - val_acc: 0.3333\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.0 (error: 0.0)\n",
      "\n",
      "\t-> Selected: OV_six_fold_Var_400\n",
      "\t   tr_acc: 1.0\n",
      "\t   val_acc: 0.611\n",
      "\t   Weighted error: 0.0, Alpha: 8.0\n",
      "\n",
      "\n",
      "# 4/5th step\n",
      "\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.7834 - acc: 0.6310 - val_loss: 1.0415 - val_acc: 0.3333\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.5046 - acc: 0.7798 - val_loss: 1.3576 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4294 - acc: 0.8155 - val_loss: 0.9306 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3106 - acc: 0.8750 - val_loss: 1.6293 - val_acc: 0.6111\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2975 - acc: 0.8750 - val_loss: 2.4847 - val_acc: 0.6111\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2203 - acc: 0.9167 - val_loss: 2.0742 - val_acc: 0.5556\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2026 - acc: 0.9226 - val_loss: 2.0378 - val_acc: 0.5556\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1257 - acc: 0.9702 - val_loss: 1.4087 - val_acc: 0.6111\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0936 - acc: 0.9821 - val_loss: 1.3348 - val_acc: 0.3889\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1421 - acc: 0.9405 - val_loss: 3.0707 - val_acc: 0.6111\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1944 - acc: 0.9345 - val_loss: 2.3679 - val_acc: 0.6111\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2374 - acc: 0.8869 - val_loss: 2.5643 - val_acc: 0.6111\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1210 - acc: 0.9524 - val_loss: 1.5833 - val_acc: 0.6111\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.036 (error: 0.036)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 0.8186 - acc: 0.6131 - val_loss: 0.8120 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4336 - acc: 0.8036 - val_loss: 0.8762 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3859 - acc: 0.8274 - val_loss: 0.8021 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3240 - acc: 0.8750 - val_loss: 0.8633 - val_acc: 0.5556\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2322 - acc: 0.9286 - val_loss: 1.1335 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2676 - acc: 0.8869 - val_loss: 0.8720 - val_acc: 0.6111\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1486 - acc: 0.9464 - val_loss: 0.9498 - val_acc: 0.6111\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1761 - acc: 0.9405 - val_loss: 1.3204 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2038 - acc: 0.9286 - val_loss: 1.2554 - val_acc: 0.6111\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1590 - acc: 0.9464 - val_loss: 1.4145 - val_acc: 0.6111\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1179 - acc: 0.9583 - val_loss: 1.2322 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0954 - acc: 0.9643 - val_loss: 1.3963 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0667 - acc: 0.9881 - val_loss: 1.7296 - val_acc: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.0 (error: 0.0)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 6s 38ms/step - loss: 0.7626 - acc: 0.6548 - val_loss: 1.4870 - val_acc: 0.6111\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3816 - acc: 0.8333 - val_loss: 1.2073 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3354 - acc: 0.8214 - val_loss: 1.0953 - val_acc: 0.4444\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2991 - acc: 0.9048 - val_loss: 1.3612 - val_acc: 0.5556\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2076 - acc: 0.9286 - val_loss: 1.3143 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1368 - acc: 0.9524 - val_loss: 1.8642 - val_acc: 0.5556\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1583 - acc: 0.9464 - val_loss: 1.4798 - val_acc: 0.4444\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2244 - acc: 0.9107 - val_loss: 1.3263 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1803 - acc: 0.9286 - val_loss: 1.6618 - val_acc: 0.6111\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2045 - acc: 0.9167 - val_loss: 1.7229 - val_acc: 0.4444\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2176 - acc: 0.9405 - val_loss: 1.8031 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1536 - acc: 0.9524 - val_loss: 1.9619 - val_acc: 0.6111\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1099 - acc: 0.9702 - val_loss: 1.7328 - val_acc: 0.5556\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.0 (error: 0.0)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 5s 32ms/step - loss: 0.5681 - acc: 0.7679 - val_loss: 1.4336 - val_acc: 0.2778\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2648 - acc: 0.8869 - val_loss: 1.5740 - val_acc: 0.2778\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2395 - acc: 0.8988 - val_loss: 1.3019 - val_acc: 0.2222\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1473 - acc: 0.9583 - val_loss: 1.3445 - val_acc: 0.5556\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1808 - acc: 0.9345 - val_loss: 1.4374 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0898 - acc: 0.9762 - val_loss: 1.4900 - val_acc: 0.3889\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0848 - acc: 0.9643 - val_loss: 2.1286 - val_acc: 0.2778\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - acc: 0.9881 - val_loss: 2.2466 - val_acc: 0.3333\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0844 - acc: 0.9821 - val_loss: 2.4066 - val_acc: 0.3889\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1025 - acc: 0.9821 - val_loss: 2.3576 - val_acc: 0.5556\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2454 - acc: 0.9226 - val_loss: 2.3037 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1439 - acc: 0.9464 - val_loss: 2.5521 - val_acc: 0.5556\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0760 - acc: 0.9821 - val_loss: 1.7661 - val_acc: 0.6667\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.0 (error: 0.0)\n",
      "\n",
      "\t-> Selected: OV_six_fold_CV_400\n",
      "\t   tr_acc: 1.0\n",
      "\t   val_acc: 0.556\n",
      "\t   Weighted error: 0.0, Alpha: 8.0\n",
      "\n",
      "\n",
      "# 5/5th step\n",
      "\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 6s 37ms/step - loss: 0.7583 - acc: 0.6131 - val_loss: 1.0354 - val_acc: 0.6111\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.4289 - acc: 0.8393 - val_loss: 1.2336 - val_acc: 0.6111\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3279 - acc: 0.8571 - val_loss: 1.3713 - val_acc: 0.6111\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3193 - acc: 0.8631 - val_loss: 1.4602 - val_acc: 0.5556\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3522 - acc: 0.8512 - val_loss: 1.5399 - val_acc: 0.6667\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2008 - acc: 0.9286 - val_loss: 1.2189 - val_acc: 0.5556\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2678 - acc: 0.8690 - val_loss: 1.9420 - val_acc: 0.6111\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2461 - acc: 0.9048 - val_loss: 1.4090 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1972 - acc: 0.9286 - val_loss: 1.6639 - val_acc: 0.6667\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1992 - acc: 0.9345 - val_loss: 1.7851 - val_acc: 0.5556\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1296 - acc: 0.9762 - val_loss: 2.1584 - val_acc: 0.5556\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.113 (error: 0.113)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 7s 39ms/step - loss: 0.7610 - acc: 0.7083 - val_loss: 0.9135 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4452 - acc: 0.7798 - val_loss: 0.9931 - val_acc: 0.4444\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3821 - acc: 0.8393 - val_loss: 0.9266 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2787 - acc: 0.8810 - val_loss: 0.9686 - val_acc: 0.4444\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2340 - acc: 0.8929 - val_loss: 1.1387 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1826 - acc: 0.9405 - val_loss: 1.1504 - val_acc: 0.6111\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2440 - acc: 0.8929 - val_loss: 1.3010 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1846 - acc: 0.9405 - val_loss: 1.4949 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1784 - acc: 0.9464 - val_loss: 1.5195 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1756 - acc: 0.9405 - val_loss: 1.7402 - val_acc: 0.6111\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1594 - acc: 0.9524 - val_loss: 1.7314 - val_acc: 0.5000\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.0 (error: 0.0)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 6s 37ms/step - loss: 0.8210 - acc: 0.6250 - val_loss: 2.0585 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4506 - acc: 0.7738 - val_loss: 1.4001 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3484 - acc: 0.8274 - val_loss: 1.7620 - val_acc: 0.5556\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2842 - acc: 0.8512 - val_loss: 1.9742 - val_acc: 0.5556\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2249 - acc: 0.9048 - val_loss: 1.7772 - val_acc: 0.5556\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2087 - acc: 0.8988 - val_loss: 1.8578 - val_acc: 0.4444\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0981 - acc: 0.9762 - val_loss: 2.5677 - val_acc: 0.5556\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0682 - acc: 0.9881 - val_loss: 2.8431 - val_acc: 0.6111\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1148 - acc: 0.9464 - val_loss: 2.6398 - val_acc: 0.5556\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1418 - acc: 0.9524 - val_loss: 2.3401 - val_acc: 0.4444\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2209 - acc: 0.9286 - val_loss: 2.9977 - val_acc: 0.6111\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1335 - acc: 0.9583 - val_loss: 3.1298 - val_acc: 0.6111\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.012 (error: 0.012)\n",
      "Train on 168 samples, validate on 18 samples\n",
      "Epoch 1/50\n",
      "168/168 [==============================] - 6s 37ms/step - loss: 0.4664 - acc: 0.7679 - val_loss: 1.8247 - val_acc: 0.6667\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2519 - acc: 0.8810 - val_loss: 1.6253 - val_acc: 0.4444\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1628 - acc: 0.9286 - val_loss: 1.3695 - val_acc: 0.3889\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1385 - acc: 0.9464 - val_loss: 1.3692 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2581 - acc: 0.9345 - val_loss: 1.7921 - val_acc: 0.3333\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0983 - acc: 0.9702 - val_loss: 1.7132 - val_acc: 0.3333\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0547 - acc: 0.9821 - val_loss: 1.9387 - val_acc: 0.4444\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1537 - acc: 0.9464 - val_loss: 1.5850 - val_acc: 0.3889\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0650 - acc: 0.9821 - val_loss: 1.6487 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1841 - acc: 0.9762 - val_loss: 1.4857 - val_acc: 0.6111\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0960 - acc: 0.9821 - val_loss: 1.9242 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0472 - acc: 0.9881 - val_loss: 2.1423 - val_acc: 0.3889\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0378 - acc: 0.9881 - val_loss: 2.3085 - val_acc: 0.3889\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0892 - acc: 0.9821 - val_loss: 2.3981 - val_acc: 0.4444\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.0 (error: 0.0)\n",
      "\n",
      "\t-> Selected: OV_six_fold_CV_400\n",
      "\t   tr_acc: 1.0\n",
      "\t   val_acc: 0.5\n",
      "\t   Weighted error: 0.0, Alpha: 8.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.array([1/tr_x_1.shape[0]]*tr_x_1.shape[0])\n",
    "model_list = []\n",
    "alpha_list = []\n",
    "type_num_list = []\n",
    "sample_weight_list = []\n",
    "error_list = []\n",
    "\n",
    "for step in range(max_model_num):\n",
    "    print(\"# \"+str(step+1)+\"/\"+str(max_model_num)+\"th step\\n\")\n",
    "    best_model = 0\n",
    "    best_weighted_errors = 0\n",
    "    best_weighted_error_sum = -1\n",
    "    best_alpha = 0\n",
    "    best_type_num = 0\n",
    "    best_tr_acc = 0\n",
    "    best_error = 0\n",
    "    \n",
    "    for t in range(4):\n",
    "        \n",
    "        tr_x = tr_x_list[t]\n",
    "        tr_y = tr_y_list[t]\n",
    "        val_x = val_x_list[t]\n",
    "        val_y = val_y_list[t]\n",
    "        #print(tr_x.iloc[:2][:2])\n",
    "\n",
    "        model_t = train_NN_model(tr_x_val=tr_x, tr_y_val=tr_y, val_x_val=val_x, val_y_val=val_y, n_epoch=50)\n",
    "        pred_Y = model_performance(using_model = model_t, tr_x_val=tr_x, tr_y_val=tr_y, output_list=[\"labeled_tr_predictions\"])\n",
    "        #if pred_Y is 0 or 1, all weighted predict Y of 0 samples will be just 0\n",
    "        pred_Y_proc = pred_Y*2-1\n",
    "        Y_proc = np.array(tr_y)*2-1\n",
    "        error = abs(Y_proc - pred_Y_proc)/2\n",
    "        error_sum = np.sum(error)\n",
    "        weighted_errors = sample_weight*error.T\n",
    "        weighted_error_sum = np.sum(weighted_errors)\n",
    "        print(\"Weighted error of \"+types[t]+\":\\n\\t\"+str(weighted_error_sum.round(3))+\" (error: \"+str((error_sum/tr_x_1.shape[0]).round(3))+\")\")\n",
    "        \n",
    "        if best_weighted_error_sum == -1 or best_weighted_error_sum > weighted_error_sum:\n",
    "            #print(error)\n",
    "            #print(weighted_errors)\n",
    "            \n",
    "            best_model = model_t\n",
    "            best_error = error\n",
    "            best_weighted_errors = weighted_errors\n",
    "            best_weighted_error_sum = np.sum(weighted_errors)\n",
    "            best_alpha = math.log((1-min(best_weighted_error_sum, (1-math.exp(-16))))/max(best_weighted_error_sum, math.exp(-16)))/2\n",
    "            best_type_num = t\n",
    "            best_tr_acc = model_t.evaluate(tr_x, tr_y, verbose = 0)[1]\n",
    "            best_val_acc = model_t.evaluate(val_x, val_y, verbose = 0)[1]\n",
    "\n",
    "\n",
    "    print(\"\\n\\t-> Selected: \"+types[best_type_num])\n",
    "    print(\"\\t   tr_acc: \"+str(best_tr_acc.round(3)))\n",
    "    print(\"\\t   val_acc: \"+str(best_val_acc.round(3)))\n",
    "    print(\"\\t   Weighted error: \"+str(best_weighted_error_sum.round(3))+\", Alpha: \"+str(np.float64(best_alpha).round(3))+\"\\n\\n\")\n",
    "    error_term = (best_error*2)-1\n",
    "    updated_weight = sample_weight*np.exp((-1)*best_alpha*error_term).T\n",
    "    sample_weight = updated_weight / np.sum(updated_weight)\n",
    "    \n",
    "    model_list.append(best_model)\n",
    "    alpha_list.append(best_alpha)\n",
    "    type_num_list.append(best_type_num)\n",
    "    sample_weight_list.append(sample_weight)\n",
    "    error_list.append(best_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *AdaBoost Using Weight of Validation Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1/5th step\n",
      "\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.389 (error: 0.389)\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.444 (error: 0.444)\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.444 (error: 0.444)\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.389 (error: 0.389)\n",
      "\n",
      "\t-> Selected: OV_six_fold_Annotation3000_400\n",
      "\t   tr_acc: 0.952\n",
      "\t   val_acc: 0.611\n",
      "\t   Weighted error: 0.389, Alpha: 0.226\n",
      "\n",
      "\n",
      "# 2/5th step\n",
      "\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.312 (error: 0.389)\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.359 (error: 0.389)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method ScopedTFStatus.__del__ of <tensorflow.python.framework.c_api_util.ScopedTFStatus object at 0x0000020A4BF116A0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 37, in __del__\n",
      "    c_api.TF_DeleteStatus(self.status)\n",
      "AttributeError: 'ScopedTFStatus' object has no attribute 'status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.441 (error: 0.5)\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.441 (error: 0.5)\n",
      "\n",
      "\t-> Selected: OV_six_fold_Annotation3000_400\n",
      "\t   tr_acc: 0.982\n",
      "\t   val_acc: 0.611\n",
      "\t   Weighted error: 0.312, Alpha: 0.396\n",
      "\n",
      "\n",
      "# 3/5th step\n",
      "\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.263 (error: 0.444)\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.374 (error: 0.444)\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.58 (error: 0.611)\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.474 (error: 0.556)\n",
      "\n",
      "\t-> Selected: OV_six_fold_Annotation3000_400\n",
      "\t   tr_acc: 0.869\n",
      "\t   val_acc: 0.556\n",
      "\t   Weighted error: 0.263, Alpha: 0.516\n",
      "\n",
      "\n",
      "# 4/5th step\n",
      "\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.103 (error: 0.389)\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.341 (error: 0.444)\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.521 (error: 0.667)\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.508 (error: 0.5)\n",
      "\n",
      "\t-> Selected: OV_six_fold_Annotation3000_400\n",
      "\t   tr_acc: 0.911\n",
      "\t   val_acc: 0.611\n",
      "\t   Weighted error: 0.103, Alpha: 1.083\n",
      "\n",
      "\n",
      "# 5/5th step\n",
      "\n",
      "Weighted error of OV_six_fold_Annotation3000_400:\n",
      "\t0.269 (error: 0.444)\n",
      "Weighted error of OV_six_fold_CV_400:\n",
      "\t0.319 (error: 0.5)\n",
      "Weighted error of OV_six_fold_Var_400:\n",
      "\t0.226 (error: 0.444)\n",
      "Weighted error of OV_six_fold_new_Diff_400:\n",
      "\t0.329 (error: 0.556)\n",
      "\n",
      "\t-> Selected: OV_six_fold_Var_400\n",
      "\t   tr_acc: 0.988\n",
      "\t   val_acc: 0.556\n",
      "\t   Weighted error: 0.226, Alpha: 0.615\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.array([1/val_x_1.shape[0]]*val_x_1.shape[0])\n",
    "model_list = []\n",
    "alpha_list = []\n",
    "type_num_list = []\n",
    "sample_weight_list = []\n",
    "error_list = []\n",
    "\n",
    "for step in range(max_model_num):\n",
    "    print(\"# \"+str(step+1)+\"/\"+str(max_model_num)+\"th step\\n\")\n",
    "    best_model = 0\n",
    "    best_weighted_errors = 0\n",
    "    best_weighted_error_sum = -1\n",
    "    best_alpha = 0\n",
    "    best_type_num = 0\n",
    "    best_tr_acc = 0\n",
    "    best_val_acc = 0\n",
    "    best_error = 0\n",
    "    \n",
    "    for t in range(4):\n",
    "        \n",
    "        tr_x = tr_x_list[t]\n",
    "        tr_y = tr_y_list[t]\n",
    "        val_x = val_x_list[t]\n",
    "        val_y = val_y_list[t]\n",
    "        #print(tr_x.iloc[:2][:2])\n",
    "\n",
    "        model_t = train_NN_model(tr_x_val=tr_x, tr_y_val=tr_y, val_x_val=val_x, val_y_val=val_y, n_epoch=50)\n",
    "        pred_Y = model_performance(using_model = model_t, tr_x_val=val_x, tr_y_val=val_y, output_list=[\"labeled_tr_predictions\"])\n",
    "        #if pred_Y is 0 or 1, all weighted predict Y of 0 samples will be just 0\n",
    "        pred_Y_proc = pred_Y*2-1\n",
    "        Y_proc = np.array(val_y)*2-1\n",
    "        error = abs(Y_proc - pred_Y_proc)/2\n",
    "        error_sum = np.sum(error)\n",
    "        weighted_errors = sample_weight*error.T\n",
    "        weighted_error_sum = np.sum(weighted_errors)\n",
    "        print(\"Weighted error of \"+types[t]+\":\\n\\t\"+str(weighted_error_sum.round(3))+\" (error: \"+str((error_sum/val_x_1.shape[0]).round(3))+\")\")\n",
    "        \n",
    "        if best_weighted_error_sum == -1 or best_weighted_error_sum > weighted_error_sum:\n",
    "            #print(error)\n",
    "            #print(weighted_errors)\n",
    "            \n",
    "            best_model = model_t\n",
    "            best_error = error\n",
    "            best_weighted_errors = weighted_errors\n",
    "            best_weighted_error_sum = np.sum(weighted_errors)\n",
    "            best_alpha = math.log((1-min(best_weighted_error_sum, (1-math.exp(-16))))/max(best_weighted_error_sum, math.exp(-16)))/2\n",
    "            best_type_num = t\n",
    "            best_tr_acc = model_t.evaluate(tr_x, tr_y, verbose = 0)[1]\n",
    "            best_val_acc = model_t.evaluate(val_x, val_y, verbose = 0)[1]\n",
    "\n",
    "\n",
    "    print(\"\\n\\t-> Selected: \"+types[best_type_num])\n",
    "    print(\"\\t   tr_acc: \"+str(best_tr_acc.round(3)))\n",
    "    print(\"\\t   val_acc: \"+str(best_val_acc.round(3)))\n",
    "    print(\"\\t   Weighted error: \"+str(best_weighted_error_sum.round(3))+\", Alpha: \"+str(np.float64(best_alpha).round(3))+\"\\n\\n\")\n",
    "    error_term = (best_error*2)-1\n",
    "    updated_weight = sample_weight*np.exp((-1)*best_alpha*error_term).T\n",
    "    sample_weight = updated_weight / np.sum(updated_weight)\n",
    "    \n",
    "    model_list.append(best_model)\n",
    "    alpha_list.append(best_alpha)\n",
    "    type_num_list.append(best_type_num)\n",
    "    sample_weight_list.append(sample_weight)\n",
    "    error_list.append(best_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OV_six_fold_Annotation3000_400: 4\n",
      "OV_six_fold_CV_400: 0\n",
      "OV_six_fold_Var_400: 1\n",
      "OV_six_fold_new_Diff_400: 0\n"
     ]
    }
   ],
   "source": [
    "for k in range(4):\n",
    "    print(types[k]+\": \"+str(type_num_list.count(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th best model is OV_six_fold_Annotation3000_400\n",
      "# 1 th model: OV_six_fold_Annotation3000_400\n",
      "tr_acc: 0.9523809523809523\n",
      "ts_acc: 0.6774193644523621\n",
      "tr_acc_tot: 0.9523809523809523\n",
      "ts_acc_tot: 0.6774193548387097\n",
      "\n",
      "2th best model is OV_six_fold_Annotation3000_400\n",
      "# 2 th model: OV_six_fold_Annotation3000_400\n",
      "tr_acc: 0.9821428571428571\n",
      "ts_acc: 0.6774193644523621\n",
      "tr_acc_tot: 0.9821428571428571\n",
      "ts_acc_tot: 0.6774193548387097\n",
      "\n",
      "3th best model is OV_six_fold_Annotation3000_400\n",
      "# 3 th model: OV_six_fold_Annotation3000_400\n",
      "tr_acc: 0.8690476190476191\n",
      "ts_acc: 0.6774193644523621\n",
      "tr_acc_tot: 0.9583333333333334\n",
      "ts_acc_tot: 0.6774193548387097\n",
      "\n",
      "4th best model is OV_six_fold_Annotation3000_400\n",
      "# 4 th model: OV_six_fold_Annotation3000_400\n",
      "tr_acc: 0.9107142857142857\n",
      "ts_acc: 0.6774193644523621\n",
      "tr_acc_tot: 0.9464285714285714\n",
      "ts_acc_tot: 0.6451612903225806\n",
      "\n",
      "5th best model is OV_six_fold_Var_400\n",
      "# 5 th model: OV_six_fold_Var_400\n",
      "tr_acc: 0.9880952380952381\n",
      "ts_acc: 0.4838709533214569\n",
      "tr_acc_tot: 0.9523809523809523\n",
      "ts_acc_tot: 0.6774193548387097\n",
      "\n",
      "####################### Final acc: 0.9523809523809523, 0.6774193548387097\n"
     ]
    }
   ],
   "source": [
    "tr_sum = 0\n",
    "ts_sum = 0\n",
    "alpha_sum = 0\n",
    "\n",
    "for m in range(len(model_list)):\n",
    "    b = type_num_list[m]\n",
    "    best_type = types[b]\n",
    "    print(str(m+1)+\"th best model is \"+best_type)\n",
    "    [tr_x, tr_y, ts_x, ts_y] = [tr_x_list[b], tr_y_list[b], ts_x_list[b], ts_y_list[b]]\n",
    "    print(\"# \"+str(m+1)+\" th model: \"+best_type)\n",
    "    tr_pred_Y = np.array(model_performance(using_model = model_list[m], tr_x_val=tr_x, tr_y_val=tr_y, ts_x_val=ts_x, ts_y_val=ts_y, output_list=[\"labeled_tr_predictions\"]))\n",
    "    ts_pred_Y = np.array(model_performance(using_model = model_list[m], tr_x_val=tr_x, tr_y_val=tr_y, ts_x_val=ts_x, ts_y_val=ts_y, output_list=[\"labeled_ts_predictions\"]))\n",
    "    tr_acc, ts_acc = np.array(model_performance(using_model = model_list[m], tr_x_val=tr_x, tr_y_val=tr_y, ts_x_val=ts_x, ts_y_val=ts_y, output_list=[\"tr_accuracy\", \"ts_accuracy\"]))\n",
    "    best_val_acc = model_t.evaluate(val_x, val_y, verbose = 0)[1]\n",
    "    \n",
    "    print(\"tr_acc: \"+str(tr_acc))\n",
    "    print(\"ts_acc: \"+str(ts_acc))\n",
    "\n",
    "    tr_pred_Y_proc = tr_pred_Y*2 -1 \n",
    "    ts_pred_Y_proc = ts_pred_Y*2 -1\n",
    "    \n",
    "    #print(tr_pred_Y)\n",
    "    #print(tr_pred_Y_proc)\n",
    "    \n",
    "    tr_sum = tr_sum + alpha_list[m]*tr_pred_Y_proc\n",
    "    ts_sum = ts_sum + alpha_list[m]*ts_pred_Y_proc\n",
    "    alpha_sum = alpha_sum + alpha_list[m]\n",
    "    \n",
    "    tr_sum_tot = np.where(tr_sum / alpha_sum > 0, 1, 0).flatten()\n",
    "    ts_sum_tot = np.where(ts_sum / alpha_sum > 0, 1, 0).flatten()\n",
    "    \n",
    "    tr_acc_tot = 1 - np.sum(np.abs(tr_sum_tot - np.asarray(tr_y))) / tr_sum_tot.shape[0]\n",
    "    ts_acc_tot = 1 - np.sum(np.abs(ts_sum_tot - np.asarray(ts_y))) / ts_sum_tot.shape[0]\n",
    "\n",
    "    print(\"tr_acc_tot: \"+str(tr_acc_tot))\n",
    "    print(\"ts_acc_tot: \"+str(ts_acc_tot)+\"\\n\")\n",
    "    \n",
    "    \n",
    "print(\"####################### Final acc: \"+str(tr_acc_tot)+\", \"+str(ts_acc_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
