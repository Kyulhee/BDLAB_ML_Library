{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Input, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, load_model, Sequential \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Functions library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide raw data into train / test & x_val / y_val\n",
    "def data_split(raw_data, index_col, test_index):\n",
    "    \n",
    "    train_data = raw_data.iloc[list(raw_data.iloc[:,index_col]!=test_index)]\n",
    "    test_data = raw_data.iloc[list(raw_data.iloc[:,index_col]==test_index)]\n",
    "    \n",
    "    y_val = train_data.Platinum_Status\n",
    "    x_val = train_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val = test_data.Platinum_Status\n",
    "    test_x_val = test_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    return train_data, test_data, y_val, x_val, test_y_val, test_x_val\n",
    "\n",
    "    # raw_data: have gene_expressions(maybe multiple columns), index column, Platinum_Status column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all of model performance \n",
    "# - predictions(probability) / labeled predictions(0/1) / Loss / Accuracy / Sensitivity / Specificity / AUC values of Train / Test dataset.\n",
    "# using trained models, or you can put predictions(probability) passively(in this case, Loss & Accuracy do not provided.)\n",
    "def model_performance(information=False, Input_Prediction_Passively=False, using_model=None, tr_predictions=None, ts_predictions=None, tr_x_val=None, tr_y_val=None, ts_x_val=None, ts_y_val=None, output_list=None):\n",
    "    \n",
    "    if information == True:            \n",
    "        print(\"options model_performance:\\n1) using_model: keras models that you want to check performance. \\\"Input_Prediction_Passive\\\" option for input prediction list instead using models.\\n3) tr_predictions & ts_predictions: prediction input passively. put this data only when not using keras model.\\n4) tr_x_val & ts_x_val: input samples of train/test samples.\\n4) tr_y_val & ts_y_val: results of train/test samples.\\n5) output_list: return values that you want to recieve.\\n CAUTION: Essential variable.\\n\\t tr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\\n\\n* CAUTION: if 'None' value is returned, please check your input tr inputs(None value for tr outputs) or ts inputs(None value for ts outputs).\") \n",
    "        return 0\n",
    "    elif information != False:\n",
    "        print(\"for using information options, please set 'information' variable for 'True'\")\n",
    "        return -1\n",
    "    \n",
    "    if using_model is None:\n",
    "        if Input_Prediction_Passively == False:\n",
    "            print(\"ERROR: There are no models for using.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\") \n",
    "            return -1\n",
    "        elif (tr_predictions is None) and (ts_predictions is None): # No model/prediction input. no performance should be calculated.\n",
    "                print(\"ERROR: Input prediction list instead using saved model.\")\n",
    "                return -1\n",
    "        else: # No model input, but Input_Prediction_Passively is True & input prediction is valid.\n",
    "            tr_loss,tr_accuracy= None, None\n",
    "            ts_loss,ts_accuracy= None, None\n",
    "            \n",
    "    elif Input_Prediction_Passively == True: # both of model/prediction putted, could cause confusing.\n",
    "        ch = input(\"You put both model and prediction. Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "        while 1:\n",
    "            if ch == 'p':\n",
    "                using_model = None\n",
    "                break\n",
    "            elif ch == 'm':\n",
    "                tr_predictions = None\n",
    "                ts_predictions = None\n",
    "                break\n",
    "            elif ch == 'e':\n",
    "                return 0\n",
    "            else:\n",
    "                print(\"you put worng option: \"+str(ch))\n",
    "            ch = input(\"Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "                \n",
    "    if output_list is None:\n",
    "        print(\"ERROR: There are no output_list for return.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\")\n",
    "        return -1\n",
    "    \n",
    "    if not(tr_x_val is None) and not(tr_y_val is None):\n",
    "        # predict tr result only when no tr_prediction input\n",
    "        if tr_predictions is None:\n",
    "            tr_loss,tr_accuracy= using_model.evaluate(tr_x_val,tr_y_val)\n",
    "            tr_predictions = using_model.predict(tr_x_val)\n",
    "        # tr sensitivity / specificity\n",
    "        labeled_tr_predictions = np.where(tr_predictions > 0.5, 1, 0).flatten()\n",
    "        tr_sensitivity, tr_specificity = check_correct(labeled_tr_predictions, tr_y_val)\n",
    "        tr_predictions_flat = tr_predictions[:,0]   \n",
    "        # roc(tr)\n",
    "        fpr_tr, tpr_tr, threshold_tr = metrics.roc_curve(tr_y_val, tr_predictions)\n",
    "        roc_auc_tr = metrics.auc(fpr_tr, tpr_tr)\n",
    "    \n",
    "    if not(ts_x_val is None) and not(ts_y_val is None):\n",
    "        # predict ts result only when no ts_prediction input\n",
    "        if ts_predictions is None:\n",
    "            ts_loss,ts_accuracy= using_model.evaluate(ts_x_val,ts_y_val)\n",
    "            ts_predictions = using_model.predict(ts_x_val)\n",
    "        labeled_ts_predictions = np.where(ts_predictions > 0.5, 1, 0).flatten()\n",
    "        ts_sensitivity, ts_specificity = check_correct(labeled_ts_predictions, ts_y_val)\n",
    "        ts_predictions_flat = ts_predictions[:,0]   \n",
    "        # roc(ts)\n",
    "        fpr_ts, tpr_ts, threshold_ts = metrics.roc_curve(ts_y_val, ts_predictions)\n",
    "        roc_auc_ts = metrics.auc(fpr_ts, tpr_ts)    \n",
    "    \n",
    "    if (not(tr_x_val is None) and not(tr_y_val is None)) and (not(ts_x_val is None) and not(ts_y_val is None)):\n",
    "        y_true = np.append(tr_y_val, ts_y_val)\n",
    "        y_pred = np.append(tr_predictions, ts_predictions)\n",
    "        fpr_total, tpr_total, threshold_total = metrics.roc_curve(y_true, y_pred)\n",
    "        roc_auc_total = metrics.auc(fpr_total, tpr_total)\n",
    "        \n",
    "        \n",
    "    return_list = []\n",
    "    \n",
    "    for output in output_list:\n",
    "        \n",
    "        if(output == \"tr_loss\"):\n",
    "            return_list.append(tr_loss)\n",
    "                               \n",
    "        elif(output == \"tr_accuracy\"):\n",
    "            return_list.append(tr_accuracy)\n",
    "                               \n",
    "        elif(output == \"tr_sensitivity\"):\n",
    "            return_list.append(tr_sensitivity)\n",
    "                               \n",
    "        elif(output == \"tr_specificity\"):\n",
    "            return_list.append(tr_specificity)\n",
    "                               \n",
    "        elif(output == \"tr_predictions\"):\n",
    "            return_list.append(tr_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_tr_predictions\"):\n",
    "            return_list.append(labeled_tr_predictions)\n",
    "                               \n",
    "        elif(output == \"tr_predictions_flat\"):\n",
    "            return_list.append(tr_predictions_flat)\n",
    "            \n",
    "        elif(output == \"roc_auc_tr\"):\n",
    "            return_list.append(roc_auc_tr)\n",
    "\n",
    "        elif(output == \"ts_loss\"):\n",
    "            return_list.append(ts_loss)\n",
    "                               \n",
    "        elif(output == \"ts_accuracy\"):\n",
    "            return_list.append(ts_accuracy)\n",
    "                               \n",
    "        elif(output == \"ts_sensitivity\"):\n",
    "            return_list.append(ts_sensitivity)\n",
    "                               \n",
    "        elif(output == \"ts_specificity\"):\n",
    "            return_list.append(ts_specificity)\n",
    "                               \n",
    "        elif(output == \"ts_predictions\"):\n",
    "            return_list.append(ts_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_ts_predictions\"):\n",
    "            return_list.append(labeled_ts_predictions)\n",
    "                               \n",
    "        elif(output == \"ts_predictions_flat\"):\n",
    "            return_list.append(ts_predictions_flat)\n",
    "        \n",
    "        elif(output == \"roc_auc_ts\"):\n",
    "            return_list.append(roc_auc_ts)\n",
    "            \n",
    "        elif(output == \"roc_auc_total\"):\n",
    "            return_list.append(roc_auc_total)\n",
    "                               \n",
    "        else:\n",
    "            print(\"There are no options <\"+str(output)+\">. Please refer these output options:\\ntr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\")\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage algorithm\n",
    "def ensemble_coverage(inputModels,x,y):\n",
    "    \n",
    "    outputModels = []\n",
    "    modelInfo = []\n",
    "    coverageTotal= [False]*len(y)\n",
    "    \n",
    "    for i in range(len(inputModels)):\n",
    "        m = inputModels[i]\n",
    "        yHat = m.predict(x[i])\n",
    "        yHat = [round(i) for [i] in yHat]\n",
    "        \n",
    "        loss, acc = m.evaluate(x[i],y[i])\n",
    "        modelInfo.append((m,yHat,acc))\n",
    "        print(yHat[0:10])\n",
    "        print(acc)\n",
    "    \n",
    "    modelInfo.sort(key=lambda x : x[2],reverse=True)\n",
    "    print(modelInfo)\n",
    "    \n",
    "    i = 0\n",
    "    y = y[i]\n",
    "    for m,yHat,acc in modelInfo:\n",
    "        beforeCoverage = sum(coverageTotal)\n",
    "        coverage = [a == b for a,b in zip(y,yHat)]\n",
    "        coverageTotal = [a or b for a,b in zip(coverageTotal,coverage)]\n",
    "        afterCoverage = sum(coverageTotal)\n",
    "        \n",
    "        print(afterCoverage/len(y))\n",
    "        \n",
    "        if afterCoverage > beforeCoverage:\n",
    "            outputModels.append(m)\n",
    "            print(\"Increased Coverage : model added!\")\n",
    "        else:\n",
    "            print(\"Same Coverage : model not added\")\n",
    "        if afterCoverage == len(y):\n",
    "            print(\"Fully Covered!\")\n",
    "            break\n",
    "        \n",
    "        i=i+1\n",
    "                \n",
    "    return outputModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 90us/step\n",
      "[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "1.0\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
      "0.9672131147540983\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "0.9262295033110947\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "0.8852459035935949\n",
      "[(<keras.engine.training.Model object at 0x00000236BEE59278>, [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], 1.0), (<keras.engine.training.Model object at 0x00000236BEE59160>, [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], 0.9672131147540983), (<keras.engine.training.Model object at 0x00000236BF8D7908>, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], 0.9262295033110947), (<keras.engine.training.Model object at 0x00000236BEE59208>, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], 0.8852459035935949)]\n",
      "0.03278688524590164\n",
      "Increased Coverage : model added!\n",
      "0.03278688524590164\n",
      "Same Coverage : model not added\n",
      "0.03278688524590164\n",
      "Same Coverage : model not added\n",
      "0.03278688524590164\n",
      "Same Coverage : model not added\n"
     ]
    }
   ],
   "source": [
    "#e_models_select = ensemble_coverage(model_list,inter_dataset[\"tr_x_val\"],inter_dataset[\"tr_y_val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation: import & preprocessing data + import module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input path & name of models / raw data for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test index: 2\n"
     ]
    }
   ],
   "source": [
    "# change model_path & each model_name.\n",
    "# Caution: If you want to change input models, you also have to change selected data types.\n",
    "\n",
    "# ex) if you want to put these models: two CV, one Annot_3000,  one Var, one new_Diff, one Clin.\n",
    "\n",
    "'''\n",
    "\n",
    "m_1_name = CV_400_1.h5\n",
    "m_2_name = CV_400_2.h5\n",
    "m_3_name = Annot_3000_400_1.h5\n",
    "m_4_name = Var_400_0.h5\n",
    "m_5_name = new_Diff_400_2.h5\n",
    "m_6_name = Clin_400_1.h5\n",
    "--> if you change this part,\n",
    "\n",
    "select_types = [types[1], # \"inter_by_names_CV_400\"\n",
    "                types[1], # \"inter_by_names_CV_400\"\n",
    "                types[0], # \"inter_by_names_Annotation3000_400\"\n",
    "                types[2], # \"inter_by_names_Var_400\"\n",
    "                types[3], # \"inter_by_names_new_Diff_400\"\n",
    "                types[4]] # \"inter_by_names_Clin\"\n",
    "--> you also have to change this part.\n",
    "\n",
    "'''\n",
    "\n",
    "types = [\"OV_six_fold_Annotation3000_400\", \n",
    "         \"OV_six_fold_CV_400\", \n",
    "         \"OV_six_fold_Var_400\", \"OV_six_fold_new_Diff_400\",\n",
    "         \"OV_six_fold_Clin\", \n",
    "         \"OV_six_fold_SNV\" \n",
    "         ]\n",
    "\n",
    "ch = input(\"test index: \")\n",
    "ts_i = int(ch)\n",
    "\n",
    "# input model path & ensemble data(Transcriptome, Cinical Information, Somatic Mutation data)\n",
    "# data path(server): /home/tjahn/TCGA_Ovary/01.Data/DNN/TC_intersect_subsamples_by_names \n",
    "model_path = \"C:/test/temp/test_\"+str(ts_i)+\"/\"\n",
    "path = \"C:/test/TC_six_fold_subsamples/\"\n",
    "save_model_path = \"C:/test/temp/model/\"\n",
    "save_prediction_path = \"C:/test/temp/predictions/\"\n",
    "\n",
    "model_names = []\n",
    "model_index = []\n",
    "files = os.listdir(model_path)\n",
    "\n",
    "for f in files:\n",
    "    ext= os.path.splitext(f)[-1]\n",
    "    if ext == \".h5\":\n",
    "        model_names.append(f)\n",
    "        ind = int(f.split(\"_\")[1].split(\"-\")[0])\n",
    "        model_index.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_1-2_16.h5\n",
      "OV_six_fold_CV_400\n",
      "\n",
      "m_1-2_6.h5\n",
      "OV_six_fold_CV_400\n",
      "\n",
      "m_3-2.h5\n",
      "OV_six_fold_new_Diff_400\n",
      "\n",
      "m_4-2_56.h5\n",
      "OV_six_fold_Clin\n",
      "\n",
      "m_4-2_58.h5\n",
      "OV_six_fold_Clin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for model_i in model_index:\n",
    "    print(model_names[t])\n",
    "    print(types[model_i]+\"\\n\")\n",
    "    t = t+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### test index is [2] ###############\n",
      "\n",
      "\n",
      "1\n",
      "[0]: m_1-2_16.h5 for type: OV_six_fold_CV_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "1\n",
      "[1]: m_1-2_6.h5 for type: OV_six_fold_CV_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "3\n",
      "[2]: m_3-2.h5 for type: OV_six_fold_new_Diff_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "4\n",
      "[3]: m_4-2_56.h5 for type: OV_six_fold_Clin.\n",
      " full tr & ts: (256, 35), (31, 35)\n",
      "\n",
      "4\n",
      "[4]: m_4-2_58.h5 for type: OV_six_fold_Clin.\n",
      " full tr & ts: (256, 35), (31, 35)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_1 = path+types[0]+\".csv\"\n",
    "file_2 = path+types[1]+\".csv\"\n",
    "file_3 = path+types[2]+\".csv\"\n",
    "file_4 = path+types[3]+\".csv\"\n",
    "file_5 = path+types[4]+\".csv\"\n",
    "file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "full_data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "full_data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "full_data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "full_data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "full_data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "full_data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "inter_data_1 = full_data_1.iloc[list(full_data_1.iloc[:,-1]!=6)]\n",
    "inter_data_2 = full_data_2.iloc[list(full_data_2.iloc[:,-1]!=6)]\n",
    "inter_data_3 = full_data_3.iloc[list(full_data_3.iloc[:,-1]!=6)]\n",
    "inter_data_4 = full_data_4.iloc[list(full_data_4.iloc[:,-1]!=6)]\n",
    "inter_data_5 = full_data_5.iloc[list(full_data_5.iloc[:,-1]!=6)]\n",
    "inter_data_6 = full_data_6.iloc[list(full_data_6.iloc[:,-1]!=6)]\n",
    "\n",
    "full_ds_list = [full_data_1, full_data_2, full_data_3, full_data_4, full_data_5, full_data_6]\n",
    "inter_ds_list = [inter_data_1, inter_data_2, inter_data_3, inter_data_4, inter_data_5, inter_data_6]\n",
    "\n",
    "# Split Train Test Data & Make full & inter dataset\n",
    "\n",
    "full_dataset = {\"tr_data\":[], \"ts_data\":[], \"tr_y_val\":[], \"tr_x_val\":[], \"ts_y_val\":[], \"ts_x_val\":[]}\n",
    "inter_dataset = {\"tr_data\":[], \"ts_data\":[], \"tr_y_val\":[], \"tr_x_val\":[], \"ts_y_val\":[], \"ts_x_val\":[]}\n",
    "\n",
    "print(\"############### test index is [\"+str(ts_i)+\"] ###############\\n\\n\")\n",
    "for m in range(len(model_index)):\n",
    "    print(model_index[m])\n",
    "    full_tr_data, full_ts_data, full_tr_y_val, full_tr_x_val, full_ts_y_val, full_ts_x_val = data_split(raw_data = full_ds_list[model_index[m]], index_col = -1, test_index = ts_i)\n",
    "    print(\"[\"+str(m)+\"]: \"+model_names[m]+\" for type: \"+types[model_index[m]]+\".\\n full tr & ts: \"+str(full_tr_x_val.shape)+\", \"+str(full_ts_x_val.shape)+\"\\n\")\n",
    "    full_dataset['tr_data'].append(full_tr_data)\n",
    "    full_dataset['ts_data'].append(full_ts_data)\n",
    "    full_dataset['tr_x_val'].append(full_tr_x_val)\n",
    "    full_dataset['tr_y_val'].append(full_tr_y_val)\n",
    "    full_dataset['ts_x_val'].append(full_ts_x_val)\n",
    "    full_dataset['ts_y_val'].append(full_ts_y_val)  \n",
    "    inter_tr_data, inter_ts_data, inter_tr_y_val, inter_tr_x_val, inter_ts_y_val, inter_ts_x_val = data_split(raw_data = inter_ds_list[model_index[m]], index_col = -1, test_index = ts_i)\n",
    "    inter_dataset['tr_data'].append(inter_tr_data)\n",
    "    inter_dataset['ts_data'].append(inter_ts_data)\n",
    "    inter_dataset['tr_x_val'].append(inter_tr_x_val)\n",
    "    inter_dataset['tr_y_val'].append(inter_tr_y_val)\n",
    "    inter_dataset['ts_x_val'].append(inter_ts_x_val)\n",
    "    inter_dataset['ts_y_val'].append(inter_ts_y_val)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import separate models & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 2s 20ms/step\n",
      "31/31 [==============================] - 0s 194us/step\n",
      "\n",
      "model: m_1-2_16.h5\n",
      "tr & ts for inter data: 1.0, 0.8064516186714172\n",
      "\n",
      "122/122 [==============================] - 3s 21ms/step\n",
      "31/31 [==============================] - 0s 129us/step\n",
      "\n",
      "model: m_1-2_6.h5\n",
      "tr & ts for inter data: 0.9918032786885246, 0.774193525314331\n",
      "\n",
      "122/122 [==============================] - 2s 19ms/step\n",
      "31/31 [==============================] - 0s 161us/step\n",
      "\n",
      "model: m_3-2.h5\n",
      "tr & ts for inter data: 1.0, 0.8709677457809448\n",
      "\n",
      "122/122 [==============================] - 3s 22ms/step\n",
      "31/31 [==============================] - 0s 129us/step\n",
      "\n",
      "model: m_4-2_56.h5\n",
      "tr & ts for inter data: 0.9836065573770492, 0.774193525314331\n",
      "\n",
      "122/122 [==============================] - 3s 22ms/step\n",
      "31/31 [==============================] - 0s 161us/step\n",
      "\n",
      "model: m_4-2_58.h5\n",
      "tr & ts for inter data: 1.0, 0.774193525314331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model load & evaluation. <model_n_l> is full-layer model, <model_n_l_new> is without-sigmoid-layer model.\n",
    "'''\n",
    "Each model's tr_accuracy can be differ to original model, but ts_accuracy should be same to original tested models.\n",
    "Because we using full-size data(about 200 patients data used Transcriptome, Clinical, SNV models.) for train each models.\n",
    "In contrast, in this code, we using ensemble-input data(intersected 153 patients).\n",
    "For-training-patients may be different in ensemble data and whole size data, but for-test-patients are the same.\n",
    "'''\n",
    "\n",
    "model_list = []\n",
    "model_output_list = {\"tr_accuracy\":[], \"tr_sensitivity\":[], \"tr_specificity\":[], \"tr_predictions\":[],\n",
    "                 \"labeled_tr_predictions\":[], \"tr_predictions_flat\":[], \"roc_auc_tr\":[], \n",
    "                 \"ts_accuracy\":[], \"ts_sensitivity\":[], \"ts_specificity\":[], \"ts_predictions\":[],\n",
    "                 \"labeled_ts_predictions\":[], \"ts_predictions_flat\":[], \"roc_auc_ts\":[], \n",
    "                 \"roc_auc_total\":[], \"tr_result\":[], \"ts_result\":[]}\n",
    "tr_predictions = []\n",
    "ts_predictions = []\n",
    "\n",
    "for m in range(len(model_names)):\n",
    "    \n",
    "    model_l = load_model(model_path+model_names[m])\n",
    "    model_list.append(model_l)\n",
    "    output_list = output_list = model_performance(\n",
    "        information = False, using_model=model_l,Input_Prediction_Passively = False, \n",
    "        tr_x_val=inter_dataset['tr_x_val'][m], tr_y_val=inter_dataset['tr_y_val'][m], ts_x_val=inter_dataset['ts_x_val'][m], ts_y_val=inter_dataset['ts_y_val'][m],\n",
    "        output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                     \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                     \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                     \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                     \"roc_auc_total\"])\n",
    "    m_tr_accuracy, m_tr_sensitivity, m_tr_specificity, m_tr_predictions, m_labeled_tr_predictions, m_tr_predictions_flat, m_roc_auc_tr, m_ts_accuracy, m_ts_sensitivity, m_ts_specificity, m_ts_predictions,m_labeled_ts_predictions, m_ts_predictions_flat, m_roc_auc_ts, m_roc_auc_total = output_list\n",
    "    print(\"\\nmodel: \"+model_names[m])\n",
    "    print(\"tr & ts for inter data: \"+str(m_tr_accuracy)+\", \"+str(m_ts_accuracy)+\"\\n\")\n",
    "    \n",
    "    model_l_new = Model(inputs = model_l.input, outputs=model_l.get_layer(model_l.layers[-2].name).output)\n",
    "    m_tr_result = model_l_new.predict([inter_dataset['tr_x_val'][m]])\n",
    "    m_ts_result = model_l_new.predict([inter_dataset['ts_x_val'][m]])\n",
    "    \n",
    "    model_output_list[\"tr_accuracy\"].append(m_tr_accuracy)\n",
    "    model_output_list[\"tr_sensitivity\"].append(m_tr_sensitivity)\n",
    "    model_output_list[\"tr_specificity\"].append(m_tr_specificity)\n",
    "    model_output_list[\"ts_accuracy\"].append(m_ts_accuracy)\n",
    "    model_output_list[\"ts_sensitivity\"].append(m_ts_sensitivity)\n",
    "    model_output_list[\"ts_specificity\"].append(m_ts_specificity)\n",
    "    model_output_list[\"tr_result\"].append(m_tr_result)\n",
    "    \n",
    "    model_output_list[\"tr_predictions\"].append(m_tr_predictions)\n",
    "    model_output_list[\"labeled_tr_predictions\"].append(m_labeled_tr_predictions)\n",
    "    model_output_list[\"tr_predictions_flat\"].append(m_tr_predictions_flat)\n",
    "    model_output_list[\"roc_auc_tr\"].append(m_roc_auc_tr)\n",
    "    model_output_list[\"ts_predictions\"].append(m_ts_predictions)\n",
    "    model_output_list[\"labeled_ts_predictions\"].append(m_labeled_ts_predictions)\n",
    "    model_output_list[\"ts_predictions_flat\"].append(m_ts_predictions_flat)\n",
    "    model_output_list[\"roc_auc_ts\"].append(m_roc_auc_ts)\n",
    "    model_output_list[\"ts_result\"].append(m_ts_result)\n",
    "    \n",
    "    model_output_list[\"roc_auc_total\"].append(m_roc_auc_total)  \n",
    "    \n",
    "    tr_predictions.append(m_tr_predictions)\n",
    "    ts_predictions.append(m_ts_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating seperate model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### m_1-2_16.h5 ####\n",
      "types: OV_six_fold_CV_400\n",
      "tr: 1.0, ts: 0.8064516186714172\n",
      "\n",
      "#### m_1-2_6.h5 ####\n",
      "types: OV_six_fold_CV_400\n",
      "tr: 0.9918032786885246, ts: 0.774193525314331\n",
      "\n",
      "#### m_3-2.h5 ####\n",
      "types: OV_six_fold_new_Diff_400\n",
      "tr: 1.0, ts: 0.8709677457809448\n",
      "\n",
      "#### m_4-2_56.h5 ####\n",
      "types: OV_six_fold_Clin\n",
      "tr: 0.9836065573770492, ts: 0.774193525314331\n",
      "\n",
      "#### m_4-2_58.h5 ####\n",
      "types: OV_six_fold_Clin\n",
      "tr: 1.0, ts: 0.774193525314331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in range(len(model_names)):\n",
    "    print(\"#### \"+model_names[m]+\" ####\")\n",
    "    print(\"types: \"+types[model_index[m]])\n",
    "    print(\"tr: \"+str(model_output_list[\"tr_accuracy\"][m])+\", ts: \"+str(model_output_list[\"ts_accuracy\"][m])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "# select models for ensemble among loaded models.\n",
    "# CAUTION: Duplication(ex: select = [1, 1, 1, 3, 5]) is allowed, but it is same models, and have same predictions. They have same opinions.\n",
    "\n",
    "select = [1, 2, 2, 2, 4]\n",
    "print(select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) DNN-Combiner Ensmeble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Input listup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tr_predictions_select = []\n",
    "m_ts_predictions_select = []   \n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_tr_predictions_select.append(model_output_list[\"tr_predictions\"][select[i]-1])\n",
    "    m_ts_predictions_select.append(model_output_list[\"ts_predictions\"][select[i]-1])\n",
    "    #print(m_tr_predictions[select[i]-1].shape)\n",
    "    \n",
    "em_tr_x_val = np.concatenate(m_tr_predictions_select, axis=1)\n",
    "em_ts_x_val = np.concatenate(m_ts_predictions_select, axis=1)\n",
    "\n",
    "tr_y_val = inter_dataset[\"tr_y_val\"][0]\n",
    "ts_y_val = inter_dataset[\"ts_y_val\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 5)\n",
      "(31, 5)\n"
     ]
    }
   ],
   "source": [
    "print(em_tr_x_val.shape)\n",
    "print(em_ts_x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################## DNN em ##################################\n",
      "select: [1, 2, 2, 2, 4]\n",
      "\n",
      "OV_six_fold_CV_400\n",
      "m_1-2_16.h5\n",
      "\n",
      "OV_six_fold_CV_400\n",
      "m_1-2_6.h5\n",
      "\n",
      "OV_six_fold_CV_400\n",
      "m_1-2_6.h5\n",
      "\n",
      "OV_six_fold_CV_400\n",
      "m_1-2_6.h5\n",
      "\n",
      "OV_six_fold_Clin\n",
      "m_4-2_56.h5\n",
      "#############################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 3s 22ms/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "122/122 [==============================] - 0s 107us/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 107us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 426us/step\n",
      "122/122 [==============================] - 0s 172us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "122/122 [==============================] - 0s 107us/step\n",
      "122/122 [==============================] - 0s 107us/step\n",
      "122/122 [==============================] - 0s 107us/step\n",
      "122/122 [==============================] - 0s 254us/step\n",
      "Model em-2 trained.\n"
     ]
    }
   ],
   "source": [
    "print(\"################################## DNN em ##################################\")\n",
    "print(\"select: \"+str(select))\n",
    "for select_i in select:\n",
    "    print(\"\\n\"+types[model_index[select_i-1]])\n",
    "    print(model_names[select_i-1])\n",
    "\n",
    "    \n",
    "print(\"#############################################################################################\")\n",
    "\n",
    "# 1) parameter setting\n",
    "em_adam = optimizers.Adam(lr=0.05)                                   \n",
    "em_input_drop_out = 0.3\n",
    "em_drop_out = 0\n",
    "em_batch_size = 5\n",
    "em_BN = True                           \n",
    "\n",
    "em_layers = [10]\n",
    "em_tr_loss_best = 100 # for saving best loss value \n",
    "em_best_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "em_input = Input(shape=(len(select),))\n",
    "em_dp = Dropout(em_input_drop_out)(em_input)\n",
    "for l in layers:\n",
    "    if em_BN == True:\n",
    "        em_m = Dense(l)(em_dp)\n",
    "        em_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(em_m)\n",
    "        em_dp = Activation(\"relu\")(em_bn)\n",
    "    else:\n",
    "        em_m = Dense(l,activation='relu')(em_dp)\n",
    "        em_dp = Dropout(drop_out_m)(em_m)\n",
    "\n",
    "em_final = em_dp\n",
    "em_output = Dense(1, activation=\"sigmoid\")(em_final)\n",
    "em_model = Model(inputs=em_input,outputs=em_output)\n",
    "em_model.compile(optimizer=em_adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    em_model.fit(em_tr_x_val, tr_y_val, batch_size=em_batch_size, nb_epoch=1, verbose = 0)\n",
    "    em_tr_loss=em_model.evaluate( em_tr_x_val, tr_y_val)[0]\n",
    "    if em_tr_loss < em_tr_loss_best: # new best model. count reset.\n",
    "        em_tr_loss_best = em_tr_loss\n",
    "        count=0\n",
    "        em_best_model = em_model\n",
    "    if count>10: # no increase three time. stop.\n",
    "        em_model = em_best_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"Model em\" +\"-\"+str(ts_i)+\" trained.\")\n",
    "\n",
    "# 4) save model\n",
    "em_model.save(save_model_path+\"/m_em-\"+str(ts_i)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _DNN Combiner_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 148us/step\n",
      "31/31 [==============================] - 0s 161us/step\n",
      "Overall AUC:  0.9879492600422832\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8383838383838383\n",
      "Train Accuracy: 0.9918032786885246\n",
      "Train Sensitivities & Specificities : 1.0, 0.9886363636363636\n",
      "Test Accuracy: 0.7419354915618896\n",
      "Test Sensitivities & Specificities : 0.7777777777777778, 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "em_output_list = model_performance(\n",
    "    information = False, using_model=em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=em_tr_x_val, tr_y_val=tr_y_val, ts_x_val=em_ts_x_val, ts_y_val=ts_y_val,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "em_tr_loss, em_tr_accuracy, em_tr_sensitivity, em_tr_specificity, em_tr_predictions, em_labeled_tr_predictions, em_tr_predictions_flat, em_roc_auc_tr, em_ts_loss, em_ts_accuracy, em_ts_sensitivity, em_ts_specificity, em_ts_predictions,em_labeled_ts_predictions, em_ts_predictions_flat, em_roc_auc_ts, em_roc_auc_total = em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", em_roc_auc_total)\n",
    "print(\"Train AUC: \", em_roc_auc_tr)\n",
    "print(\"Test AUC: \", em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(em_tr_sensitivity)+\", \"+str(em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(em_ts_sensitivity)+\", \"+str(em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"tr_data\"][0].index), \"hypothesis 1\": list(em_tr_predictions_flat), \n",
    "                        \"prediction\":list(em_labeled_tr_predictions), \"Platinum_Status\":list(tr_y_val)})\n",
    "tr_df_em.to_csv(save_prediction_path+\"m_em-\"+str(ts_i)+\"_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"ts_data\"][0].index), \"hypothesis 1\": list(em_ts_predictions_flat), \n",
    "                        \"prediction\":list(em_labeled_ts_predictions), \"Platinum_Status\":list(ts_y_val)})\n",
    "ts_df_em.to_csv(save_prediction_path+\"m_em-\"+str(ts_i)+\"_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Mean Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _mean_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC:  0.9826638477801268\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8080808080808081\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.7419354838709677\n",
      "Test Sensitivities & Specificities : 0.6666666666666666, 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "mean_em_tr_predictions=sum(m_tr_predictions_select)/len(select)\n",
    "mean_em_ts_predictions=sum(m_ts_predictions_select)/len(select)\n",
    "\n",
    "mean_em_output_list = model_performance(\n",
    "    information = False, using_model=None,Input_Prediction_Passively = True, \n",
    "    tr_predictions=mean_em_tr_predictions, ts_predictions=mean_em_ts_predictions, \n",
    "    tr_x_val=em_tr_x_val, tr_y_val=tr_y_val, ts_x_val=em_ts_x_val, ts_y_val=ts_y_val,\n",
    "    output_list=[\"tr_sensitivity\", \"tr_specificity\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_sensitivity\", \"ts_specificity\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "mean_em_tr_sensitivity, mean_em_tr_specificity,  mean_em_labeled_tr_predictions, mean_em_tr_predictions_flat, mean_em_roc_auc_tr, mean_em_ts_sensitivity, mean_em_ts_specificity, mean_em_labeled_ts_predictions, mean_em_ts_predictions_flat, mean_em_roc_auc_ts, mean_em_roc_auc_total = mean_em_output_list\n",
    "\n",
    "mean_em_tr_accuracy = sum(mean_em_labeled_tr_predictions==tr_y_val.values)/len(tr_y_val)\n",
    "mean_em_ts_accuracy = sum(mean_em_labeled_ts_predictions==ts_y_val.values)/len(ts_y_val)\n",
    "\n",
    "print(\"Overall AUC: \", mean_em_roc_auc_total)\n",
    "print(\"Train AUC: \", mean_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", mean_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(mean_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(mean_em_tr_sensitivity)+\", \"+str(mean_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(mean_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(mean_em_ts_sensitivity)+\", \"+str(mean_em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"tr_data\"][0].index), \"hypothesis 1\": list(mean_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(mean_em_labeled_tr_predictions), \"Platinum_Status\":list(tr_y_val)})\n",
    "tr_df_em.to_csv(save_prediction_path+\"m_mean-\"+str(ts_i)+\"_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"ts_data\"][0].index), \"hypothesis 1\": list(mean_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(mean_em_labeled_ts_predictions), \"Platinum_Status\":list(ts_y_val)})\n",
    "ts_df_em.to_csv(save_prediction_path+\"m_mean-\"+str(ts_i)+\"_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Transferred Ensemble Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making new input data for t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################### t-em x val merged. ###############################################\n",
      "\n",
      "(122, 450)\n",
      "(31, 450)\n"
     ]
    }
   ],
   "source": [
    "m_tr_result_select = []\n",
    "m_ts_result_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_tr_result_select.append(model_output_list[\"tr_result\"][select[i]-1])\n",
    "    m_ts_result_select.append(model_output_list[\"ts_result\"][select[i]-1])\n",
    "\n",
    "t_em_tr_x_val = np.concatenate(m_tr_result_select, axis=1)\n",
    "t_em_ts_x_val = np.concatenate(m_ts_result_select, axis=1)\n",
    "print(\"\\n############################################### t-em x val merged. ###############################################\\n\")\n",
    "print(t_em_tr_x_val.shape)\n",
    "print(t_em_ts_x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling t-ensemble  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################## Transferred em ##################################\n",
      "select: [1, 2, 2, 2, 4]\n",
      "\n",
      "OV_six_fold_CV_400\n",
      "m_1-2_16.h5\n",
      "\n",
      "OV_six_fold_CV_400\n",
      "m_1-2_6.h5\n",
      "\n",
      "OV_six_fold_CV_400\n",
      "m_1-2_6.h5\n",
      "\n",
      "OV_six_fold_CV_400\n",
      "m_1-2_6.h5\n",
      "\n",
      "OV_six_fold_Clin\n",
      "m_4-2_56.h5\n",
      "#############################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 3s 22ms/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 148us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 156us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 148us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "Model t-em-2 trained.\n"
     ]
    }
   ],
   "source": [
    "print(\"################################## Transferred em ##################################\")\n",
    "print(\"select: \"+str(select))\n",
    "for select_i in select:\n",
    "    print(\"\\n\"+types[model_index[select_i-1]])\n",
    "    print(model_names[select_i-1])\n",
    "\n",
    "    \n",
    "print(\"#############################################################################################\")\n",
    "\n",
    "# 1) parameter setting\n",
    "t_em_adam = optimizers.Adam(lr=0.05)                                   \n",
    "t_em_input_drop_out = 0.3\n",
    "t_em_drop_out = 0\n",
    "t_em_batch_size = 5\n",
    "t_em_BN = True                           \n",
    "\n",
    "t_em_layers = [10]\n",
    "t_em_tr_loss_best = 100 # for saving best loss value \n",
    "t_em_best_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "t_em_input = Input(shape=(t_em_ts_x_val.shape[1],))\n",
    "t_em_dp = Dropout(t_em_input_drop_out)(t_em_input)\n",
    "for l in layers:\n",
    "    if t_em_BN == True:\n",
    "        t_em_m = Dense(l)(t_em_dp)\n",
    "        t_em_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(t_em_m)\n",
    "        t_em_dp = Activation(\"relu\")(t_em_bn)\n",
    "    else:\n",
    "        t_em_m = Dense(l,activation='relu')(t_em_dp)\n",
    "        t_em_dp = Dropout(drop_out_m)(t_em_m)\n",
    "\n",
    "t_em_final = t_em_dp\n",
    "t_em_output = Dense(1, activation=\"sigmoid\")(t_em_final)\n",
    "t_em_model = Model(inputs=t_em_input,outputs=t_em_output)\n",
    "t_em_model.compile(optimizer=t_em_adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    t_em_model.fit(t_em_tr_x_val, tr_y_val, batch_size=t_em_batch_size, nb_epoch=1, verbose = 0)\n",
    "    t_em_tr_loss=t_em_model.evaluate( t_em_tr_x_val, tr_y_val)[0]\n",
    "    if t_em_tr_loss < t_em_tr_loss_best: # new best model. count reset.\n",
    "        t_em_tr_loss_best = t_em_tr_loss\n",
    "        count=0\n",
    "        t_em_best_model = t_em_model\n",
    "    if count>10: # no increase three time. stop.\n",
    "        t_em_model = t_em_best_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "        \n",
    "print(\"Model t-em\" +\"-\"+str(ts_i)+\" trained.\")\n",
    "\n",
    "# 4) save model\n",
    "em_model.save(save_model_path+\"/m_t-em-\"+str(ts_i)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 190us/step\n",
      "31/31 [==============================] - 0s 160us/step\n",
      "Overall AUC:  0.9808668076109937\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8207070707070707\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.7419354915618896\n",
      "Test Sensitivities & Specificities : 0.6666666666666666, 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "t_em_output_list = model_performance(\n",
    "    information = False, using_model=t_em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=t_em_tr_x_val, tr_y_val=tr_y_val, ts_x_val=t_em_ts_x_val, ts_y_val=ts_y_val,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "t_em_tr_loss, t_em_tr_accuracy, t_em_tr_sensitivity, t_em_tr_specificity, t_em_tr_predictions, t_em_labeled_tr_predictions, t_em_tr_predictions_flat, t_em_roc_auc_tr, t_em_ts_loss, t_em_ts_accuracy, t_em_ts_sensitivity, t_em_ts_specificity, t_em_ts_predictions,t_em_labeled_ts_predictions, t_em_ts_predictions_flat, t_em_roc_auc_ts, t_em_roc_auc_total = t_em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", t_em_roc_auc_total)\n",
    "print(\"Train AUC: \", t_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", t_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(t_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(t_em_tr_sensitivity)+\", \"+str(t_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(t_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(t_em_ts_sensitivity)+\", \"+str(t_em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_t_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"tr_data\"][0].index), \"hypothesis 1\": list(t_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(t_em_labeled_tr_predictions), \"Platinum_Status\":list(tr_y_val)})\n",
    "tr_df_t_em.to_csv(save_prediction_path+\"m_t-em-\"+str(ts_i)+\"_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_t_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"ts_data\"][0].index), \"hypothesis 1\": list(t_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(t_em_labeled_ts_predictions), \"Platinum_Status\":list(ts_y_val)})\n",
    "ts_df_t_em.to_csv(save_prediction_path+\"m_t-em-\"+str(ts_i)+\"_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferred Ensemble(Modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mo_transferred ensemble input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset : raw data + prediction results\n",
    "mo_em_tr_x_val = np.concatenate([inter_dataset[\"tr_x_val\"][1], em_tr_x_val], axis = 1)\n",
    "mo_em_ts_x_val = np.concatenate([inter_dataset[\"ts_x_val\"][1], em_ts_x_val], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 405)\n",
      "(31, 405)\n"
     ]
    }
   ],
   "source": [
    "print(mo_em_tr_x_val.shape)\n",
    "print(mo_em_ts_x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_em_matrix = np.concatenate([full_em_ts_x_val, full_em_tr_x_val], axis = 0)\n",
    "#df_full_dataset = pd.DataFrame(full_em_matrix)\n",
    "#df_full_dataset.to_csv(index=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_full_dataset = pd.DataFrame(full_em_matrix)\\ndf_full_dataset.to_csv(\"C:/test/merge_newDiff_400_with_predictions.csv\",index=False)\\n\\n'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_full_dataset = pd.DataFrame(full_em_matrix)\n",
    "df_full_dataset.to_csv(\"C:/test/merge_newDiff_400_with_predictions.csv\",index=False)\n",
    "\n",
    "'''\n",
    "#df_full_dataset.loc[df_full_dataset.shape[1]] = patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified t-ensemble model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 3s 23ms/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 148us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 148us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 156us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 148us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Model mo-em-2 trained.\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "31/31 [==============================] - 0s 161us/step\n",
      "Overall AUC:  0.9788583509513742\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.797979797979798\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.8064516186714172\n",
      "Test Sensitivities & Specificities : 0.5555555555555556, 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "print(\"modified t-ensemble model\")\n",
    "\n",
    "# 1) parameter setting\n",
    "mo_em_adam = optimizers.Adam(lr=0.05)                                   \n",
    "mo_em_input_drop_out = 0.3\n",
    "mo_em_drop_out = 0\n",
    "mo_em_batch_size = 5\n",
    "mo_em_BN = True                           \n",
    "\n",
    "mo_em_layers = [100]\n",
    "mo_em_tr_loss_best = 100 # for saving best loss value \n",
    "mo_em_best_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "mo_em_input = Input(shape=(mo_em_ts_x_val.shape[1],))\n",
    "mo_em_dp = Dropout(mo_em_input_drop_out)(mo_em_input)\n",
    "for l in layers:\n",
    "    if mo_em_BN == True:\n",
    "        mo_em_m = Dense(l)(mo_em_dp)\n",
    "        mo_em_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(mo_em_m)\n",
    "        mo_em_dp = Activation(\"relu\")(mo_em_bn)\n",
    "    else:\n",
    "        mo_em_m = Dense(l,activation='relu')(mo_em_dp)\n",
    "        mo_em_dp = Dropout(drop_out_m)(mo_em_m)\n",
    "\n",
    "mo_em_final = mo_em_dp\n",
    "mo_em_output = Dense(1, activation=\"sigmoid\")(mo_em_final)\n",
    "mo_em_model = Model(inputs=mo_em_input,outputs=mo_em_output)\n",
    "mo_em_model.compile(optimizer=mo_em_adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    mo_em_model.fit(mo_em_tr_x_val, tr_y_val, batch_size=mo_em_batch_size, nb_epoch=1, verbose = 0)\n",
    "    mo_em_tr_loss=mo_em_model.evaluate( mo_em_tr_x_val, tr_y_val)[0]\n",
    "    if mo_em_tr_loss < mo_em_tr_loss_best: # new best model. count reset.\n",
    "        mo_em_tr_loss_best = mo_em_tr_loss\n",
    "        count=0\n",
    "        mo_em_best_model = mo_em_model\n",
    "    if count>10: # no increase three time. stop.\n",
    "        mo_em_model = mo_em_best_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "        \n",
    "print(\"Model mo-em\" +\"-\"+str(ts_i)+\" trained.\")\n",
    "\n",
    "# 4) save model\n",
    "em_model.save(save_model_path+\"/m_mo-em-\"+str(ts_i)+\".h5\")\n",
    "\n",
    "# 5) evaluate model\n",
    "mo_em_output_list = model_performance(\n",
    "    information = False, using_model=mo_em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=mo_em_tr_x_val, tr_y_val=tr_y_val, ts_x_val=mo_em_ts_x_val, ts_y_val=ts_y_val,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "mo_em_tr_loss, mo_em_tr_accuracy, mo_em_tr_sensitivity, mo_em_tr_specificity, mo_em_tr_predictions, mo_em_labeled_tr_predictions, mo_em_tr_predictions_flat, mo_em_roc_auc_tr, mo_em_ts_loss, mo_em_ts_accuracy, mo_em_ts_sensitivity, mo_em_ts_specificity, mo_em_ts_predictions,mo_em_labeled_ts_predictions, mo_em_ts_predictions_flat, mo_em_roc_auc_ts, mo_em_roc_auc_total = mo_em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", mo_em_roc_auc_total)\n",
    "print(\"Train AUC: \", mo_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", mo_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(mo_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(mo_em_tr_sensitivity)+\", \"+str(mo_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(mo_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(mo_em_ts_sensitivity)+\", \"+str(mo_em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_mo_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"tr_data\"][0].index), \"hypothesis 1\": list(mo_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(mo_em_labeled_tr_predictions), \"Platinum_Status\":list(tr_y_val)})\n",
    "tr_df_mo_em.to_csv(save_prediction_path+\"m_mo-em-\"+str(ts_i)+\"_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_mo_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"ts_data\"][0].index), \"hypothesis 1\": list(mo_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(mo_em_labeled_ts_predictions), \"Platinum_Status\":list(ts_y_val)})\n",
    "ts_df_mo_em.to_csv(save_prediction_path+\"m_mo-em-\"+str(ts_i)+\"_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm_1_l_tr_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-215-367749414d73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtr_accuracy_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mm_1_l_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_2_l_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_3_l_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_4_l_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_5_l_tr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_6_l_tr_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mts_accuracy_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mm_1_l_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_2_l_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_3_l_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_4_l_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_5_l_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_6_l_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtr_accuracy_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mts_accuracy_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm_1_l_tr_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "t_em_tr_accuracy, t_em_tr_sensitivity, t_em_tr_specificity,t_em_roc_auc_tr, \n",
    "t_em_ts_accuracy, t_em_ts_sensitivity, t_em_ts_specificity, t_em_roc_auc_ts, \n",
    "t_em_roc_auc_total\n",
    "tr_accuracy_list = [m_1_l_tr_accuracy, m_2_l_tr_accuracy, m_3_l_tr_accuracy, m_4_l_tr_accuracy, m_5_l_tr_accuracy, m_6_l_tr_accuracy]\n",
    "ts_accuracy_list = [m_1_l_accuracy, m_2_l_accuracy, m_3_l_accuracy, m_4_l_accuracy, m_5_l_accuracy, m_6_l_accuracy]\n",
    "tr_accuracy_select = []\n",
    "ts_accuracy_select = []\n",
    "\n",
    "for i in select:\n",
    "    label.append(\"model\"+str(i))\n",
    "    tr_accuracy_select.append(tr_accuracy_list[i-1])\n",
    "    ts_accuracy_select.append(ts_accuracy_list[i-1])\n",
    "\n",
    "label = label+[\"mean-em\",\"d-comb em\",\"t-em\"]\n",
    "tr_accuracy_select= tr_accuracy_select + [mean_em_tr_accuracy, em_tr_accuracy, t_em_tr_accuracy]\n",
    "ts_accuracy_select= ts_accuracy_select + [mean_em_ts_accuracy, em_ts_accuracy, t_em_ts_accuracy]\n",
    "\n",
    "for model_num in range(len(label)):\n",
    "    print(\"< \"+label[model_num]+\" > tr: \"+str(tr_accuracy_select[model_num])+\", ts: \"+str(ts_accuracy_select[model_num]))\n",
    "\n",
    "#label = [\"model1\",\"model2\",\"model3\",\"mean-em\",\"d-comb em\",\"t-em\"]\n",
    "#accuracy = [m1_accuracy,m2_accuracy,m3_accuracy,mean_em_accuracy,em_accuracy,t_em_accuracy ]\n",
    "#print(\"model1: \"+str(accuracy[0])+\"\\nmodel2: \"+str(accuracy[1])+\"\\nmodel3: \"+str(accuracy[2])+\"\\nmean-em: \"+str(accuracy[3])+\"\\nd-comb em: \"+str(accuracy[4])+\"\\nt-em: \"+str(accuracy[5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
