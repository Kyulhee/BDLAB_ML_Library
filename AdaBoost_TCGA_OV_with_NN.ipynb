{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Packages & Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Input, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, load_model, Sequential \n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity & specificity using Predicted Y & Real Y\n",
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide raw data into train / test & x_val / y_val\n",
    "def data_split(raw_data, index_col, test_index):\n",
    "    \n",
    "    train_data = raw_data.iloc[list(raw_data.iloc[:,index_col]!=test_index)]\n",
    "    test_data = raw_data.iloc[list(raw_data.iloc[:,index_col]==test_index)]\n",
    "    \n",
    "    y_val = train_data.Platinum_Status\n",
    "    x_val = train_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val = test_data.Platinum_Status\n",
    "    test_x_val = test_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    return train_data, test_data, y_val, x_val, test_y_val, test_x_val\n",
    "\n",
    "    # raw_data: have gene_expressions(maybe multiple columns), index column, Platinum_Status column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all of model performance \n",
    "# - predictions(probability) / labeled predictions(0/1) / Loss / Accuracy / Sensitivity / Specificity / AUC values of Train / Test dataset.\n",
    "# using trained models, or you can put predictions(probability) passively(in this case, Loss & Accuracy do not provided.)\n",
    "def model_performance(information=False, Input_Prediction_Passively=False, using_model=None, tr_predictions=None, ts_predictions=None, tr_x_val=None, tr_y_val=None, ts_x_val=None, ts_y_val=None, output_list=None):\n",
    "    \n",
    "    if information == True:            \n",
    "        print(\"options model_performance:\\n1) using_model: keras models that you want to check performance. \\\"Input_Prediction_Passive\\\" option for input prediction list instead using models.\\n3) tr_predictions & ts_predictions: prediction input passively. put this data only when not using keras model.\\n4) tr_x_val & ts_x_val: input samples of train/test samples.\\n4) tr_y_val & ts_y_val: results of train/test samples.\\n5) output_list: return values that you want to recieve.\\n CAUTION: Essential variable.\\n\\t tr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\\n\\n* CAUTION: if 'None' value is returned, please check your input tr inputs(None value for tr outputs) or ts inputs(None value for ts outputs).\") \n",
    "        return 0\n",
    "    elif information != False:\n",
    "        print(\"for using information options, please set 'information' variable for 'True'\")\n",
    "        return -1\n",
    "    \n",
    "    if using_model is None:\n",
    "        if Input_Prediction_Passively == False:\n",
    "            print(\"ERROR: There are no models for using.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\") \n",
    "            return -1\n",
    "        elif (tr_predictions is None) and (ts_predictions is None): # No model/prediction input. no performance should be calculated.\n",
    "                print(\"ERROR: Input prediction list instead using saved model.\")\n",
    "                return -1\n",
    "        else: # No model input, but Input_Prediction_Passively is True & input prediction is valid.\n",
    "            tr_loss,tr_accuracy= None, None\n",
    "            ts_loss,ts_accuracy= None, None\n",
    "            \n",
    "    elif Input_Prediction_Passively == True: # both of model/prediction putted, could cause confusing.\n",
    "        ch = input(\"You put both model and prediction. Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "        while 1:\n",
    "            if ch == 'p':\n",
    "                using_model = None\n",
    "                break\n",
    "            elif ch == 'm':\n",
    "                tr_predictions = None\n",
    "                ts_predictions = None\n",
    "                break\n",
    "            elif ch == 'e':\n",
    "                return 0\n",
    "            else:\n",
    "                print(\"you put worng option: \"+str(ch))\n",
    "            ch = input(\"Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "                \n",
    "    if output_list is None:\n",
    "        print(\"ERROR: There are no output_list for return.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\")\n",
    "        return -1\n",
    "    \n",
    "    if not(tr_x_val is None) and not(tr_y_val is None):\n",
    "        # predict tr result only when no tr_prediction input\n",
    "        if tr_predictions is None:\n",
    "            tr_loss,tr_accuracy= using_model.evaluate(tr_x_val,tr_y_val,verbose=0)\n",
    "            tr_predictions = using_model.predict(tr_x_val,verbose=0)\n",
    "        # tr sensitivity / specificity\n",
    "        labeled_tr_predictions = np.where(tr_predictions > 0.5, 1, 0).flatten()\n",
    "        tr_sensitivity, tr_specificity = check_correct(labeled_tr_predictions, tr_y_val)\n",
    "        tr_predictions_flat = tr_predictions[:,0]   \n",
    "        # roc(tr)\n",
    "        fpr_tr, tpr_tr, threshold_tr = metrics.roc_curve(tr_y_val, tr_predictions)\n",
    "        roc_auc_tr = metrics.auc(fpr_tr, tpr_tr)\n",
    "    \n",
    "    if not(ts_x_val is None) and not(ts_y_val is None):\n",
    "        # predict ts result only when no ts_prediction input\n",
    "        if ts_predictions is None:\n",
    "            ts_loss,ts_accuracy= using_model.evaluate(ts_x_val,ts_y_val,verbose=0)\n",
    "            ts_predictions = using_model.predict(ts_x_val,verbose=0)\n",
    "        labeled_ts_predictions = np.where(ts_predictions > 0.5, 1, 0).flatten()\n",
    "        ts_sensitivity, ts_specificity = check_correct(labeled_ts_predictions, ts_y_val)\n",
    "        ts_predictions_flat = ts_predictions[:,0]   \n",
    "        # roc(ts)\n",
    "        fpr_ts, tpr_ts, threshold_ts = metrics.roc_curve(ts_y_val, ts_predictions)\n",
    "        roc_auc_ts = metrics.auc(fpr_ts, tpr_ts)    \n",
    "    \n",
    "    if (not(tr_x_val is None) and not(tr_y_val is None)) and (not(ts_x_val is None) and not(ts_y_val is None)):\n",
    "        y_true = np.append(tr_y_val, ts_y_val)\n",
    "        y_pred = np.append(tr_predictions, ts_predictions)\n",
    "        fpr_total, tpr_total, threshold_total = metrics.roc_curve(y_true, y_pred)\n",
    "        roc_auc_total = metrics.auc(fpr_total, tpr_total)\n",
    "        \n",
    "        \n",
    "    return_list = []\n",
    "    \n",
    "    for output in output_list:\n",
    "        \n",
    "        if(output == \"tr_loss\"):\n",
    "            return_list.append(tr_loss)\n",
    "                               \n",
    "        elif(output == \"tr_accuracy\"):\n",
    "            return_list.append(tr_accuracy)\n",
    "                               \n",
    "        elif(output == \"tr_sensitivity\"):\n",
    "            return_list.append(tr_sensitivity)\n",
    "                               \n",
    "        elif(output == \"tr_specificity\"):\n",
    "            return_list.append(tr_specificity)\n",
    "                               \n",
    "        elif(output == \"tr_predictions\"):\n",
    "            return_list.append(tr_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_tr_predictions\"):\n",
    "            return_list.append(labeled_tr_predictions)\n",
    "                               \n",
    "        elif(output == \"tr_predictions_flat\"):\n",
    "            return_list.append(tr_predictions_flat)\n",
    "            \n",
    "        elif(output == \"roc_auc_tr\"):\n",
    "            return_list.append(roc_auc_tr)\n",
    "\n",
    "        elif(output == \"ts_loss\"):\n",
    "            return_list.append(ts_loss)\n",
    "                               \n",
    "        elif(output == \"ts_accuracy\"):\n",
    "            return_list.append(ts_accuracy)\n",
    "                               \n",
    "        elif(output == \"ts_sensitivity\"):\n",
    "            return_list.append(ts_sensitivity)\n",
    "                               \n",
    "        elif(output == \"ts_specificity\"):\n",
    "            return_list.append(ts_specificity)\n",
    "                               \n",
    "        elif(output == \"ts_predictions\"):\n",
    "            return_list.append(ts_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_ts_predictions\"):\n",
    "            return_list.append(labeled_ts_predictions)\n",
    "                               \n",
    "        elif(output == \"ts_predictions_flat\"):\n",
    "            return_list.append(ts_predictions_flat)\n",
    "        \n",
    "        elif(output == \"roc_auc_ts\"):\n",
    "            return_list.append(roc_auc_ts)\n",
    "            \n",
    "        elif(output == \"roc_auc_total\"):\n",
    "            return_list.append(roc_auc_total)\n",
    "                               \n",
    "        else:\n",
    "            print(\"There are no options <\"+str(output)+\">. Please refer these output options:\\ntr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\")\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training one NN model using train X & Y values\n",
    "def train_NN_model(tr_x, tr_y):\n",
    "    \n",
    "    # 1) parameter setting\n",
    "    lr=0.01\n",
    "    input_drop_out = 0\n",
    "    drop_out = 0.5\n",
    "    layers = [10]\n",
    "    BN = True\n",
    "    batch_size = 5\n",
    "    m_tr_loss_best = 100\n",
    "    \n",
    "    m_adam = optimizers.Adam(lr=lr)\n",
    "    # 2) model build\n",
    "    #m_input = Input(shape=(input_dim[1],))\n",
    "    m_input = Input(shape=(tr_x.shape[1],))\n",
    "    m_dp = Dropout(input_drop_out)(m_input)\n",
    "    if BN == True:\n",
    "        for i in layers:\n",
    "            m_h = Dense(i)(m_dp)\n",
    "            m_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(m_h)\n",
    "            m_dp = Activation(\"relu\")(m_bn)\n",
    "    else:        \n",
    "        for i in m_layers:\n",
    "            m_h = Dense(i,activation='relu')(m_dp)\n",
    "            m_dp = Dropout(drop_out)(m_h)\n",
    "    m_final = m_dp\n",
    "    m_output = Dense(1, activation=\"sigmoid\")(m_final)\n",
    "    m_model = Model(inputs=m_input,outputs=m_output)\n",
    "    m_model.compile(optimizer=m_adam, \n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    \n",
    "#    while 1:\n",
    "#        m_model.fit(tr_x, tr_y, batch_size=batch_size, nb_epoch=1, verbose = 0)\n",
    "#        m_tr_loss=m_model.evaluate(tr_x, tr_y, verbose = 0)[0]\n",
    "#        if m_tr_loss < m_tr_loss_best: # new best model. count reset.\n",
    "#            m_tr_loss_best = m_tr_loss\n",
    "#            count=0\n",
    "#            best_m_model = m_model\n",
    "#        if count>3: # no increase three time. stop.\n",
    "#            m_model = best_m_model\n",
    "#            break\n",
    "#        else: count=count+1\n",
    "    m_model.fit(tr_x, tr_y, batch_size=batch_size, nb_epoch=10, verbose = 0)\n",
    "    \n",
    "    return m_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Input Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"OV_six_fold_Annotation3000_400\", \n",
    "         \"OV_six_fold_CV_400\", \n",
    "         \"OV_six_fold_Var_400\", \"OV_six_fold_new_Diff_400\",\n",
    "         \"OV_six_fold_Clin\", \n",
    "         \"OV_six_fold_SNV\" \n",
    "         ]\n",
    "\n",
    "path = \"../../TC_six_fold_subsamples/\"\n",
    "save_model_path = \"C:/test/best_models/model/\"\n",
    "save_prediction_path = \"C:/test/best_models/predictions/\"\n",
    "save_result_path = \"C:/test/best_models/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] file_name:  OV_six_fold_Annotation3000_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[2] file_name:  OV_six_fold_CV_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[3] file_name:  OV_six_fold_Var_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[4] file_name:  OV_six_fold_new_Diff_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[5] file_name:  OV_six_fold_Clin \n",
      "sample : 287  \n",
      "features : 35\n",
      "[6] file_name:  OV_six_fold_SNV \n",
      "sample : 213  \n",
      "features : 13814\n"
     ]
    }
   ],
   "source": [
    "file_1 = path+types[0]+\".csv\"\n",
    "file_2 = path+types[1]+\".csv\"\n",
    "file_3 = path+types[2]+\".csv\"\n",
    "file_4 = path+types[3]+\".csv\"\n",
    "file_5 = path+types[4]+\".csv\"\n",
    "file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "full_data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "full_data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "full_data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "full_data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "full_data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "full_data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "inter_data_1 = full_data_1.iloc[list(full_data_1.iloc[:,-1]!=6)]\n",
    "inter_data_2 = full_data_2.iloc[list(full_data_2.iloc[:,-1]!=6)]\n",
    "inter_data_3 = full_data_3.iloc[list(full_data_3.iloc[:,-1]!=6)]\n",
    "inter_data_4 = full_data_4.iloc[list(full_data_4.iloc[:,-1]!=6)]\n",
    "inter_data_5 = full_data_5.iloc[list(full_data_5.iloc[:,-1]!=6)]\n",
    "inter_data_6 = full_data_6.iloc[list(full_data_6.iloc[:,-1]!=6)]\n",
    "\n",
    "data_1 = full_data_1\n",
    "data_2 = full_data_2\n",
    "data_3 = full_data_3\n",
    "data_4 = full_data_4\n",
    "data_5 = full_data_5\n",
    "data_6 = full_data_6\n",
    "\n",
    "sample_1,features_1 = data_1.shape\n",
    "sample_2,features_2 = data_2.shape\n",
    "sample_3,features_3 = data_3.shape\n",
    "sample_4,features_4 = data_4.shape\n",
    "sample_5,features_5 = data_5.shape\n",
    "sample_6,features_6 = data_6.shape\n",
    "\n",
    "# Data frame include index & Platinum_Status column, substract 2 to calculate real number of features \n",
    "[features_1, features_2, features_3, features_4, features_5, features_6] = [features_1-2, features_2-2, features_3-2, features_4-2, features_5-2, features_6-2]\n",
    "\n",
    "print(\"[1] file_name: \", types[0], \"\\nsample : {}  \\nfeatures : {}\".format(sample_1,features_1))\n",
    "print(\"[2] file_name: \", types[1], \"\\nsample : {}  \\nfeatures : {}\".format(sample_2,features_2))\n",
    "print(\"[3] file_name: \", types[2], \"\\nsample : {}  \\nfeatures : {}\".format(sample_3,features_3))\n",
    "print(\"[4] file_name: \", types[3], \"\\nsample : {}  \\nfeatures : {}\".format(sample_4,features_4))\n",
    "print(\"[5] file_name: \", types[4], \"\\nsample : {}  \\nfeatures : {}\".format(sample_5,features_5))\n",
    "print(\"[6] file_name: \", types[5], \"\\nsample : {}  \\nfeatures : {}\".format(sample_6,features_6))\n",
    "\n",
    "# Split Train Test Data\n",
    "\n",
    "train_data_1, test_data_1, tr_y_val_1, tr_x_val_1, ts_y_val_1, ts_x_val_1 = data_split(raw_data = data_1, index_col = -1, test_index = 1)\n",
    "train_data_2, test_data_2, tr_y_val_2, tr_x_val_2, ts_y_val_2, ts_x_val_2 = data_split(raw_data = data_2, index_col = -1, test_index = 1)\n",
    "train_data_3, test_data_3, tr_y_val_3, tr_x_val_3, ts_y_val_3, ts_x_val_3 = data_split(raw_data = data_3, index_col = -1, test_index = 1)\n",
    "train_data_4, test_data_4, tr_y_val_4, tr_x_val_4, ts_y_val_4, ts_x_val_4 = data_split(raw_data = data_4, index_col = -1, test_index = 1)\n",
    "train_data_5, test_data_5, tr_y_val_5, tr_x_val_5, ts_y_val_5, ts_x_val_5 = data_split(raw_data = data_5, index_col = -1, test_index = 1)\n",
    "train_data_6, test_data_6, tr_y_val_6, tr_x_val_6, ts_y_val_6, ts_x_val_6 = data_split(raw_data = data_6, index_col = -1, test_index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x_val_list = [tr_x_val_1, tr_x_val_2, tr_x_val_3, tr_x_val_4]\n",
    "tr_y_val_list = [tr_y_val_1, tr_y_val_2, tr_y_val_3, tr_y_val_4]\n",
    "ts_x_val_list = [ts_x_val_1, ts_x_val_2, ts_x_val_3, ts_x_val_4]\n",
    "ts_y_val_list = [ts_y_val_1, ts_y_val_2, ts_y_val_3, ts_y_val_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models N stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_model_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1/10th step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of OV_six_fold_Annotation3000_400: 0.10752688172043011\n",
      "Error of OV_six_fold_CV_400: 0.021505376344086023\n",
      "Error of OV_six_fold_Var_400: 0.010752688172043012\n",
      "Error of OV_six_fold_new_Diff_400: 0.005376344086021506\n",
      "\t-> Selected: OV_six_fold_new_Diff_400\n",
      "\tError: 0.005376344086021506, Alpha: 2.610177912539162\n",
      "# 2/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.05376344086021506\n",
      "Error of OV_six_fold_CV_400: 0.010752688172043012\n",
      "Error of OV_six_fold_Var_400: 0.005376344086021506\n",
      "Error of OV_six_fold_new_Diff_400: 0.010752688172043012\n",
      "\t-> Selected: OV_six_fold_Var_400\n",
      "\tError: 0.005376344086021506, Alpha: 2.610177912539162\n",
      "# 3/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.037634408602150546\n",
      "Error of OV_six_fold_CV_400: 0.0\n",
      "Error of OV_six_fold_Var_400: 0.005376344086021506\n",
      "Error of OV_six_fold_new_Diff_400: 0.0\n",
      "\t-> Selected: OV_six_fold_CV_400\n",
      "\tError: 0.0, Alpha: 8.0\n",
      "# 4/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.2096774193548387\n",
      "Error of OV_six_fold_CV_400: 0.005376344086021506\n",
      "Error of OV_six_fold_Var_400: 0.0\n",
      "Error of OV_six_fold_new_Diff_400: 0.0\n",
      "\t-> Selected: OV_six_fold_Var_400\n",
      "\tError: 0.0, Alpha: 8.0\n",
      "# 5/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.08602150537634409\n",
      "Error of OV_six_fold_CV_400: 0.010752688172043012\n",
      "Error of OV_six_fold_Var_400: 0.13440860215053763\n",
      "Error of OV_six_fold_new_Diff_400: 0.0\n",
      "\t-> Selected: OV_six_fold_new_Diff_400\n",
      "\tError: 0.0, Alpha: 8.0\n",
      "# 6/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.20967741935483872\n",
      "Error of OV_six_fold_CV_400: 0.005376344086021506\n",
      "Error of OV_six_fold_Var_400: 0.005376344086021506\n",
      "Error of OV_six_fold_new_Diff_400: 0.0\n",
      "\t-> Selected: OV_six_fold_new_Diff_400\n",
      "\tError: 0.0, Alpha: 8.0\n",
      "# 7/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.10215053763440862\n",
      "Error of OV_six_fold_CV_400: 0.0\n",
      "Error of OV_six_fold_Var_400: 0.05913978494623656\n",
      "Error of OV_six_fold_new_Diff_400: 0.0\n",
      "\t-> Selected: OV_six_fold_CV_400\n",
      "\tError: 0.0, Alpha: 8.0\n",
      "# 8/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.06989247311827956\n",
      "Error of OV_six_fold_CV_400: 0.016129032258064516\n",
      "Error of OV_six_fold_Var_400: 0.005376344086021506\n",
      "Error of OV_six_fold_new_Diff_400: 0.0\n",
      "\t-> Selected: OV_six_fold_new_Diff_400\n",
      "\tError: 0.0, Alpha: 8.0\n",
      "# 9/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.05376344086021506\n",
      "Error of OV_six_fold_CV_400: 0.005376344086021506\n",
      "Error of OV_six_fold_Var_400: 0.08064516129032258\n",
      "Error of OV_six_fold_new_Diff_400: 0.0\n",
      "\t-> Selected: OV_six_fold_new_Diff_400\n",
      "\tError: 0.0, Alpha: 8.0\n",
      "# 10/10th step\n",
      "Error of OV_six_fold_Annotation3000_400: 0.12903225806451613\n",
      "Error of OV_six_fold_CV_400: 0.0\n",
      "Error of OV_six_fold_Var_400: 0.016129032258064516\n",
      "Error of OV_six_fold_new_Diff_400: 0.005376344086021506\n",
      "\t-> Selected: OV_six_fold_CV_400\n",
      "\tError: 0.0, Alpha: 8.0\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.array([1/tr_x_val_1.shape[0]]*tr_x_val_1.shape[0])\n",
    "model_list = []\n",
    "alpha_list = []\n",
    "type_list = []\n",
    "sample_weight_list = []\n",
    "error_list = []\n",
    "\n",
    "for step in range(max_model_num):\n",
    "    print(\"# \"+str(step+1)+\"/\"+str(max_model_num)+\"th step\")\n",
    "    best_model = 0\n",
    "    best_weighted_errors = 0\n",
    "    best_weighted_error_sum = -1\n",
    "    best_alpha = 0\n",
    "    best_error = 0\n",
    "    best_type = 0\n",
    "    \n",
    "    for t in range(4):\n",
    "        \n",
    "        tr_x_val = tr_x_val_list[t]\n",
    "        tr_y_val = tr_y_val_list[t]\n",
    "        #ts_x_val = ts_x_val_list[t]\n",
    "        #ts_y_val = ts_y_val_list[t]\n",
    "        model_t = train_model(tr_x=tr_x_val, tr_y=tr_y_val)\n",
    "        \n",
    "        pred_Y = np.array(model_performance(using_model = model_t, tr_x_val=tr_x_val, tr_y_val=tr_y_val, output_list=[\"labeled_tr_predictions\"]))[0]\n",
    "        #if pred_Y is 0 or 1, all weighted predict Y of 0 samples will be just 0\n",
    "        pred_Y_proc = pred_Y*2-1\n",
    "        Y_proc = np.array(tr_y_val_list[t])*2-1\n",
    "        sample_weight = np.array([1/tr_x_val.shape[0]]*tr_x_val.shape[0])\n",
    "        error = abs(Y_proc - pred_Y_proc)/2\n",
    "        weighted_errors = sample_weight*error.T\n",
    "        weighted_error_sum = np.sum(weighted_errors)\n",
    "        print(\"Error of \"+types[t]+\": \"+str(weighted_error_sum))\n",
    "        \n",
    "        if best_weighted_error_sum == -1 or best_weighted_error_sum > weighted_error_sum:\n",
    "            #print(error)\n",
    "            #print(weighted_errors)\n",
    "            \n",
    "            best_model = model_t\n",
    "            best_weighted_errors = weighted_errors\n",
    "            best_weighted_error_sum = np.sum(weighted_errors)\n",
    "            best_alpha = math.log((1-min(best_weighted_error_sum, (1-math.exp(-16))))/max(best_weighted_error_sum, math.exp(-16)))/2\n",
    "            best_error = error\n",
    "            best_type = t\n",
    "\n",
    "    print(\"\\t-> Selected: \"+types[best_type])\n",
    "    print(\"\\tError: \"+str(best_weighted_error_sum)+\", Alpha: \"+str(best_alpha))\n",
    "    error_term = (best_error*2)-1\n",
    "    updated_weight = sample_weight*np.exp((-1)*best_alpha*error_term).T\n",
    "    sample_weight = updated_weight / np.sum(updated_weight)\n",
    "    \n",
    "    model_list.append(best_model)\n",
    "    alpha_list.append(best_alpha)\n",
    "    type_list.append(best_type)\n",
    "    sample_weight_list.append(sample_weight)\n",
    "    error_list.append(best_error)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1th model: OV_six_fold_new_Diff_400\n",
      "tr_acc: 0.9946236559139785\n",
      "ts_acc: 0.8064516186714172\n",
      "tr_acc_tot: 0.9946236559139785\n",
      "ts_acc_tot: 0.8064516129032258\n",
      "\n",
      "# 2th model: OV_six_fold_Var_400\n",
      "tr_acc: 0.9946236559139785\n",
      "ts_acc: 0.4838709533214569\n",
      "tr_acc_tot: 0.9946236559139785\n",
      "ts_acc_tot: 0.7096774193548387\n",
      "\n",
      "# 3th model: OV_six_fold_CV_400\n",
      "tr_acc: 1.0\n",
      "ts_acc: 0.5161290168762207\n",
      "tr_acc_tot: 1.0\n",
      "ts_acc_tot: 0.5161290322580645\n",
      "\n",
      "# 4th model: OV_six_fold_Var_400\n",
      "tr_acc: 1.0\n",
      "ts_acc: 0.5806451439857483\n",
      "tr_acc_tot: 1.0\n",
      "ts_acc_tot: 0.6774193548387097\n",
      "\n",
      "# 5th model: OV_six_fold_new_Diff_400\n",
      "tr_acc: 1.0\n",
      "ts_acc: 0.8064516186714172\n",
      "tr_acc_tot: 1.0\n",
      "ts_acc_tot: 0.7419354838709677\n",
      "\n",
      "# 6th model: OV_six_fold_new_Diff_400\n",
      "tr_acc: 1.0\n",
      "ts_acc: 0.7419354915618896\n",
      "tr_acc_tot: 1.0\n",
      "ts_acc_tot: 0.8064516129032258\n",
      "\n",
      "# 7th model: OV_six_fold_CV_400\n",
      "tr_acc: 1.0\n",
      "ts_acc: 0.5161290168762207\n",
      "tr_acc_tot: 1.0\n",
      "ts_acc_tot: 0.7419354838709677\n",
      "\n",
      "# 8th model: OV_six_fold_new_Diff_400\n",
      "tr_acc: 1.0\n",
      "ts_acc: 0.6451612710952759\n",
      "tr_acc_tot: 1.0\n",
      "ts_acc_tot: 0.7419354838709677\n",
      "\n",
      "# 9th model: OV_six_fold_new_Diff_400\n",
      "tr_acc: 1.0\n",
      "ts_acc: 0.7096773982048035\n",
      "tr_acc_tot: 1.0\n",
      "ts_acc_tot: 0.7096774193548387\n",
      "\n",
      "# 10th model: OV_six_fold_CV_400\n",
      "tr_acc: 1.0\n",
      "ts_acc: 0.6129032373428345\n",
      "tr_acc_tot: 1.0\n",
      "ts_acc_tot: 0.7096774193548387\n",
      "\n",
      "####################### Final acc: 1.0, 0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "tr_sum = 0\n",
    "ts_sum = 0\n",
    "alpha_sum = 0\n",
    "\n",
    "for m in range(len(model_list)):\n",
    "    best_type = type_list[m]\n",
    "    print(\"# \"+str(m+1)+\"th model: \"+types[best_type])\n",
    "    tr_pred_Y = np.array(model_performance(using_model = model_list[m], tr_x_val=tr_x_val_list[best_type], tr_y_val=tr_y_val_list[best_type], ts_x_val=ts_x_val_list[best_type], ts_y_val=ts_y_val_list[best_type], output_list=[\"labeled_tr_predictions\"]))[0]\n",
    "    ts_pred_Y = np.array(model_performance(using_model = model_list[m], tr_x_val=tr_x_val_list[best_type], tr_y_val=tr_y_val_list[best_type], ts_x_val=ts_x_val_list[best_type], ts_y_val=ts_y_val_list[best_type], output_list=[\"labeled_ts_predictions\"]))[0]\n",
    "    tr_acc, ts_acc = np.array(model_performance(using_model = model_list[m], tr_x_val=tr_x_val_list[best_type], tr_y_val=tr_y_val_list[best_type], ts_x_val=ts_x_val_list[best_type], ts_y_val=ts_y_val_list[best_type], output_list=[\"tr_accuracy\", \"ts_accuracy\"]))\n",
    "    print(\"tr_acc: \"+str(tr_acc))\n",
    "    print(\"ts_acc: \"+str(ts_acc))\n",
    "\n",
    "    tr_pred_Y_proc = tr_pred_Y*2 -1 \n",
    "    ts_pred_Y_proc = ts_pred_Y*2 -1\n",
    "    \n",
    "    #print(tr_pred_Y)\n",
    "    #print(tr_pred_Y_proc)\n",
    "    \n",
    "    tr_sum = tr_sum + alpha_list[m]*tr_pred_Y_proc\n",
    "    ts_sum = ts_sum + alpha_list[m]*ts_pred_Y_proc\n",
    "    alpha_sum = alpha_sum + alpha_list[m]\n",
    "    \n",
    "    tr_sum_tot = np.where(tr_sum / alpha_sum > 0, 1, 0).flatten()\n",
    "    ts_sum_tot = np.where(ts_sum / alpha_sum > 0, 1, 0).flatten()\n",
    "    \n",
    "    tr_acc_tot = 1 - np.sum(np.abs(tr_sum_tot - np.asarray(tr_y_val_list[best_type]))) / tr_sum_tot.shape[0]\n",
    "    ts_acc_tot = 1 - np.sum(np.abs(ts_sum_tot - np.asarray(ts_y_val_list[best_type]))) / ts_sum_tot.shape[0]\n",
    "\n",
    "    print(\"tr_acc_tot: \"+str(tr_acc_tot))\n",
    "    print(\"ts_acc_tot: \"+str(ts_acc_tot)+\"\\n\")\n",
    "    \n",
    "    \n",
    "print(\"####################### Final acc: \"+str(tr_acc_tot)+\", \"+str(ts_acc_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0, -1,  0,  0,  0, -1,  0,  0,  0,  0, -1,  0,  0,  0,  1,  0,\n",
       "        0,  0,  0,  0,  0, -1,  0,  0,  1,  1,  0,  0,  0,  0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_sum_tot - np.asarray(ts_y_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
