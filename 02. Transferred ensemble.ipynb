{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Input, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, load_model, Sequential \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from os import listdir\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Functions library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide raw data into train / test & x_val / y_val\n",
    "def data_split(raw_data, index_col, test_index):\n",
    "    \n",
    "    train_data = raw_data.iloc[list(raw_data.iloc[:,index_col]!=test_index)]\n",
    "    test_data = raw_data.iloc[list(raw_data.iloc[:,index_col]==test_index)]\n",
    "    \n",
    "    y_val = train_data.Platinum_Status\n",
    "    x_val = train_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val = test_data.Platinum_Status\n",
    "    test_x_val = test_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    return train_data, test_data, y_val, x_val, test_y_val, test_x_val\n",
    "\n",
    "    # raw_data: have gene_expressions(maybe multiple columns), index column, Platinum_Status column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all of model performance \n",
    "# - predictions(probability) / labeled predictions(0/1) / Loss / Accuracy / Sensitivity / Specificity / AUC values of Train / Test dataset.\n",
    "# using trained models, or you can put predictions(probability) passively(in this case, Loss & Accuracy do not provided.)\n",
    "def model_performance(information=False, Input_Prediction_Passively=False, using_model=None, tr_predictions=None, ts_predictions=None, tr_x_val=None, tr_y_val=None, ts_x_val=None, ts_y_val=None, output_list=None):\n",
    "    \n",
    "    if information == True:            \n",
    "        print(\"options model_performance:\\n1) using_model: keras models that you want to check performance. \\\"Input_Prediction_Passive\\\" option for input prediction list instead using models.\\n3) tr_predictions & ts_predictions: prediction input passively. put this data only when not using keras model.\\n4) tr_x_val & ts_x_val: input samples of train/test samples.\\n4) tr_y_val & ts_y_val: results of train/test samples.\\n5) output_list: return values that you want to recieve.\\n CAUTION: Essential variable.\\n\\t tr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\\n\\n* CAUTION: if 'None' value is returned, please check your input tr inputs(None value for tr outputs) or ts inputs(None value for ts outputs).\") \n",
    "        return 0\n",
    "    elif information != False:\n",
    "        print(\"for using information options, please set 'information' variable for 'True'\")\n",
    "        return -1\n",
    "    \n",
    "    if using_model is None:\n",
    "        if Input_Prediction_Passively == False:\n",
    "            print(\"ERROR: There are no models for using.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\") \n",
    "            return -1\n",
    "        elif (tr_predictions is None) and (ts_predictions is None): # No model/prediction input. no performance should be calculated.\n",
    "                print(\"ERROR: Input prediction list instead using saved model.\")\n",
    "                return -1\n",
    "        else: # No model input, but Input_Prediction_Passively is True & input prediction is valid.\n",
    "            tr_loss,tr_accuracy= None, None\n",
    "            ts_loss,ts_accuracy= None, None\n",
    "            \n",
    "    elif Input_Prediction_Passively == True: # both of model/prediction putted, could cause confusing.\n",
    "        ch = input(\"You put both model and prediction. Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "        while 1:\n",
    "            if ch == 'p':\n",
    "                using_model = None\n",
    "                break\n",
    "            elif ch == 'm':\n",
    "                tr_predictions = None\n",
    "                ts_predictions = None\n",
    "                break\n",
    "            elif ch == 'e':\n",
    "                return 0\n",
    "            else:\n",
    "                print(\"you put worng option: \"+str(ch))\n",
    "            ch = input(\"Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "                \n",
    "    if output_list is None:\n",
    "        print(\"ERROR: There are no output_list for return.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\")\n",
    "        return -1\n",
    "    \n",
    "    if not(tr_x_val is None) and not(tr_y_val is None):\n",
    "        # predict tr result only when no tr_prediction input\n",
    "        if tr_predictions is None:\n",
    "            tr_loss,tr_accuracy= using_model.evaluate(tr_x_val,tr_y_val)\n",
    "            tr_predictions = using_model.predict(tr_x_val)\n",
    "        # tr sensitivity / specificity\n",
    "        labeled_tr_predictions = np.where(tr_predictions > 0.5, 1, 0).flatten()\n",
    "        tr_sensitivity, tr_specificity = check_correct(labeled_tr_predictions, tr_y_val)\n",
    "        tr_predictions_flat = tr_predictions[:,0]   \n",
    "        # roc(tr)\n",
    "        fpr_tr, tpr_tr, threshold_tr = metrics.roc_curve(tr_y_val, tr_predictions)\n",
    "        roc_auc_tr = metrics.auc(fpr_tr, tpr_tr)\n",
    "    \n",
    "    if not(ts_x_val is None) and not(ts_y_val is None):\n",
    "        # predict ts result only when no ts_prediction input\n",
    "        if ts_predictions is None:\n",
    "            ts_loss,ts_accuracy= using_model.evaluate(ts_x_val,ts_y_val)\n",
    "            ts_predictions = using_model.predict(ts_x_val)\n",
    "        labeled_ts_predictions = np.where(ts_predictions > 0.5, 1, 0).flatten()\n",
    "        ts_sensitivity, ts_specificity = check_correct(labeled_ts_predictions, ts_y_val)\n",
    "        ts_predictions_flat = ts_predictions[:,0]   \n",
    "        # roc(ts)\n",
    "        fpr_ts, tpr_ts, threshold_ts = metrics.roc_curve(ts_y_val, ts_predictions)\n",
    "        roc_auc_ts = metrics.auc(fpr_ts, tpr_ts)    \n",
    "    \n",
    "    if (not(tr_x_val is None) and not(tr_y_val is None)) and (not(ts_x_val is None) and not(ts_y_val is None)):\n",
    "        y_true = np.append(tr_y_val, ts_y_val)\n",
    "        y_pred = np.append(tr_predictions, ts_predictions)\n",
    "        fpr_total, tpr_total, threshold_total = metrics.roc_curve(y_true, y_pred)\n",
    "        roc_auc_total = metrics.auc(fpr_total, tpr_total)\n",
    "        \n",
    "        \n",
    "    return_list = []\n",
    "    \n",
    "    for output in output_list:\n",
    "        \n",
    "        if(output == \"tr_loss\"):\n",
    "            return_list.append(tr_loss)\n",
    "                               \n",
    "        elif(output == \"tr_accuracy\"):\n",
    "            return_list.append(tr_accuracy)\n",
    "                               \n",
    "        elif(output == \"tr_sensitivity\"):\n",
    "            return_list.append(tr_sensitivity)\n",
    "                               \n",
    "        elif(output == \"tr_specificity\"):\n",
    "            return_list.append(tr_specificity)\n",
    "                               \n",
    "        elif(output == \"tr_predictions\"):\n",
    "            return_list.append(tr_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_tr_predictions\"):\n",
    "            return_list.append(labeled_tr_predictions)\n",
    "                               \n",
    "        elif(output == \"tr_predictions_flat\"):\n",
    "            return_list.append(tr_predictions_flat)\n",
    "            \n",
    "        elif(output == \"roc_auc_tr\"):\n",
    "            return_list.append(roc_auc_tr)\n",
    "\n",
    "        elif(output == \"ts_loss\"):\n",
    "            return_list.append(ts_loss)\n",
    "                               \n",
    "        elif(output == \"ts_accuracy\"):\n",
    "            return_list.append(ts_accuracy)\n",
    "                               \n",
    "        elif(output == \"ts_sensitivity\"):\n",
    "            return_list.append(ts_sensitivity)\n",
    "                               \n",
    "        elif(output == \"ts_specificity\"):\n",
    "            return_list.append(ts_specificity)\n",
    "                               \n",
    "        elif(output == \"ts_predictions\"):\n",
    "            return_list.append(ts_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_ts_predictions\"):\n",
    "            return_list.append(labeled_ts_predictions)\n",
    "                               \n",
    "        elif(output == \"ts_predictions_flat\"):\n",
    "            return_list.append(ts_predictions_flat)\n",
    "        \n",
    "        elif(output == \"roc_auc_ts\"):\n",
    "            return_list.append(roc_auc_ts)\n",
    "            \n",
    "        elif(output == \"roc_auc_total\"):\n",
    "            return_list.append(roc_auc_total)\n",
    "                               \n",
    "        else:\n",
    "            print(\"There are no options <\"+str(output)+\">. Please refer these output options:\\ntr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\")\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation: import & preprocessing data + import module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input path & name of models / raw data for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model_path & each model_name.\n",
    "# Caution: If you want to change input models, you also have to change selected data types.\n",
    "\n",
    "# ex) if you want to put these models: two CV, one Annot_3000,  one Var, one new_Diff, one Clin.\n",
    "\n",
    "'''\n",
    "\n",
    "m_1_name = CV_400_1.h5\n",
    "m_2_name = CV_400_2.h5\n",
    "m_3_name = Annot_3000_400_1.h5\n",
    "m_4_name = Var_400_0.h5\n",
    "m_5_name = new_Diff_400_2.h5\n",
    "m_6_name = Clin_400_1.h5\n",
    "--> if you change this part,\n",
    "\n",
    "select_types = [types[1], # \"inter_by_names_CV_400\"\n",
    "                types[1], # \"inter_by_names_CV_400\"\n",
    "                types[0], # \"inter_by_names_Annotation3000_400\"\n",
    "                types[2], # \"inter_by_names_Var_400\"\n",
    "                types[3], # \"inter_by_names_new_Diff_400\"\n",
    "                types[4]] # \"inter_by_names_Clin\"\n",
    "--> you also have to change this part.\n",
    "\n",
    "'''\n",
    "\n",
    "types = [\"OV_six_fold_Annotation3000_400\", \n",
    "         \"OV_six_fold_CV_400\", \n",
    "         \"OV_six_fold_Var_400\", \"OV_six_fold_new_Diff_400\",\n",
    "         \"OV_six_fold_Clin\", \n",
    "         \"OV_six_fold_SNV\" \n",
    "         ]\n",
    "\n",
    "# input model path & ensemble data(Transcriptome, Cinical Information, Somatic Mutation data)\n",
    "# data path(server): /home/tjahn/TCGA_Ovary/01.Data/DNN/TC_intersect_subsamples_by_names \n",
    "model_path = \"C:/test/best_models/\"\n",
    "path = \"C:/test/TC_six_fold_subsamples/\"\n",
    "save_model_path = \"C:/test/best_models/model/\"\n",
    "save_prediction_path = \"C:/test/best_models/predictions\"\n",
    "\n",
    "# change 'types' and 'load_model' part for using another models.\n",
    "m_1_name = \"new_Diff_400_2.h5\"\n",
    "m_2_name = \"CV_400_0.h5\"\n",
    "m_3_name = \"Var_400_0.h5\"\n",
    "m_4_name = \"new_Diff_400_0.h5\"\n",
    "m_5_name = \"Clin_2.h5\"\n",
    "m_6_name = \"Var_400_1.h5\"\n",
    "select_types = [types[3],\n",
    "                types[1],\n",
    "                types[2],\n",
    "                types[3],\n",
    "                types[4],\n",
    "                types[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "select = [1, 3, 4]\n",
    "print(select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] file_name:  OV_six_fold_new_Diff_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[2] file_name:  OV_six_fold_CV_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[3] file_name:  OV_six_fold_Var_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[4] file_name:  OV_six_fold_new_Diff_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[5] file_name:  OV_six_fold_Annotation3000_400 \n",
      "sample : 153  \n",
      "features : 400\n",
      "[6] file_name:  OV_six_fold_Var_400 \n",
      "sample : 153  \n",
      "features : 400\n"
     ]
    }
   ],
   "source": [
    "file_1 = path+select_types[0]+\".csv\"\n",
    "file_2 = path+select_types[1]+\".csv\"\n",
    "file_3 = path+select_types[2]+\".csv\"\n",
    "file_4 = path+select_types[3]+\".csv\"\n",
    "file_5 = path+select_types[4]+\".csv\"\n",
    "file_6 = path+select_types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "full_data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "full_data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "full_data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "full_data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "full_data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "full_data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "data_1 = full_data_1.iloc[list(full_data_1.iloc[:,-1]!=6)]\n",
    "data_2 = full_data_2.iloc[list(full_data_2.iloc[:,-1]!=6)]\n",
    "data_3 = full_data_3.iloc[list(full_data_3.iloc[:,-1]!=6)]\n",
    "data_4 = full_data_4.iloc[list(full_data_4.iloc[:,-1]!=6)]\n",
    "data_5 = full_data_5.iloc[list(full_data_5.iloc[:,-1]!=6)]\n",
    "data_6 = full_data_6.iloc[list(full_data_6.iloc[:,-1]!=6)]\n",
    "\n",
    "\n",
    "sample_1,features_1 = data_1.shape\n",
    "sample_2,features_2 = data_2.shape\n",
    "sample_3,features_3 = data_3.shape\n",
    "sample_4,features_4 = data_4.shape\n",
    "sample_5,features_5 = data_5.shape\n",
    "sample_6,features_6 = data_6.shape\n",
    "\n",
    "# Data frame include index & Platinum_Status column, substract 2 to calculate real number of features \n",
    "[features_1, features_2, features_3, features_4, features_5, features_6] = [features_1-2, features_2-2, features_3-2, features_4-2, features_5-2, features_6-2]\n",
    "\n",
    "print(\"[1] file_name: \", select_types[0], \"\\nsample : {}  \\nfeatures : {}\".format(sample_1,features_1))\n",
    "print(\"[2] file_name: \", select_types[1], \"\\nsample : {}  \\nfeatures : {}\".format(sample_2,features_2))\n",
    "print(\"[3] file_name: \", select_types[2], \"\\nsample : {}  \\nfeatures : {}\".format(sample_3,features_3))\n",
    "print(\"[4] file_name: \", select_types[3], \"\\nsample : {}  \\nfeatures : {}\".format(sample_4,features_4))\n",
    "print(\"[5] file_name: \", select_types[4], \"\\nsample : {}  \\nfeatures : {}\".format(sample_5,features_5))\n",
    "print(\"[6] file_name: \", select_types[5], \"\\nsample : {}  \\nfeatures : {}\".format(sample_6,features_6))\n",
    "\n",
    "# Split Train Test Data\n",
    "\n",
    "train_data_1, test_data_1, y_val_1, x_val_1, test_y_val_1, test_x_val_1 = data_split(raw_data = data_1, index_col = -1, test_index = 1)\n",
    "train_data_2, test_data_2, y_val_2, x_val_2, test_y_val_2, test_x_val_2 = data_split(raw_data = data_2, index_col = -1, test_index = 1)\n",
    "train_data_3, test_data_3, y_val_3, x_val_3, test_y_val_3, test_x_val_3 = data_split(raw_data = data_3, index_col = -1, test_index = 1)\n",
    "train_data_4, test_data_4, y_val_4, x_val_4, test_y_val_4, test_x_val_4 = data_split(raw_data = data_4, index_col = -1, test_index = 1)\n",
    "train_data_5, test_data_5, y_val_5, x_val_5, test_y_val_5, test_x_val_5 = data_split(raw_data = data_5, index_col = -1, test_index = 1)\n",
    "train_data_6, test_data_6, y_val_6, x_val_6, test_y_val_6, test_x_val_6 = data_split(raw_data = data_6, index_col = -1, test_index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_model = load_model(\"G:/내 드라이브/Class/6과 7 사이(hell)/Lab/TCGA 난소암/Best_Models/18.09.15/best_models/Annot_3000_400_0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 96us/step\n",
      "Overall AUC:  0.9427061310782241\n",
      "Train AUC:  0.9822860962566845\n",
      "Test AUC:  0.7575757575757575\n",
      "Train Accuracy: 0.8852458957765923\n",
      "Train Sensitivities & Specificities : 0.5882352941176471, 1.0\n",
      "Test Accuracy: 0.774193525314331\n",
      "Test Sensitivities & Specificities : 0.2222222222222222, 1.0\n"
     ]
    }
   ],
   "source": [
    "model_6_l = load_model(model_path+m_6_name)\n",
    "m_6_l_output_list = model_performance(\n",
    "    information = False, using_model=model_6_l,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_6, tr_y_val=y_val_6, ts_x_val=test_x_val_6, ts_y_val=test_y_val_6,\n",
    "    output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "m_6_tr_accuracy, m_6_tr_sensitivity, m_6_tr_specificity, m_6_tr_predictions, m_6_labeled_tr_predictions, m_6_tr_predictions_flat, m_6_roc_auc_tr, m_6_ts_accuracy, m_6_ts_sensitivity, m_6_ts_specificity, m_6_ts_predictions,m_6_labeled_ts_predictions, m_6_ts_predictions_flat, m_6_roc_auc_ts, m_6_roc_auc_total = m_6_l_output_list\n",
    "model_6_l_new = Model(inputs = model_6_l.input, outputs=model_6_l.get_layer(model_6_l.layers[-2].name).output)\n",
    "\n",
    "print(\"Overall AUC: \", m_6_roc_auc_total)\n",
    "print(\"Train AUC: \", m_6_roc_auc_tr)\n",
    "print(\"Test AUC: \", m_6_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_6_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_6_tr_sensitivity)+\", \"+str(m_6_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_6_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_6_ts_sensitivity)+\", \"+str(m_6_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import separate models & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 744us/step\n",
      "31/31 [==============================] - 0s 97us/step\n",
      "OV_six_fold_new_Diff_400\n",
      "Train Accuracy: 0.9918032786885246\n",
      "Test Accuracy: 0.8387096524238586\n",
      "122/122 [==============================] - 0s 904us/step\n",
      "31/31 [==============================] - 0s 193us/step\n",
      "OV_six_fold_CV_400\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.6451612710952759\n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 97us/step\n",
      "OV_six_fold_Var_400\n",
      "Train Accuracy: 0.9426229449569202\n",
      "Test Accuracy: 0.7096773982048035\n",
      "122/122 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "OV_six_fold_new_Diff_400\n",
      "Train Accuracy: 0.9508196662683956\n",
      "Test Accuracy: 0.8387096524238586\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 257us/step\n",
      "OV_six_fold_Clin\n",
      "Train Accuracy: 0.754098364564239\n",
      "Test Accuracy: 0.8064516186714172\n",
      "122/122 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 96us/step\n",
      "OV_six_fold_Var_400\n",
      "Train Accuracy: 0.8852458957765923\n",
      "Test Accuracy: 0.774193525314331\n"
     ]
    }
   ],
   "source": [
    "# model load & evaluation. <model_n_l> is full-layer model, <model_n_l_new> is without-sigmoid-layer model.\n",
    "'''\n",
    "Each model's tr_accuracy can be differ to original model, but ts_accuracy should be same to original tested models.\n",
    "Because we using full-size data(about 200 patients data used Transcriptome, Clinical, SNV models.) for train each models.\n",
    "In contrast, in this code, we using ensemble-input data(intersected 153 patients).\n",
    "For-training-patients may be different in ensemble data and whole size data, but for-test-patients are the same.\n",
    "'''\n",
    "\n",
    "model_1_l = load_model(model_path+m_1_name)\n",
    "m_1_l_output_list = model_performance(\n",
    "    information = False, using_model=model_1_l,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_1, tr_y_val=y_val_1, ts_x_val=test_x_val_1, ts_y_val=test_y_val_1,\n",
    "    output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "m_1_tr_accuracy, m_1_tr_sensitivity, m_1_tr_specificity, m_1_tr_predictions, m_1_labeled_tr_predictions, m_1_tr_predictions_flat, m_1_roc_auc_tr, m_1_ts_accuracy, m_1_ts_sensitivity, m_1_ts_specificity, m_1_ts_predictions,m_1_labeled_ts_predictions, m_1_ts_predictions_flat, m_1_roc_auc_ts, m_1_roc_auc_total = m_1_l_output_list\n",
    "model_1_l_new = Model(inputs = model_1_l.input, outputs=model_1_l.get_layer(model_1_l.layers[-2].name).output)\n",
    "\n",
    "print(select_types[0])\n",
    "print(\"Train Accuracy: {}\".format(m_1_tr_accuracy))\n",
    "print(\"Test Accuracy: {}\".format(m_1_ts_accuracy))\n",
    "\n",
    "model_2_l = load_model(model_path+m_2_name)\n",
    "m_2_l_output_list = model_performance(\n",
    "    information = False, using_model=model_2_l,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_2, tr_y_val=y_val_2, ts_x_val=test_x_val_2, ts_y_val=test_y_val_2,\n",
    "    output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "m_2_tr_accuracy, m_2_tr_sensitivity, m_2_tr_specificity, m_2_tr_predictions, m_2_labeled_tr_predictions, m_2_tr_predictions_flat, m_2_roc_auc_tr, m_2_ts_accuracy, m_2_ts_sensitivity, m_2_ts_specificity, m_2_ts_predictions,m_2_labeled_ts_predictions, m_2_ts_predictions_flat, m_2_roc_auc_ts, m_2_roc_auc_total = m_2_l_output_list\n",
    "model_2_l_new = Model(inputs = model_2_l.input, outputs=model_2_l.get_layer(model_2_l.layers[-2].name).output)\n",
    "\n",
    "print(select_types[1])\n",
    "print(\"Train Accuracy: {}\".format(m_2_tr_accuracy))\n",
    "print(\"Test Accuracy: {}\".format(m_2_ts_accuracy))\n",
    "\n",
    "model_3_l = load_model(model_path+m_3_name)\n",
    "m_3_l_output_list = model_performance(\n",
    "    information = False, using_model=model_3_l,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_3, tr_y_val=y_val_3, ts_x_val=test_x_val_3, ts_y_val=test_y_val_3,\n",
    "    output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "m_3_tr_accuracy, m_3_tr_sensitivity, m_3_tr_specificity, m_3_tr_predictions, m_3_labeled_tr_predictions, m_3_tr_predictions_flat, m_3_roc_auc_tr, m_3_ts_accuracy, m_3_ts_sensitivity, m_3_ts_specificity, m_3_ts_predictions,m_3_labeled_ts_predictions, m_3_ts_predictions_flat, m_3_roc_auc_ts, m_3_roc_auc_total = m_3_l_output_list\n",
    "model_3_l_new = Model(inputs = model_3_l.input, outputs=model_3_l.get_layer(model_3_l.layers[-2].name).output)\n",
    "\n",
    "print(select_types[2])\n",
    "print(\"Train Accuracy: {}\".format(m_3_tr_accuracy))\n",
    "print(\"Test Accuracy: {}\".format(m_3_ts_accuracy))\n",
    "\n",
    "model_4_l = load_model(model_path+m_4_name)\n",
    "m_4_l_output_list = model_performance(\n",
    "    information = False, using_model=model_4_l,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_4, tr_y_val=y_val_4, ts_x_val=test_x_val_4, ts_y_val=test_y_val_4,\n",
    "    output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "m_4_tr_accuracy, m_4_tr_sensitivity, m_4_tr_specificity, m_4_tr_predictions, m_4_labeled_tr_predictions, m_4_tr_predictions_flat, m_4_roc_auc_tr, m_4_ts_accuracy, m_4_ts_sensitivity, m_4_ts_specificity, m_4_ts_predictions,m_4_labeled_ts_predictions, m_4_ts_predictions_flat, m_4_roc_auc_ts, m_4_roc_auc_total = m_4_l_output_list\n",
    "model_4_l_new = Model(inputs = model_4_l.input, outputs=model_4_l.get_layer(model_4_l.layers[-2].name).output)\n",
    "\n",
    "\n",
    "print(select_types[3])\n",
    "print(\"Train Accuracy: {}\".format(m_4_tr_accuracy))\n",
    "print(\"Test Accuracy: {}\".format(m_4_ts_accuracy))\n",
    "\n",
    "model_5_l = load_model(model_path+m_5_name)\n",
    "m_5_l_output_list = model_performance(\n",
    "    information = False, using_model=model_5_l,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_5, tr_y_val=y_val_5, ts_x_val=test_x_val_5, ts_y_val=test_y_val_5,\n",
    "    output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "m_5_tr_accuracy, m_5_tr_sensitivity, m_5_tr_specificity, m_5_tr_predictions, m_5_labeled_tr_predictions, m_5_tr_predictions_flat, m_5_roc_auc_tr, m_5_ts_accuracy, m_5_ts_sensitivity, m_5_ts_specificity, m_5_ts_predictions,m_5_labeled_ts_predictions, m_5_ts_predictions_flat, m_5_roc_auc_ts, m_5_roc_auc_total = m_5_l_output_list\n",
    "model_5_l_new = Model(inputs = model_5_l.input, outputs=model_5_l.get_layer(model_5_l.layers[-2].name).output)\n",
    "\n",
    "print(select_types[4])\n",
    "print(\"Train Accuracy: {}\".format(m_5_tr_accuracy))\n",
    "print(\"Test Accuracy: {}\".format(m_5_ts_accuracy))\n",
    "\n",
    "model_6_l = load_model(model_path+m_6_name)\n",
    "m_6_l_output_list = model_performance(\n",
    "    information = False, using_model=model_6_l,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_6, tr_y_val=y_val_6, ts_x_val=test_x_val_6, ts_y_val=test_y_val_6,\n",
    "    output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "m_6_tr_accuracy, m_6_tr_sensitivity, m_6_tr_specificity, m_6_tr_predictions, m_6_labeled_tr_predictions, m_6_tr_predictions_flat, m_6_roc_auc_tr, m_6_ts_accuracy, m_6_ts_sensitivity, m_6_ts_specificity, m_6_ts_predictions,m_6_labeled_ts_predictions, m_6_ts_predictions_flat, m_6_roc_auc_ts, m_6_roc_auc_total = m_6_l_output_list\n",
    "model_6_l_new = Model(inputs = model_6_l.input, outputs=model_6_l.get_layer(model_6_l.layers[-2].name).output)\n",
    "\n",
    "print(select_types[5])\n",
    "print(\"Train Accuracy: {}\".format(m_6_tr_accuracy))\n",
    "print(\"Test Accuracy: {}\".format(m_6_ts_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# save prediction result.\\ntr_df_m_1 = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(m_1_tr_predictions_flat), \\n                        \"prediction\":list(m_1_labeled_tr_predictions), \"Platinum_Status\":list(y_val_1)})\\ntr_df_m_1.to_csv(save_prediction_path+\"prediction_result_m_1_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\nts_df_m_1 = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(m_1_ts_predictions_flat), \\n                        \"prediction\":list(m_1_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_1)})\\nts_df_m_1.to_csv(save_prediction_path+\"prediction_result_m_1_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\ntr_df_m_2 = pd.DataFrame(data={\"patient\":list(train_data_2.index), \"hypothesis 1\": list(m_2_tr_predictions_flat), \\n                        \"prediction\":list(m_2_labeled_tr_predictions), \"Platinum_Status\":list(y_val_2)})\\ntr_df_m_2.to_csv(save_prediction_path+\"prediction_result_m_2_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\nts_df_m_2 = pd.DataFrame(data={\"patient\":list(test_data_2.index), \"hypothesis 1\": list(m_2_ts_predictions_flat), \\n                        \"prediction\":list(m_2_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_2)})\\nts_df_m_2.to_csv(save_prediction_path+\"prediction_result_m_2_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\ntr_df_m_3 = pd.DataFrame(data={\"patient\":list(train_data_3.index), \"hypothesis 1\": list(m_3_tr_predictions_flat), \\n                        \"prediction\":list(m_3_labeled_tr_predictions), \"Platinum_Status\":list(y_val_3)})\\ntr_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\nts_df_m_3 = pd.DataFrame(data={\"patient\":list(test_data_3.index), \"hypothesis 1\": list(m_3_ts_predictions_flat), \\n                        \"prediction\":list(m_3_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_3)})\\nts_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\ntr_df_m_4 = pd.DataFrame(data={\"patient\":list(train_data_4.index), \"hypothesis 1\": list(m_4_tr_predictions_flat), \\n                        \"prediction\":list(m_4_labeled_tr_predictions), \"Platinum_Status\":list(y_val_4)})\\ntr_df_m_4.to_csv(save_prediction_path+\"prediction_result_m_4_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\nts_df_m_4 = pd.DataFrame(data={\"patient\":list(test_data_4.index), \"hypothesis 1\": list(m_4_ts_predictions_flat), \\n                        \"prediction\":list(m_4_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_4)})\\nts_df_m_4.to_csv(save_prediction_path+\"prediction_result_m_4_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\ntr_df_m_5 = pd.DataFrame(data={\"patient\":list(train_data_5.index), \"hypothesis 1\": list(m_5_tr_predictions_flat), \\n                        \"prediction\":list(m_5_labeled_tr_predictions), \"Platinum_Status\":list(y_val_5)})\\ntr_df_m_5.to_csv(save_prediction_path+\"prediction_result_m_5_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\nts_df_m_5 = pd.DataFrame(data={\"patient\":list(test_data_5.index), \"hypothesis 1\": list(m_5_ts_predictions_flat), \\n                        \"prediction\":list(m_5_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_5)})\\nts_df_m_5.to_csv(save_prediction_path+\"prediction_result_m_5_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\ntr_df_m_6 = pd.DataFrame(data={\"patient\":list(train_data_6.index), \"hypothesis 1\": list(m_6_tr_predictions_flat), \\n                        \"prediction\":list(m_6_labeled_tr_predictions), \"Platinum_Status\":list(y_val_6)})\\ntr_df_m_6.to_csv(save_prediction_path+\"prediction_result_m_6_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\\n\\nts_df_m_6 = pd.DataFrame(data={\"patient\":list(test_data_6.index), \"hypothesis 1\": list(m_6_ts_predictions_flat), \\n                        \"prediction\":list(m_6_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_6)})\\nts_df_m_6.to_csv(save_prediction_path+\"prediction_result_m_6_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# save prediction result.\n",
    "tr_df_m_1 = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(m_1_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_1_labeled_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_m_1.to_csv(save_prediction_path+\"prediction_result_m_1_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_1 = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(m_1_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_1_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_m_1.to_csv(save_prediction_path+\"prediction_result_m_1_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "tr_df_m_2 = pd.DataFrame(data={\"patient\":list(train_data_2.index), \"hypothesis 1\": list(m_2_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_2_labeled_tr_predictions), \"Platinum_Status\":list(y_val_2)})\n",
    "tr_df_m_2.to_csv(save_prediction_path+\"prediction_result_m_2_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_2 = pd.DataFrame(data={\"patient\":list(test_data_2.index), \"hypothesis 1\": list(m_2_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_2_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_2)})\n",
    "ts_df_m_2.to_csv(save_prediction_path+\"prediction_result_m_2_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "tr_df_m_3 = pd.DataFrame(data={\"patient\":list(train_data_3.index), \"hypothesis 1\": list(m_3_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_3_labeled_tr_predictions), \"Platinum_Status\":list(y_val_3)})\n",
    "tr_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_3 = pd.DataFrame(data={\"patient\":list(test_data_3.index), \"hypothesis 1\": list(m_3_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_3_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_3)})\n",
    "ts_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "tr_df_m_4 = pd.DataFrame(data={\"patient\":list(train_data_4.index), \"hypothesis 1\": list(m_4_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_4_labeled_tr_predictions), \"Platinum_Status\":list(y_val_4)})\n",
    "tr_df_m_4.to_csv(save_prediction_path+\"prediction_result_m_4_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_4 = pd.DataFrame(data={\"patient\":list(test_data_4.index), \"hypothesis 1\": list(m_4_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_4_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_4)})\n",
    "ts_df_m_4.to_csv(save_prediction_path+\"prediction_result_m_4_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "tr_df_m_5 = pd.DataFrame(data={\"patient\":list(train_data_5.index), \"hypothesis 1\": list(m_5_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_5_labeled_tr_predictions), \"Platinum_Status\":list(y_val_5)})\n",
    "tr_df_m_5.to_csv(save_prediction_path+\"prediction_result_m_5_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_5 = pd.DataFrame(data={\"patient\":list(test_data_5.index), \"hypothesis 1\": list(m_5_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_5_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_5)})\n",
    "ts_df_m_5.to_csv(save_prediction_path+\"prediction_result_m_5_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "tr_df_m_6 = pd.DataFrame(data={\"patient\":list(train_data_6.index), \"hypothesis 1\": list(m_6_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_6_labeled_tr_predictions), \"Platinum_Status\":list(y_val_6)})\n",
    "tr_df_m_6.to_csv(save_prediction_path+\"prediction_result_m_6_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_6 = pd.DataFrame(data={\"patient\":list(test_data_6.index), \"hypothesis 1\": list(m_6_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_6_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_6)})\n",
    "ts_df_m_6.to_csv(save_prediction_path+\"prediction_result_m_6_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating seperate model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< OV_six_fold_new_Diff_400 > tr: 0.9918032786885246, ts: 0.8387096524238586\n",
      "< OV_six_fold_CV_400 > tr: 1.0, ts: 0.6451612710952759\n",
      "< OV_six_fold_Var_400 > tr: 0.9426229449569202, ts: 0.7096773982048035\n",
      "< OV_six_fold_new_Diff_400 > tr: 0.9508196662683956, ts: 0.8387096524238586\n",
      "< OV_six_fold_Clin > tr: 0.754098364564239, ts: 0.8064516186714172\n",
      "< OV_six_fold_Var_400 > tr: 0.8852458957765923, ts: 0.774193525314331\n"
     ]
    }
   ],
   "source": [
    "print(\"< \"+select_types[0]+\" > tr: \"+str(m_1_tr_accuracy)+\", ts: \"+str(m_1_ts_accuracy))\n",
    "print(\"< \"+select_types[1]+\" > tr: \"+str(m_2_tr_accuracy)+\", ts: \"+str(m_2_ts_accuracy))\n",
    "print(\"< \"+select_types[2]+\" > tr: \"+str(m_3_tr_accuracy)+\", ts: \"+str(m_3_ts_accuracy))\n",
    "print(\"< \"+select_types[3]+\" > tr: \"+str(m_4_tr_accuracy)+\", ts: \"+str(m_4_ts_accuracy))\n",
    "print(\"< \"+select_types[4]+\" > tr: \"+str(m_5_tr_accuracy)+\", ts: \"+str(m_5_ts_accuracy))\n",
    "print(\"< \"+select_types[5]+\" > tr: \"+str(m_6_tr_accuracy)+\", ts: \"+str(m_6_ts_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# select models for ensemble among loaded models.\n",
    "# CAUTION: Duplication(ex: select = [1, 1, 1, 3, 5]) is allowed, but it is same models, and have same predictions. They have same opinions.\n",
    "\n",
    "select = [1, 3, 4]\n",
    "print(select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) DNN-Combiner Ensmeble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Input listup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tr_predictions = [m_1_tr_predictions, m_2_tr_predictions, m_3_tr_predictions, m_4_tr_predictions, m_5_tr_predictions, m_6_tr_predictions]\n",
    "m_tr_predictions_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_tr_predictions_select.append(m_tr_predictions[select[i]-1])\n",
    "    #print(m_tr_predictions[select[i]-1].shape)\n",
    "    \n",
    "em_x_val = np.concatenate(m_tr_predictions_select, axis=1)\n",
    "\n",
    "m_test_predictions = [m_1_ts_predictions, m_2_ts_predictions, m_3_ts_predictions, m_4_ts_predictions, m_5_ts_predictions, m_6_ts_predictions]\n",
    "m_test_predictions_select = []   \n",
    "#def prediction_result(pathway, tr_x_val, tr_y_val, ts_x_val, ts_y_val, tr_patients, ts_patients)\n",
    "for i in range(len(select)):\n",
    "    m_test_predictions_select.append(m_test_predictions[select[i]-1])\n",
    "    \n",
    "em_test_x_val = np.concatenate(m_test_predictions_select, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 3)\n",
      "(122, 400)\n"
     ]
    }
   ],
   "source": [
    "print(em_x_val.shape)\n",
    "print(x_val_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building original ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################## DNN em ##################################\n",
      "select: [1, 3, 4]\n",
      "OV_six_fold_new_Diff_400\n",
      "OV_six_fold_Var_400\n",
      "OV_six_fold_new_Diff_400\n",
      "#############################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.6773 - acc: 0.7213\n",
      "122/122 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 719us/step - loss: 0.5853 - acc: 0.7213\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 711us/step - loss: 0.5463 - acc: 0.7213\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 728us/step - loss: 0.5159 - acc: 0.7377\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 679us/step - loss: 0.4372 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 695us/step - loss: 0.4491 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 752us/step - loss: 0.3972 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 785us/step - loss: 0.3230 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 768us/step - loss: 0.4708 - acc: 0.7623\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 728us/step - loss: 0.3311 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 719us/step - loss: 0.3309 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 695us/step - loss: 0.3144 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 744us/step - loss: 0.2660 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 678us/step - loss: 0.2995 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 719us/step - loss: 0.2845 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 703us/step - loss: 0.2393 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 858us/step - loss: 0.3067 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 850us/step - loss: 0.3091 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 736us/step - loss: 0.2462 - acc: 0.9590\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 760us/step - loss: 0.3083 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 695us/step - loss: 0.3326 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 752us/step - loss: 0.3064 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 768us/step - loss: 0.3615 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 768us/step - loss: 0.3849 - acc: 0.8852\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 654us/step - loss: 0.3316 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 736us/step - loss: 0.3134 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 703us/step - loss: 0.3917 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 687us/step - loss: 0.2505 - acc: 0.8934\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 728us/step - loss: 0.2067 - acc: 0.9344\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 711us/step - loss: 0.3020 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "##################### DNN ensemble model trained. #####################\n",
      "##################### DNN ensemble model saved. #####################\n"
     ]
    }
   ],
   "source": [
    "print(\"################################## DNN em ##################################\")\n",
    "print(\"select: \"+str(select))\n",
    "for select_type_i in select:\n",
    "    print(select_types[select_type_i-1])\n",
    "print(\"#############################################################################################\")\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "input_drop_out_em = 0.3\n",
    "drop_out_em = 0.5\n",
    "layers = [10]\n",
    "em_tr_loss_best = 100 # for saving best loss value \n",
    "best_em_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "input_em = Input(shape=(len(select),))\n",
    "em_m_dp = Dropout(input_drop_out_em)(input_em)\n",
    "for i in layers:\n",
    "    em_m = Dense(i,activation='relu')(em_m_dp)\n",
    "    em_m_dp = Dropout(drop_out_em)(em_m)\n",
    "em_m_final = em_m_dp\n",
    "output_em = Dense(1, activation=\"sigmoid\")(em_m_final)\n",
    "em_model = Model(inputs=input_em,outputs=output_em)\n",
    "em_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    em_model.fit(em_x_val, y_val_1, batch_size=5, nb_epoch=1)\n",
    "    em_tr_loss=em_model.evaluate(em_x_val,y_val_1)[0]\n",
    "    if em_tr_loss < em_tr_loss_best: # new best model. count reset.\n",
    "        em_tr_loss_best = em_tr_loss\n",
    "        count=0\n",
    "        best_em_model = em_model\n",
    "    if count>10: # no increase three time. stop.\n",
    "        em_model = best_em_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"##################### DNN ensemble model trained. #####################\")\n",
    "# 4) save model\n",
    "\n",
    "em_model.save(save_model_path+\"/m_em.h5\")\n",
    "print(\"##################### DNN ensemble model saved. #####################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _DNN Combiner_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 123us/step\n",
      "31/31 [==============================] - 0s 32us/step\n",
      "Overall AUC:  0.9727272727272727\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8181818181818182\n",
      "Train Accuracy: 0.9754098360655737\n",
      "Train Sensitivities & Specificities : 0.9117647058823529, 1.0\n",
      "Test Accuracy: 0.8709677457809448\n",
      "Test Sensitivities & Specificities : 0.8888888888888888, 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "em_output_list = model_performance(\n",
    "    information = False, using_model=em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=em_x_val, tr_y_val=y_val_1, ts_x_val=em_test_x_val, ts_y_val=test_y_val_1,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "em_tr_loss, em_tr_accuracy, em_tr_sensitivity, em_tr_specificity, em_tr_predictions, em_labeled_tr_predictions, em_tr_predictions_flat, em_roc_auc_tr, em_ts_loss, em_ts_accuracy, em_ts_sensitivity, em_ts_specificity, em_ts_predictions,em_labeled_ts_predictions, em_ts_predictions_flat, em_roc_auc_ts, em_roc_auc_total = em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", em_roc_auc_total)\n",
    "print(\"Train AUC: \", em_roc_auc_tr)\n",
    "print(\"Test AUC: \", em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(em_tr_sensitivity)+\", \"+str(em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(em_ts_sensitivity)+\", \"+str(em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_em = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(em_tr_predictions_flat), \n",
    "                        \"prediction\":list(em_labeled_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_em.to_csv(save_prediction_path+\"prediction_result_DNN_em_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_em = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(em_ts_predictions_flat), \n",
    "                        \"prediction\":list(em_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_em.to_csv(save_prediction_path+\"prediction_result_DNN_em_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Mean Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _mean_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC:  0.9706131078224102\n",
      "Train AUC:  0.9996657754010695\n",
      "Test AUC:  0.7979797979797979\n",
      "Train Accuracy: 0.9836065573770492\n",
      "Train Sensitivities & Specificities : 0.9411764705882353, 1.0\n",
      "Test Accuracy: 0.8064516129032258\n",
      "Test Sensitivities & Specificities : 0.6666666666666666, 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "mean_em_tr_predictions=sum(m_tr_predictions_select)/len(select)\n",
    "mean_em_ts_predictions=sum(m_test_predictions_select)/len(select)\n",
    "\n",
    "mean_em_output_list = model_performance(\n",
    "    information = False, using_model=None,Input_Prediction_Passively = True, \n",
    "    tr_predictions=mean_em_tr_predictions, ts_predictions=mean_em_ts_predictions, \n",
    "    tr_x_val=em_x_val, tr_y_val=y_val_1, ts_x_val=em_test_x_val, ts_y_val=test_y_val_1,\n",
    "    output_list=[\"tr_sensitivity\", \"tr_specificity\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_sensitivity\", \"ts_specificity\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "mean_em_tr_sensitivity, mean_em_tr_specificity,  mean_em_labeled_tr_predictions, mean_em_tr_predictions_flat, mean_em_roc_auc_tr, mean_em_ts_sensitivity, mean_em_ts_specificity, mean_em_labeled_ts_predictions, mean_em_ts_predictions_flat, mean_em_roc_auc_ts, mean_em_roc_auc_total = mean_em_output_list\n",
    "\n",
    "mean_em_tr_accuracy = sum(mean_em_labeled_tr_predictions==y_val_1.values)/len(y_val_1)\n",
    "mean_em_ts_accuracy = sum(mean_em_labeled_ts_predictions==test_y_val_1.values)/len(test_y_val_1)\n",
    "\n",
    "print(\"Overall AUC: \", mean_em_roc_auc_total)\n",
    "print(\"Train AUC: \", mean_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", mean_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(mean_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(mean_em_tr_sensitivity)+\", \"+str(mean_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(mean_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(mean_em_ts_sensitivity)+\", \"+str(mean_em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_mean_em = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(mean_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(mean_em_labeled_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_mean_em.to_csv(save_prediction_path+\"prediction_result_mean_em_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_mean_em = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(mean_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(mean_em_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_mean_em.to_csv(save_prediction_path+\"prediction_result_mean_em_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Transferred Ensemble Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making new input data for t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 5)\n",
      "(122, 200)\n",
      "(122, 200)\n",
      "(31, 5)\n",
      "(31, 200)\n",
      "(31, 200)\n",
      "\n",
      "############################################### t_em x val merged. ###############################################\n",
      "\n",
      "(122, 405)\n",
      "(31, 405)\n"
     ]
    }
   ],
   "source": [
    "results_m_1 = model_1_l_new.predict([x_val_1])\n",
    "results_m_2 = model_2_l_new.predict([x_val_2])\n",
    "results_m_3 = model_3_l_new.predict([x_val_3])\n",
    "results_m_4 = model_4_l_new.predict([x_val_4])\n",
    "results_m_5 = model_5_l_new.predict([x_val_5])\n",
    "results_m_6 = model_6_l_new.predict([x_val_6])\n",
    "\n",
    "results_m_sum = [results_m_1, results_m_2, results_m_3, results_m_4, results_m_5, results_m_6]\n",
    "results_m_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    print(results_m_sum[select[i]-1].shape)\n",
    "    results_m_select.append(results_m_sum[select[i]-1])\n",
    "\n",
    "test_results_m_1 = model_1_l_new.predict([test_x_val_1])\n",
    "test_results_m_2 = model_2_l_new.predict([test_x_val_2])\n",
    "test_results_m_3 = model_3_l_new.predict([test_x_val_3])\n",
    "test_results_m_4 = model_4_l_new.predict([test_x_val_4])\n",
    "test_results_m_5 = model_5_l_new.predict([test_x_val_5])\n",
    "test_results_m_6 = model_6_l_new.predict([test_x_val_6])\n",
    "\n",
    "test_results_m_sum = [test_results_m_1, test_results_m_2, test_results_m_3, test_results_m_4, test_results_m_5, test_results_m_6]\n",
    "test_results_m_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    test_results_m_select.append(test_results_m_sum[select[i]-1])\n",
    "    print(test_results_m_sum[select[i]-1].shape)\n",
    "\n",
    "t_em_test_x_val = np.concatenate(test_results_m_select, axis=1)\n",
    "t_em_x_val = np.concatenate(results_m_select, axis=1)\n",
    "print(\"\\n############################################### t_em x val merged. ###############################################\\n\")\n",
    "print(t_em_x_val.shape)\n",
    "print(t_em_test_x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling t-ensemble  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "122/122 [==============================] - 3s 22ms/step - loss: 1.6489 - acc: 0.6967\n",
      "122/122 [==============================] - 1s 8ms/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.5490 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0136 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 196us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0839 - acc: 0.9754\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0123 - acc: 0.9918\n",
      "122/122 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0222 - acc: 0.9918\n",
      "122/122 [==============================] - 0s 213us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000\n",
      "122/122 [==============================] - 0s 327us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.0384 - acc: 0.9918\n",
      "122/122 [==============================] - 0s 323us/step\n",
      "transffered ensemble model trained.\n"
     ]
    }
   ],
   "source": [
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.005)\n",
    "input_drop_out_t_em = 0.5\n",
    "drop_out_t_em = 0.5\n",
    "layers = [100, 100, 100, 100]\n",
    "t_em_tr_loss_best = 100 # for saving best loss value \n",
    "best_t_em_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "\n",
    "# 2) model build\n",
    "input_t_em = Input(shape=(t_em_x_val.shape[1],))\n",
    "t_em_m_dp = Dropout(input_drop_out_t_em)(input_t_em)\n",
    "for i in layers:\n",
    "    t_em_m = Dense(i,activation='relu')(t_em_m_dp)\n",
    "    t_em_m_dp = Dropout(drop_out_t_em)(t_em_m)\n",
    "t_em_m_final = t_em_m_dp\n",
    "output_t_em = Dense(1, activation=\"sigmoid\")(t_em_m_final)\n",
    "t_em_model = Model(inputs=input_t_em,outputs=output_t_em)\n",
    "t_em_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "\n",
    "#t_em_model.fit(t_em_x_val, y_val_1, batch_size=5, epochs = 100, validation_split = 0.1, callbacks=[early_stopping])\n",
    "while 1:\n",
    "    t_em_model.fit(t_em_x_val, y_val_1, batch_size=5, nb_epoch=1)\n",
    "    t_em_tr_loss=t_em_model.evaluate(t_em_x_val,y_val_1)[0]\n",
    "    if t_em_tr_loss < t_em_tr_loss_best: # new best model. count reset.\n",
    "        t_em_tr_loss_best = t_em_tr_loss\n",
    "        count=0\n",
    "        best_t_em_model = t_em_model\n",
    "    if count>3: # no increase three time. stop.\n",
    "        t_em_model = best_t_em_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "\n",
    "print(\"transffered ensemble model trained.\")\n",
    "t_em_model.save(save_model_path+\"t_em.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 196us/step\n",
      "31/31 [==============================] - 0s 160us/step\n",
      "Overall AUC:  0.9782241014799153\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.6515151515151515\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.6129032373428345\n",
      "Test Sensitivities & Specificities : 0.4444444444444444, 0.6818181818181818\n"
     ]
    }
   ],
   "source": [
    "t_em_output_list = model_performance(\n",
    "    information = False, using_model=t_em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=t_em_x_val, tr_y_val=y_val_1, ts_x_val=t_em_test_x_val, ts_y_val=test_y_val_1,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "t_em_tr_loss, t_em_tr_accuracy, t_em_tr_sensitivity, t_em_tr_specificity, t_em_tr_predictions, t_em_labeled_tr_predictions, t_em_tr_predictions_flat, t_em_roc_auc_tr, t_em_ts_loss, t_em_ts_accuracy, t_em_ts_sensitivity, t_em_ts_specificity, t_em_ts_predictions,t_em_labeled_ts_predictions, t_em_ts_predictions_flat, t_em_roc_auc_ts, t_em_roc_auc_total = t_em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", t_em_roc_auc_total)\n",
    "print(\"Train AUC: \", t_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", t_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(t_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(t_em_tr_sensitivity)+\", \"+str(t_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(t_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(t_em_ts_sensitivity)+\", \"+str(t_em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_em_tr_predictions_flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-4c6dc770bcd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# save prediction result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m tr_df_t_em = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(t_em_tr_predictions_flat), \n\u001b[0m\u001b[0;32m      4\u001b[0m                         \"prediction\":list(t_em_labeled_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n\u001b[0;32m      5\u001b[0m \u001b[0mtr_df_t_em\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_prediction_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"prediction_result_t_em_tr.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"patient\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hypothesis 1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Platinum_Status\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't_em_tr_predictions_flat' is not defined"
     ]
    }
   ],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_t_em = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(t_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(t_em_labeled_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_t_em.to_csv(save_prediction_path+\"prediction_result_t_em_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_t_em = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(t_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(t_em_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_t_em.to_csv(save_prediction_path+\"prediction_result_t_em_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferred Ensemble(Modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m_transferred ensemble input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset : raw data + prediction results\n",
    "full_em_x_val = np.concatenate([x_val_1, em_x_val], axis = 1)\n",
    "full_em_test_x_val = np.concatenate([test_x_val_1, em_test_x_val], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_em_matrix = np.concatenate([full_em_test_x_val, full_em_x_val], axis = 0)\n",
    "df_full_dataset = pd.DataFrame(full_em_matrix)\n",
    "#df_full_dataset.to_csv(index=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_full_dataset = pd.DataFrame(full_em_matrix)\\ndf_full_dataset.to_csv(\"C:/test/merge_newDiff_400_with_predictions.csv\",index=False)\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_full_dataset = pd.DataFrame(full_em_matrix)\n",
    "df_full_dataset.to_csv(\"C:/test/merge_newDiff_400_with_predictions.csv\",index=False)\n",
    "\n",
    "'''\n",
    "#df_full_dataset.loc[df_full_dataset.shape[1]] = patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified t-ensemble model\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.6640 - acc: 0.6148\n",
      "122/122 [==============================] - 0s 2ms/step\n",
      "best model: 0.7377049209641628\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.6215 - acc: 0.6967\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.8360655688848652\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.5546 - acc: 0.7213\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.8770491754422423\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.4467 - acc: 0.8443\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.893442623927945\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.4485 - acc: 0.7377\n",
      "122/122 [==============================] - 0s 66us/step\n",
      "best model: 0.893442623927945\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.4879 - acc: 0.7541\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.8934426180651931\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.4636 - acc: 0.8033\n",
      "122/122 [==============================] - 0s 66us/step\n",
      "best model: 0.9590163944197483\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.4454 - acc: 0.7705\n",
      "122/122 [==============================] - 0s 66us/step\n",
      "best model: 0.9754098302028218\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3920 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.9918032786885246\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3843 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.9836065515142972\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.4069 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.9836065573770492\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3603 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.9836065573770492\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3991 - acc: 0.8197\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 0.9672131147540983\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3402 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "best model: 0.9918032786885246\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3446 - acc: 0.8770\n",
      "122/122 [==============================] - 0s 66us/step\n",
      "best model: 0.9918032786885246\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.4027 - acc: 0.8115\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.2942 - acc: 0.9098\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3818 - acc: 0.7869\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3616 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.2666 - acc: 0.9016\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3189 - acc: 0.8607\n",
      "122/122 [==============================] - 0s 66us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.2817 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3244 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 66us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3297 - acc: 0.8689\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "best model: 0.9836065515142972\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3718 - acc: 0.8525\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "Epoch 1/1\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3569 - acc: 0.8361\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "best model: 1.0\n",
      "mixed_model trained.\n",
      "mixed_model saved.\n",
      "122/122 [==============================] - 0s 199us/step\n",
      "31/31 [==============================] - 0s 0us/step\n",
      "Overall AUC:  0.9638477801268499\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.7424242424242424\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.7096773982048035\n",
      "Test Sensitivities & Specificities : 0.5555555555555556, 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "print(\"modified t-ensemble model\")\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "input_drop_out_full_em = 0.5\n",
    "drop_out_full_em = 0\n",
    "layers = [100]\n",
    "full_em_tr_loss_best = 100 # for saving best loss value \n",
    "best_full_em_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "input_full_em = Input(shape=(full_em_x_val.shape[1],))\n",
    "full_em_m_bn = Dropout(input_drop_out_full_em)(input_full_em)\n",
    "for i in layers:\n",
    "    full_em_m = Dense(i)(full_em_m_bn)\n",
    "    full_em_m_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(full_em_m)\n",
    "    full_em_m_ac = Activation(\"relu\")(full_em_m_bn)\n",
    "\n",
    "output_full_em = Dense(1, activation=\"sigmoid\")(full_em_m_ac)\n",
    "full_em_model = Model(inputs=input_full_em,outputs=output_full_em)\n",
    "full_em_model.compile(optimizer=optimizers.Adam(), \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    full_em_model.fit(full_em_x_val, y_val_1, batch_size=5,epochs=1)\n",
    "    full_em_tr_loss, full_em_tr_accuracy =full_em_model.evaluate(full_em_x_val, y_val_1)\n",
    "    if full_em_tr_loss < full_em_tr_loss_best: # new best model. count reset.\n",
    "        full_em_tr_loss_best = full_em_tr_loss\n",
    "        count=0\n",
    "        best_full_em_model = full_em_model\n",
    "        best_full_em_tr_accuracy = full_em_tr_accuracy\n",
    "        print(\"best model: \"+str(full_em_tr_accuracy))\n",
    "    if count>20 or (best_full_em_tr_accuracy == 1): # no increase three time. stop.\n",
    "        full_em_model = best_full_em_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"mixed_model trained.\")\n",
    "\n",
    "# 4) save model\n",
    "full_em_model.save(save_model_path+\"/full_em.h5\")\n",
    "print(\"mixed_model saved.\")\n",
    "\n",
    "# 5) evaluate model\n",
    "full_em_output_list = model_performance(\n",
    "    information = False, using_model=full_em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=full_em_x_val, tr_y_val=y_val_1, ts_x_val=full_em_test_x_val, ts_y_val=test_y_val_1,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "full_em_tr_loss, full_em_tr_accuracy, full_em_tr_sensitivity, full_em_tr_specificity, full_em_tr_predictions, full_em_labeled_tr_predictions, full_em_tr_predictions_flat, full_em_roc_auc_tr, full_em_ts_loss, full_em_ts_accuracy, full_em_ts_sensitivity, full_em_ts_specificity, full_em_ts_predictions,full_em_labeled_ts_predictions, full_em_ts_predictions_flat, full_em_roc_auc_ts, full_em_roc_auc_total = full_em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", full_em_roc_auc_total)\n",
    "print(\"Train AUC: \", full_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", full_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(full_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(full_em_tr_sensitivity)+\", \"+str(full_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(full_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(full_em_ts_sensitivity)+\", \"+str(full_em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_em_m_l = load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 96us/step\n",
      "Overall AUC:  0.9809725158562368\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8686868686868686\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.9032257795333862\n",
      "Test Sensitivities & Specificities : 0.8888888888888888, 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "model_test = load_model(\"G:/내 드라이브/Class/6과 7 사이(hell)/Lab/TCGA 난소암/Best_Models/18.09.15/best_models/Full_5+5.h5\")\n",
    "full_em_output_list = model_performance(\n",
    "    information = False, using_model=model_test,Input_Prediction_Passively = False, \n",
    "    tr_x_val=full_em_x_val, tr_y_val=y_val_1, ts_x_val=full_em_test_x_val, ts_y_val=test_y_val_1,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "full_em_tr_loss, full_em_tr_accuracy, full_em_tr_sensitivity, full_em_tr_specificity, full_em_tr_predictions, full_em_labeled_tr_predictions, full_em_tr_predictions_flat, full_em_roc_auc_tr, full_em_ts_loss, full_em_ts_accuracy, full_em_ts_sensitivity, full_em_ts_specificity, full_em_ts_predictions,full_em_labeled_ts_predictions, full_em_ts_predictions_flat, full_em_roc_auc_ts, full_em_roc_auc_total = full_em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", full_em_roc_auc_total)\n",
    "print(\"Train AUC: \", full_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", full_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(full_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(full_em_tr_sensitivity)+\", \"+str(full_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(full_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(full_em_ts_sensitivity)+\", \"+str(full_em_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_full_em = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(full_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(full_em_labeled_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_full_em.to_csv(save_prediction_path+\"prediction_result_full_em_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_full_em = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(full_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(full_em_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_full_em.to_csv(save_prediction_path+\"prediction_result_full_em_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< model1 > tr: 0.9262295091738466, ts: 0.774193525314331\n",
      "< model4 > tr: 0.9508196662683956, ts: 0.8387096524238586\n",
      "< model5 > tr: 0.7704918062100645, ts: 0.7419354915618896\n",
      "< model6 > tr: 1.0, ts: 0.774193525314331\n",
      "< mean-em > tr: 0.8360655737704918, ts: 0.6129032258064516\n",
      "< d-comb em > tr: 0.8934426180651931, ts: 0.7096773982048035\n",
      "< t-em > tr: 1.0, ts: 0.774193525314331\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "tr_accuracy_list = [m_1_l_tr_accuracy, m_2_l_tr_accuracy, m_3_l_tr_accuracy, m_4_l_tr_accuracy, m_5_l_tr_accuracy, m_6_l_tr_accuracy]\n",
    "ts_accuracy_list = [m_1_l_accuracy, m_2_l_accuracy, m_3_l_accuracy, m_4_l_accuracy, m_5_l_accuracy, m_6_l_accuracy]\n",
    "tr_accuracy_select = []\n",
    "ts_accuracy_select = []\n",
    "\n",
    "for i in select:\n",
    "    label.append(\"model\"+str(i))\n",
    "    tr_accuracy_select.append(tr_accuracy_list[i-1])\n",
    "    ts_accuracy_select.append(ts_accuracy_list[i-1])\n",
    "\n",
    "label = label+[\"mean-em\",\"d-comb em\",\"t-em\"]\n",
    "tr_accuracy_select= tr_accuracy_select + [mean_em_tr_accuracy, em_tr_accuracy, t_em_tr_accuracy]\n",
    "ts_accuracy_select= ts_accuracy_select + [mean_em_ts_accuracy, em_ts_accuracy, t_em_ts_accuracy]\n",
    "\n",
    "for model_num in range(len(label)):\n",
    "    print(\"< \"+label[model_num]+\" > tr: \"+str(tr_accuracy_select[model_num])+\", ts: \"+str(ts_accuracy_select[model_num]))\n",
    "\n",
    "#label = [\"model1\",\"model2\",\"model3\",\"mean-em\",\"d-comb em\",\"t-em\"]\n",
    "#accuracy = [m1_accuracy,m2_accuracy,m3_accuracy,mean_em_accuracy,em_accuracy,t_em_accuracy ]\n",
    "#print(\"model1: \"+str(accuracy[0])+\"\\nmodel2: \"+str(accuracy[1])+\"\\nmodel3: \"+str(accuracy[2])+\"\\nmean-em: \"+str(accuracy[3])+\"\\nd-comb em: \"+str(accuracy[4])+\"\\nt-em: \"+str(accuracy[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def plot_bar_x():\n",
    "    # this is for plotting purpose\n",
    "    plt.figure(figsize=(30,20))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([min(m_1_accuracy,m_2_accuracy,m_3_accuracy,mean_em_accuracy,em_accuracy,t_em_accuracy)-0.02,1])\n",
    "    index = np.arange(len(label))\n",
    "    plt.bar(index, accuracy,color=['red', 'orange', 'yellow', \"green\",'blue', 'purple'],alpha=0.5,width=0.3)\n",
    "    plt.xlabel('Method', fontsize=35)\n",
    "    plt.ylabel('Accuracy', fontsize=35)\n",
    "    plt.yticks(fontsize=30)    \n",
    "    plt.xticks(index, label, fontsize=30, rotation=90)\n",
    "    plt.title('Performance Comparison for each Ensemble Model',fontsize=40)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "plot_bar_x()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
