{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample : 1400  \n",
      "features : 311\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/chanhee/Desktop/foundation_toy.csv\"\n",
    "idx_col = 0\n",
    "\n",
    "data = pd.read_csv(path,index_col=idx_col)\n",
    "sample,features = data.shape\n",
    "\n",
    "\n",
    "y_val = data.result\n",
    "x_val = data.drop([\"patient\",\"cancer_code\",\"result\"],axis=1)\n",
    "print(\"sample : {}  \\nfeatures : {}\".format(sample,features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train each model for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 1s 446us/step - loss: 0.3950 - acc: 0.8164\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 0s 64us/step - loss: 0.2235 - acc: 0.9029\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.1738 - acc: 0.9307\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 0s 65us/step - loss: 0.1409 - acc: 0.9464\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.1259 - acc: 0.9571\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.1251 - acc: 0.9464\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 0s 64us/step - loss: 0.0850 - acc: 0.9686\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 0s 67us/step - loss: 0.0726 - acc: 0.9707\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 0s 65us/step - loss: 0.0577 - acc: 0.9793\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 0s 67us/step - loss: 0.0443 - acc: 0.9850\n",
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 0s 277us/step - loss: 0.3830 - acc: 0.8243\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 0.2032 - acc: 0.9136\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 0s 65us/step - loss: 0.1631 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 0s 72us/step - loss: 0.1476 - acc: 0.9457\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 0s 67us/step - loss: 0.1308 - acc: 0.9436\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 0s 88us/step - loss: 0.1165 - acc: 0.9543\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 0s 76us/step - loss: 0.1095 - acc: 0.9536\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 0s 64us/step - loss: 0.1071 - acc: 0.9593\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 0.0650 - acc: 0.9736\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 0.0522 - acc: 0.9814\n",
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 0s 281us/step - loss: 0.4040 - acc: 0.8243\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.2194 - acc: 0.9186\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.1860 - acc: 0.9264\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 0.1447 - acc: 0.9414\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.1181 - acc: 0.9586\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.1014 - acc: 0.9614\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.1139 - acc: 0.9557\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 0.0909 - acc: 0.9614\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.0793 - acc: 0.9693\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 0.0469 - acc: 0.9864\n",
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 0s 293us/step - loss: 0.4023 - acc: 0.8157\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.2107 - acc: 0.9136\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.1518 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 0.1219 - acc: 0.9557\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 0s 67us/step - loss: 0.1212 - acc: 0.9557\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 0s 64us/step - loss: 0.0929 - acc: 0.9593\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 0.0902 - acc: 0.9657\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 0s 60us/step - loss: 0.0583 - acc: 0.9786\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 0s 72us/step - loss: 0.0458 - acc: 0.9857\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 0s 123us/step - loss: 0.0545 - acc: 0.9771\n",
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 1s 429us/step - loss: 0.4340 - acc: 0.8021\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 0s 94us/step - loss: 0.2098 - acc: 0.9207\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 0s 69us/step - loss: 0.1715 - acc: 0.9357\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.1441 - acc: 0.9486\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 0s 64us/step - loss: 0.1136 - acc: 0.9571\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.1013 - acc: 0.9614\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 0s 73us/step - loss: 0.0855 - acc: 0.9671\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 0s 82us/step - loss: 0.0819 - acc: 0.9693\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 0s 82us/step - loss: 0.0634 - acc: 0.9793\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 0s 69us/step - loss: 0.0509 - acc: 0.9800\n",
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 1s 399us/step - loss: 0.4819 - acc: 0.7814\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.2490 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.1752 - acc: 0.9357\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 0s 60us/step - loss: 0.1576 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 0s 58us/step - loss: 0.1269 - acc: 0.9493\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 0s 73us/step - loss: 0.1074 - acc: 0.9621\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 0s 76us/step - loss: 0.0865 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 0s 74us/step - loss: 0.0721 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 0s 62us/step - loss: 0.0772 - acc: 0.9729\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 0s 68us/step - loss: 0.0516 - acc: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1181c0748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "input_m1 = Input(shape=(308,))\n",
    "h1_m1 = Dense(200,activation='relu')(input_m1)\n",
    "h2_m1 = Dense(150,activation='relu')(h1_m1) \n",
    "h3_m1 = Dense(100,activation='relu')(h2_m1) \n",
    "h4_m1 = Dense(10,activation='relu')(h3_m1) \n",
    "output_m1 = Dense(1,activation=\"sigmoid\")(h4_m1) \n",
    "model1 = Model(inputs=input_m1,outputs=output_m1)\n",
    "\n",
    "\n",
    "input_m2 = Input(shape=(308,))\n",
    "h1_m2 = Dense(250,activation='relu')(input_m2)\n",
    "h2_m2 = Dense(100,activation='relu')(h1_m2) \n",
    "h3_m2 = Dense(30,activation='relu')(h2_m2)\n",
    "h4_m2 = Dense(10,activation='relu')(h3_m2) \n",
    "output_m2 = Dense(1,activation=\"sigmoid\")(h4_m2)\n",
    "model2 = Model(inputs=input_m2,outputs=output_m2)\n",
    "\n",
    "input_m3 = Input(shape=(308,))\n",
    "h1_m3 = Dense(200,activation='relu')(input_m3)\n",
    "h2_m3 = Dense(100,activation='relu')(h1_m3) \n",
    "h3_m3 = Dense(100,activation='relu')(h2_m3)\n",
    "h4_m3 = Dense(10,activation='relu')(h3_m3) \n",
    "output_m3 = Dense(1,activation=\"sigmoid\")(h4_m3)\n",
    "model3 = Model(inputs=input_m3,outputs=output_m3)\n",
    "\n",
    "input_m4 = Input(shape=(308,))\n",
    "h1_m4 = Dense(200,activation='relu')(input_m4)\n",
    "h2_m4 = Dense(100,activation='relu')(h1_m4) \n",
    "h3_m4 = Dense(100,activation='relu')(h2_m4)\n",
    "h4_m4 = Dense(10,activation='relu')(h3_m4) \n",
    "output_m4 = Dense(1,activation=\"sigmoid\")(h4_m4)\n",
    "model4 = Model(inputs=input_m4,outputs=output_m4)\n",
    "\n",
    "input_m5 = Input(shape=(308,))\n",
    "h1_m5 = Dense(200,activation='relu')(input_m5)\n",
    "h2_m5 = Dense(10,activation='relu')(h1_m5) \n",
    "h3_m5 = Dense(150,activation='relu')(h2_m5)\n",
    "h4_m5 = Dense(10,activation='relu')(h3_m5) \n",
    "output_m5 = Dense(1,activation=\"sigmoid\")(h4_m5)\n",
    "model5 = Model(inputs=input_m5,outputs=output_m5)\n",
    "\n",
    "input_m6 = Input(shape=(308,))\n",
    "h1_m6 = Dense(200,activation='relu')(input_m6)\n",
    "h2_m6 = Dense(150,activation='relu')(h1_m6) \n",
    "h3_m6 = Dense(10,activation='relu')(h2_m6)\n",
    "h4_m6 = Dense(10,activation='relu')(h3_m6) \n",
    "output_m6 = Dense(1,activation=\"sigmoid\")(h4_m6)\n",
    "model6 = Model(inputs=input_m6,outputs=output_m6)\n",
    "\n",
    "model1.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model2.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model3.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model4.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model5.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model6.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit(x_val, y_val, epochs=10)\n",
    "model2.fit(x_val, y_val, epochs=10)\n",
    "model3.fit(x_val, y_val, epochs=10)\n",
    "model4.fit(x_val, y_val, epochs=10)\n",
    "model5.fit(x_val, y_val, epochs=10)\n",
    "model6.fit(x_val, y_val, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembel Coverage Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_coverage(inputModels,x,y):\n",
    "    outputModels = []\n",
    "    modelInfo = []\n",
    "    coverageTotal= [False]*len(y)\n",
    "    \n",
    "    for m in inputModels:\n",
    "        yHat = m.predict(x)\n",
    "        yHat = [round(i) for [i] in yHat]\n",
    "        \n",
    "        loss, acc = m.evaluate(x,y)\n",
    "        modelInfo.append((m,yHat,acc))\n",
    "    \n",
    "    modelInfo.sort(key=lambda x : x[2],reverse=True)\n",
    "    \n",
    "    for m,yHat,acc in modelInfo:\n",
    "        beforeCoverage = sum(coverageTotal)\n",
    "        coverage = [a == b for a,b in zip(y,yHat)]\n",
    "        coverageTotal = [a or b for a,b in zip(coverageTotal,coverage)]\n",
    "        afterCoverage = sum(coverageTotal)\n",
    "        \n",
    "        print(afterCoverage/len(y))\n",
    "        \n",
    "        if afterCoverage > beforeCoverage:\n",
    "            outputModels.append(m)\n",
    "            print(\"Increased Coverage : model added!\")\n",
    "        else:\n",
    "            print(\"Same Coverage : model not added\")\n",
    "        if afterCoverage == len(y):\n",
    "            print(\"Fully Covered!\")\n",
    "            break\n",
    "        \n",
    "                \n",
    "    return outputModels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Maximum Coverage Model Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 34us/step\n",
      "1400/1400 [==============================] - 0s 27us/step\n",
      "1400/1400 [==============================] - 0s 25us/step\n",
      "1400/1400 [==============================] - 0s 25us/step\n",
      "1400/1400 [==============================] - 0s 22us/step\n",
      "1400/1400 [==============================] - 0s 26us/step\n",
      "0.9942857142857143\n",
      "Increased Coverage : model added!\n",
      "0.9957142857142857\n",
      "Increased Coverage : model added!\n",
      "0.9957142857142857\n",
      "Same Coverage : model not added\n",
      "0.9978571428571429\n",
      "Increased Coverage : model added!\n",
      "0.9985714285714286\n",
      "Increased Coverage : model added!\n",
      "0.9985714285714286\n",
      "Same Coverage : model not added\n",
      "number of final models for ensemble:  4\n"
     ]
    }
   ],
   "source": [
    "inputModels = [model1,model2,model3,model4,model5,model6]\n",
    "x = x_val\n",
    "y = y_val\n",
    "\n",
    "ensemble_models = ensemble_coverage(inputModels,x,y)\n",
    "print(\"number of final models for ensemble: \",len(ensemble_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
