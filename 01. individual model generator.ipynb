{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Input, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, load_model, Sequential \n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Functions library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide raw data into train / test & x_val / y_val\n",
    "def data_split(raw_data, index_col, test_index):\n",
    "    \n",
    "    train_data = raw_data.iloc[list(raw_data.iloc[:,index_col]!=test_index)]\n",
    "    test_data = raw_data.iloc[list(raw_data.iloc[:,index_col]==test_index)]\n",
    "    \n",
    "    y_val = train_data.Platinum_Status\n",
    "    x_val = train_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val = test_data.Platinum_Status\n",
    "    test_x_val = test_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    return train_data, test_data, y_val, x_val, test_y_val, test_x_val\n",
    "\n",
    "    # raw_data: have gene_expressions(maybe multiple columns), index column, Platinum_Status column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all of model performance \n",
    "# - predictions(probability) / labeled predictions(0/1) / Loss / Accuracy / Sensitivity / Specificity / AUC values of Train / Test dataset.\n",
    "# using trained models, or you can put predictions(probability) passively(in this case, Loss & Accuracy do not provided.)\n",
    "def model_performance(information=False, Input_Prediction_Passively=False, using_model=None, tr_predictions=None, ts_predictions=None, tr_x_val=None, tr_y_val=None, ts_x_val=None, ts_y_val=None, output_list=None):\n",
    "    \n",
    "    if information == True:            \n",
    "        print(\"options model_performance:\\n1) using_model: keras models that you want to check performance. \\\"Input_Prediction_Passive\\\" option for input prediction list instead using models.\\n3) tr_predictions & ts_predictions: prediction input passively. put this data only when not using keras model.\\n4) tr_x_val & ts_x_val: input samples of train/test samples.\\n4) tr_y_val & ts_y_val: results of train/test samples.\\n5) output_list: return values that you want to recieve.\\n CAUTION: Essential variable.\\n\\t tr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\\n\\n* CAUTION: if 'None' value is returned, please check your input tr inputs(None value for tr outputs) or ts inputs(None value for ts outputs).\") \n",
    "        return 0\n",
    "    elif information != False:\n",
    "        print(\"for using information options, please set 'information' variable for 'True'\")\n",
    "        return -1\n",
    "    \n",
    "    if using_model is None:\n",
    "        if Input_Prediction_Passively == False:\n",
    "            print(\"ERROR: There are no models for using.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\") \n",
    "            return -1\n",
    "        elif (tr_predictions is None) and (ts_predictions is None): # No model/prediction input. no performance should be calculated.\n",
    "                print(\"ERROR: Input prediction list instead using saved model.\")\n",
    "                return -1\n",
    "        else: # No model input, but Input_Prediction_Passively is True & input prediction is valid.\n",
    "            tr_loss,tr_accuracy= None, None\n",
    "            ts_loss,ts_accuracy= None, None\n",
    "            \n",
    "    elif Input_Prediction_Passively == True: # both of model/prediction putted, could cause confusing.\n",
    "        ch = input(\"You put both model and prediction. Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "        while 1:\n",
    "            if ch == 'p':\n",
    "                using_model = None\n",
    "                break\n",
    "            elif ch == 'm':\n",
    "                tr_predictions = None\n",
    "                ts_predictions = None\n",
    "                break\n",
    "            elif ch == 'e':\n",
    "                return 0\n",
    "            else:\n",
    "                print(\"you put worng option: \"+str(ch))\n",
    "            ch = input(\"Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "                \n",
    "    if output_list is None:\n",
    "        print(\"ERROR: There are no output_list for return.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\")\n",
    "        return -1\n",
    "    \n",
    "    if not(tr_x_val is None) and not(tr_y_val is None):\n",
    "        # predict tr result only when no tr_prediction input\n",
    "        if tr_predictions is None:\n",
    "            tr_loss,tr_accuracy= using_model.evaluate(tr_x_val,tr_y_val)\n",
    "            tr_predictions = using_model.predict(tr_x_val)\n",
    "        # tr sensitivity / specificity\n",
    "        labeled_tr_predictions = np.where(tr_predictions > 0.5, 1, 0).flatten()\n",
    "        tr_sensitivity, tr_specificity = check_correct(labeled_tr_predictions, tr_y_val)\n",
    "        tr_predictions_flat = tr_predictions[:,0]   \n",
    "        # roc(tr)\n",
    "        fpr_tr, tpr_tr, threshold_tr = metrics.roc_curve(tr_y_val, tr_predictions)\n",
    "        roc_auc_tr = metrics.auc(fpr_tr, tpr_tr)\n",
    "    \n",
    "    if not(ts_x_val is None) and not(ts_y_val is None):\n",
    "        # predict ts result only when no ts_prediction input\n",
    "        if ts_predictions is None:\n",
    "            ts_loss,ts_accuracy= using_model.evaluate(ts_x_val,ts_y_val)\n",
    "            ts_predictions = using_model.predict(ts_x_val)\n",
    "        labeled_ts_predictions = np.where(ts_predictions > 0.5, 1, 0).flatten()\n",
    "        ts_sensitivity, ts_specificity = check_correct(labeled_ts_predictions, ts_y_val)\n",
    "        ts_predictions_flat = ts_predictions[:,0]   \n",
    "        # roc(ts)\n",
    "        fpr_ts, tpr_ts, threshold_ts = metrics.roc_curve(ts_y_val, ts_predictions)\n",
    "        roc_auc_ts = metrics.auc(fpr_ts, tpr_ts)    \n",
    "    \n",
    "    if (not(tr_x_val is None) and not(tr_y_val is None)) and (not(ts_x_val is None) and not(ts_y_val is None)):\n",
    "        y_true = np.append(tr_y_val, ts_y_val)\n",
    "        y_pred = np.append(tr_predictions, ts_predictions)\n",
    "        fpr_total, tpr_total, threshold_total = metrics.roc_curve(y_true, y_pred)\n",
    "        roc_auc_total = metrics.auc(fpr_total, tpr_total)\n",
    "        \n",
    "        \n",
    "    return_list = []\n",
    "    \n",
    "    for output in output_list:\n",
    "        \n",
    "        if(output == \"tr_loss\"):\n",
    "            return_list.append(tr_loss)\n",
    "                               \n",
    "        elif(output == \"tr_accuracy\"):\n",
    "            return_list.append(tr_accuracy)\n",
    "                               \n",
    "        elif(output == \"tr_sensitivity\"):\n",
    "            return_list.append(tr_sensitivity)\n",
    "                               \n",
    "        elif(output == \"tr_specificity\"):\n",
    "            return_list.append(tr_specificity)\n",
    "                               \n",
    "        elif(output == \"tr_predictions\"):\n",
    "            return_list.append(tr_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_tr_predictions\"):\n",
    "            return_list.append(labeled_tr_predictions)\n",
    "                               \n",
    "        elif(output == \"tr_predictions_flat\"):\n",
    "            return_list.append(tr_predictions_flat)\n",
    "            \n",
    "        elif(output == \"roc_auc_tr\"):\n",
    "            return_list.append(roc_auc_tr)\n",
    "\n",
    "        elif(output == \"ts_loss\"):\n",
    "            return_list.append(ts_loss)\n",
    "                               \n",
    "        elif(output == \"ts_accuracy\"):\n",
    "            return_list.append(ts_accuracy)\n",
    "                               \n",
    "        elif(output == \"ts_sensitivity\"):\n",
    "            return_list.append(ts_sensitivity)\n",
    "                               \n",
    "        elif(output == \"ts_specificity\"):\n",
    "            return_list.append(ts_specificity)\n",
    "                               \n",
    "        elif(output == \"ts_predictions\"):\n",
    "            return_list.append(ts_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_ts_predictions\"):\n",
    "            return_list.append(labeled_ts_predictions)\n",
    "                               \n",
    "        elif(output == \"ts_predictions_flat\"):\n",
    "            return_list.append(ts_predictions_flat)\n",
    "        \n",
    "        elif(output == \"roc_auc_ts\"):\n",
    "            return_list.append(roc_auc_ts)\n",
    "            \n",
    "        elif(output == \"roc_auc_total\"):\n",
    "            return_list.append(roc_auc_total)\n",
    "                               \n",
    "        else:\n",
    "            print(\"There are no options <\"+str(output)+\">. Please refer these output options:\\ntr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\")\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation: import & preprocessing data + import module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input path & name of models / raw data for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"OV_six_fold_Annotation3000_400\", \n",
    "         \"OV_six_fold_CV_400\", \n",
    "         \"OV_six_fold_Var_400\", \"OV_six_fold_new_Diff_400\",\n",
    "         \"OV_six_fold_Clin\", \n",
    "         \"OV_six_fold_SNV\" \n",
    "         ]\n",
    "\n",
    "# input pathes\n",
    "path = \"C:/test/TC_six_fold_subsamples/\"\n",
    "save_model_path = \"../models/Ovary/\"\n",
    "save_prediction_path = \"../result/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] file_name:  OV_six_fold_Annotation3000_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[2] file_name:  OV_six_fold_CV_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[3] file_name:  OV_six_fold_Var_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[4] file_name:  OV_six_fold_new_Diff_400 \n",
      "sample : 217  \n",
      "features : 400\n",
      "[5] file_name:  OV_six_fold_Clin \n",
      "sample : 287  \n",
      "features : 35\n",
      "[6] file_name:  OV_six_fold_SNV \n",
      "sample : 213  \n",
      "features : 13814\n"
     ]
    }
   ],
   "source": [
    "file_1 = path+types[0]+\".csv\"\n",
    "file_2 = path+types[1]+\".csv\"\n",
    "file_3 = path+types[2]+\".csv\"\n",
    "file_4 = path+types[3]+\".csv\"\n",
    "file_5 = path+types[4]+\".csv\"\n",
    "file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "sample_1,features_1 = data_1.shape\n",
    "sample_2,features_2 = data_2.shape\n",
    "sample_3,features_3 = data_3.shape\n",
    "sample_4,features_4 = data_4.shape\n",
    "sample_5,features_5 = data_5.shape\n",
    "sample_6,features_6 = data_6.shape\n",
    "\n",
    "# Data frame include index & Platinum_Status column, substract 2 to calculate real number of features \n",
    "[features_1, features_2, features_3, features_4, features_5, features_6] = [features_1-2, features_2-2, features_3-2, features_4-2, features_5-2, features_6-2]\n",
    "\n",
    "print(\"[1] file_name: \", types[0], \"\\nsample : {}  \\nfeatures : {}\".format(sample_1,features_1))\n",
    "print(\"[2] file_name: \", types[1], \"\\nsample : {}  \\nfeatures : {}\".format(sample_2,features_2))\n",
    "print(\"[3] file_name: \", types[2], \"\\nsample : {}  \\nfeatures : {}\".format(sample_3,features_3))\n",
    "print(\"[4] file_name: \", types[3], \"\\nsample : {}  \\nfeatures : {}\".format(sample_4,features_4))\n",
    "print(\"[5] file_name: \", types[4], \"\\nsample : {}  \\nfeatures : {}\".format(sample_5,features_5))\n",
    "print(\"[6] file_name: \", types[5], \"\\nsample : {}  \\nfeatures : {}\".format(sample_6,features_6))\n",
    "\n",
    "# Split Train Test Data\n",
<<<<<<< Updated upstream
    "\n",
    "train_data_1, test_data_1, y_val_1, x_val_1, test_y_val_1, test_x_val_1 = data_split(raw_data = data_1, index_col = -1, test_index = 1)\n",
    "train_data_2, test_data_2, y_val_2, x_val_2, test_y_val_2, test_x_val_2 = data_split(raw_data = data_2, index_col = -1, test_index = 1)\n",
    "train_data_3, test_data_3, y_val_3, x_val_3, test_y_val_3, test_x_val_3 = data_split(raw_data = data_3, index_col = -1, test_index = 1)\n",
    "train_data_4, test_data_4, y_val_4, x_val_4, test_y_val_4, test_x_val_4 = data_split(raw_data = data_4, index_col = -1, test_index = 1)\n",
    "train_data_5, test_data_5, y_val_5, x_val_5, test_y_val_5, test_x_val_5 = data_split(raw_data = data_5, index_col = -1, test_index = 1)\n",
    "train_data_6, test_data_6, y_val_6, x_val_6, test_y_val_6, test_x_val_6 = data_split(raw_data = data_6, index_col = -1, test_index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile_1 = path+types[0]+\".csv\"\\nfile_2 = path+types[1]+\".csv\"\\nfile_3 = path+types[2]+\".csv\"\\nfile_4 = path+types[3]+\".csv\"\\nfile_5 = path+types[4]+\".csv\"\\nfile_6 = path+types[5]+\".csv\"\\n\\nidx_col = 0\\n\\ndata_1 = pd.read_csv(file_1,index_col=idx_col)\\ndata_2 = pd.read_csv(file_2,index_col=idx_col)\\ndata_3 = pd.read_csv(file_3,index_col=idx_col)\\ndata_4 = pd.read_csv(file_4,index_col=idx_col)\\ndata_5 = pd.read_csv(file_5,index_col=idx_col)\\ndata_6 = pd.read_csv(file_6,index_col=idx_col)\\n\\ninter_data_1 = data_1.iloc[list(data_1.iloc[:,-1]!=6)]\\ninter_data_2 = data_2.iloc[list(data_2.iloc[:,-1]!=6)]\\ninter_data_3 = data_3.iloc[list(data_3.iloc[:,-1]!=6)]\\ninter_data_4 = data_4.iloc[list(data_4.iloc[:,-1]!=6)]\\ninter_data_5 = data_5.iloc[list(data_5.iloc[:,-1]!=6)]\\ninter_data_6 = data_6.iloc[list(data_6.iloc[:,-1]!=6)]\\n\\ndata_list  = [data_1,  data_2,  data_3,  data_4, data_5,  data_6]\\ninter_data_list  = [inter_data_1,  inter_data_2,  inter_data_3,  inter_data_4, inter_data_5,  inter_data_6]\\n\\n# for selection\\nselect = [1, 3, 4, 5]\\n\\nselect_types = []\\nselect_data = []\\nselect_inter_data = []\\n\\nfor i in select:\\n    select_types.append(types[i-1])\\n    select_data.append(data_list[i-1])\\n    select_inter_data.append(inter_data_list[i-1])\\n    print(str(len(select_types))+\"file_name: \"+ types[i-1]+\"\\nsample(full) : \"+str(data_list[i-1].shape[0])+\"\\nsample(inter) : \"+str(inter_data_list[i-1].shape[0])+\"\\nfeatures : \"+str(data_list[i-1].shape[1]))\\n        \\n\\nfor ts_i in range(1,6):\\n    dataset = {\"train_data\":[], \"test_data\":[], \"tr_y_val\":[], \"tr_x_val\":[], \"ts_y_val\":[], \"ts_x_val\":[]}\\n    val_name = [\"train_data\", \"test_data\", \"tr_y_val\", \"tr_x_val\", \"ts_y_val\", \"ts_x_val\"]\\n    for s_d in select_data:\\n        train_data, test_data, tr_y_val, tr_x_val, ts_y_val, ts_x_val = data_split(raw_data = s_d, index_col = -1, test_index = ts_i)\\n        dataset[\\'train_data\\'].append(train_data)\\n        dataset[\\'test_data\\'].append(test_data)\\n        dataset[\\'tr_x_val\\'].append(tr_x_val)\\n        dataset[\\'tr_y_val\\'].append(tr_y_val)\\n        dataset[\\'ts_x_val\\'].append(ts_x_val)\\n        dataset[\\'ts_y_val\\'].append(ts_y_val)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "file_1 = path+types[0]+\".csv\"\n",
    "file_2 = path+types[1]+\".csv\"\n",
    "file_3 = path+types[2]+\".csv\"\n",
    "file_4 = path+types[3]+\".csv\"\n",
    "file_5 = path+types[4]+\".csv\"\n",
    "file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "inter_data_1 = data_1.iloc[list(data_1.iloc[:,-1]!=6)]\n",
    "inter_data_2 = data_2.iloc[list(data_2.iloc[:,-1]!=6)]\n",
    "inter_data_3 = data_3.iloc[list(data_3.iloc[:,-1]!=6)]\n",
    "inter_data_4 = data_4.iloc[list(data_4.iloc[:,-1]!=6)]\n",
    "inter_data_5 = data_5.iloc[list(data_5.iloc[:,-1]!=6)]\n",
    "inter_data_6 = data_6.iloc[list(data_6.iloc[:,-1]!=6)]\n",
    "\n",
    "data_list  = [data_1,  data_2,  data_3,  data_4, data_5,  data_6]\n",
    "inter_data_list  = [inter_data_1,  inter_data_2,  inter_data_3,  inter_data_4, inter_data_5,  inter_data_6]\n",
    "\n",
    "# for selection\n",
    "select = [1, 3, 4, 5]\n",
    "\n",
    "select_types = []\n",
    "select_data = []\n",
    "select_inter_data = []\n",
    "\n",
    "for i in select:\n",
    "    select_types.append(types[i-1])\n",
    "    select_data.append(data_list[i-1])\n",
    "    select_inter_data.append(inter_data_list[i-1])\n",
    "    print(str(len(select_types))+\"file_name: \"+ types[i-1]+\"\\nsample(full) : \"+str(data_list[i-1].shape[0])+\"\\nsample(inter) : \"+str(inter_data_list[i-1].shape[0])+\"\\nfeatures : \"+str(data_list[i-1].shape[1]))\n",
    "        \n",
    "\n",
    "for ts_i in range(1,6):\n",
    "    dataset = {\"train_data\":[], \"test_data\":[], \"tr_y_val\":[], \"tr_x_val\":[], \"ts_y_val\":[], \"ts_x_val\":[]}\n",
    "    val_name = [\"train_data\", \"test_data\", \"tr_y_val\", \"tr_x_val\", \"ts_y_val\", \"ts_x_val\"]\n",
    "    for s_d in select_data:\n",
    "        train_data, test_data, tr_y_val, tr_x_val, ts_y_val, ts_x_val = data_split(raw_data = s_d, index_col = -1, test_index = ts_i)\n",
    "        dataset['train_data'].append(train_data)\n",
    "        dataset['test_data'].append(test_data)\n",
    "        dataset['tr_x_val'].append(tr_x_val)\n",
    "        dataset['tr_y_val'].append(tr_y_val)\n",
    "        dataset['ts_x_val'].append(ts_x_val)\n",
    "        dataset['ts_y_val'].append(ts_y_val)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['tr_y_val'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset[val_name[1]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset = {\"tr\":[], \"ts\":[]}\\ndataset[\\'tr\\'].append(1)\\ndataset[\\'tr\\'].append(2)\\ndataset[\\'tr\\'].append(3)\\ndataset[\\'ts\\'].append(3)\\ndataset[\\'ts\\'].append(2)\\ndataset[\\'ts\\'].append(1)\\ndataset[[\\'tr\\',\\'ts\\'].append([1,2])'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dataset = {\"tr\":[], \"ts\":[]}\n",
    "dataset['tr'].append(1)\n",
    "dataset['tr'].append(2)\n",
    "dataset['tr'].append(3)\n",
    "dataset['ts'].append(3)\n",
    "dataset['ts'].append(2)\n",
    "dataset['ts'].append(1)\n",
    "dataset[['tr','ts'].append([1,2])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['tr'][2]"
=======
    "\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build & Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: OV_six_fold_Annotation3000_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.8162 - acc: 0.5430\n",
      "186/186 [==============================] - 0s 544us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.6605 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 113us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 938us/step - loss: 0.6172 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 177us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 826us/step - loss: 0.6105 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 113us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 697us/step - loss: 0.6354 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 193us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 708us/step - loss: 0.6192 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 676us/step - loss: 0.5922 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 134us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 761us/step - loss: 0.6026 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 728us/step - loss: 0.5906 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 95us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 727us/step - loss: 0.6021 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 113us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 718us/step - loss: 0.6054 - acc: 0.7043\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 788us/step - loss: 0.6073 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 660us/step - loss: 0.6137 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 107us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 705us/step - loss: 0.5945 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 745us/step - loss: 0.5857 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 113us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 649us/step - loss: 0.5873 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 681us/step - loss: 0.5896 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 681us/step - loss: 0.5873 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 767us/step - loss: 0.5834 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 107us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.5869 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 724us/step - loss: 0.5993 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 113us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 643us/step - loss: 0.6067 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 118us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 676us/step - loss: 0.6050 - acc: 0.7097\n",
      "186/186 [==============================] - ETA:  - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.6052 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 660us/step - loss: 0.6037 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.6031 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 107us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 601us/step - loss: 0.6030 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 107us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 670us/step - loss: 0.6031 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 95us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.6036 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.6044 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.6030 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Model 1 trained.\n",
      "Model 1 saved.\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "31/31 [==============================] - 0s 96us/step\n",
      "Overall AUC:  0.5032467532467533\n",
      "Train AUC:  0.5037878787878788\n",
      "Test AUC:  0.5\n",
      "Train Accuracy: 0.7096774219184794\n",
      "Train Sensitivities & Specificities : 0.0, 1.0\n",
      "Test Accuracy: 0.7096773982048035\n",
      "Test Sensitivities & Specificities : 0.0, 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    train_data_1, test_data_1, y_val_1, x_val_1, test_y_val_1, test_x_val_1 = data_split(raw_data = data_1, index_col = -1, test_index = i)\n",
    "train_data_2, test_data_2, y_val_2, x_val_2, test_y_val_2, test_x_val_2 = data_split(raw_data = data_2, index_col = -1, test_index = 1)\n",
    "train_data_3, test_data_3, y_val_3, x_val_3, test_y_val_3, test_x_val_3 = data_split(raw_data = data_3, index_col = -1, test_index = 1)\n",
    "train_data_4, test_data_4, y_val_4, x_val_4, test_y_val_4, test_x_val_4 = data_split(raw_data = data_4, index_col = -1, test_index = 1)\n",
    "train_data_5, test_data_5, y_val_5, x_val_5, test_y_val_5, test_x_val_5 = data_split(raw_data = data_5, index_col = -1, test_index = 1)\n",
    "train_data_6, test_data_6, y_val_6, x_val_6, test_y_val_6, test_x_val_6 = data_split(raw_data = data_6, index_col = -1, test_index = 1)\n",
    "\n",
    "print(\"Model 1: \"+str(types[0]))\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "input_drop_out_m_1 = 0.3\n",
    "drop_out_m_1 = 0.5\n",
    "layers = [5]\n",
    "m_1_tr_loss_best = 100 # for saving best loss value \n",
    "best_m_1_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "input_m_1 = Input(shape=(features_1,))\n",
    "m_1_m_dp = Dropout(input_drop_out_m_1)(input_m_1)\n",
    "for i in layers:\n",
    "    m_1_m = Dense(i,activation='relu')(m_1_m_dp)\n",
    "    m_1_m_dp = Dropout(drop_out_m_1)(m_1_m)\n",
    "m_1_m_final = m_1_m_dp\n",
    "output_m_1 = Dense(1, activation=\"sigmoid\")(m_1_m_final)\n",
    "m_1_model = Model(inputs=input_m_1,outputs=output_m_1)\n",
    "m_1_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    m_1_model.fit(x_val_1, y_val_1, batch_size=5, nb_epoch=1)\n",
    "    m_1_tr_loss=m_1_model.evaluate(x_val_1,y_val_1)[0]\n",
    "    if m_1_tr_loss < m_1_tr_loss_best: # new best model. count reset.\n",
    "        m_1_tr_loss_best = m_1_tr_loss\n",
    "        count=0\n",
    "        best_m_1_model = m_1_model\n",
    "    if count>10: # no increase three time. stop.\n",
    "        m_1_model = best_m_1_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"Model 1 trained.\")\n",
    "\n",
    "# 4) save model\n",
    "m_1_model.save(save_model_path+\"/m_1.h5\")\n",
    "print(\"Model 1 saved.\")\n",
    "\n",
    "# 5) evaluate model\n",
    "m_1_output_list = model_performance(\n",
    "    information = False, using_model=m_1_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_1, tr_y_val=y_val_1, ts_x_val=test_x_val_1, ts_y_val=test_y_val_1,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "m_1_tr_loss, m_1_tr_accuracy, m_1_tr_sensitivity, m_1_tr_specificity, m_1_tr_predictions, m_1_labeled_tr_predictions, m_1_tr_predictions_flat, m_1_roc_auc_tr, m_1_ts_loss, m_1_ts_accuracy, m_1_ts_sensitivity, m_1_ts_specificity, m_1_ts_predictions,m_1_labeled_ts_predictions, m_1_ts_predictions_flat, m_1_roc_auc_ts, m_1_roc_auc_total = m_1_output_list\n",
    "\n",
    "print(\"Overall AUC: \", m_1_roc_auc_total)\n",
    "print(\"Train AUC: \", m_1_roc_auc_tr)\n",
    "print(\"Test AUC: \", m_1_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_1_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_1_tr_sensitivity)+\", \"+str(m_1_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_1_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_1_ts_sensitivity)+\", \"+str(m_1_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_val_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_m_1 = pd.DataFrame(data={\"patient\":list(train_data_1.index), \"hypothesis 1\": list(m_1_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_1_labeled_tr_predictions), \"Platinum_Status\":list(y_val_1)})\n",
    "tr_df_m_1.to_csv(save_prediction_path+\"prediction_result_m_1_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_1 = pd.DataFrame(data={\"patient\":list(test_data_1.index), \"hypothesis 1\": list(m_1_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_1_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_1)})\n",
    "ts_df_m_1.to_csv(save_prediction_path+\"prediction_result_m_1_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model_2: \"+str(types[1]))\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "input_drop_out_m_2 = 0.3\n",
    "drop_out_m_2 = 0.5\n",
    "layers = [5]\n",
    "m_2_tr_loss_best = 100 # for saving best loss value \n",
    "best_m_2_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "input_m_2 = Input(shape=(features_2,))\n",
    "m_2_m_dp = Dropout(input_drop_out_m_2)(input_m_2)\n",
    "for i in layers:\n",
    "    m_2_m = Dense(i,activation='relu')(m_2_m_dp)\n",
    "    m_2_m_dp = Dropout(drop_out_m_2)(m_2_m)\n",
    "m_2_m_final = m_2_m_dp\n",
    "output_m_2 = Dense(1, activation=\"sigmoid\")(m_2_m_final)\n",
    "m_2_model = Model(inputs=input_m_2,outputs=output_m_2)\n",
    "m_2_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    m_2_model.fit(x_val_2, y_val_2, batch_size=5, nb_epoch=1)\n",
    "    m_2_tr_loss=m_2_model.evaluate(x_val_2,y_val_2)[0]\n",
    "    if m_2_tr_loss < m_2_tr_loss_best: # new best model. count reset.\n",
    "        m_2_tr_loss_best = m_2_tr_loss\n",
    "        count=0\n",
    "        best_m_2_model = m_2_model\n",
    "    if count>3: # no increase three time. stop.\n",
    "        m_2_model = best_m_2_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"Model_2 trained.\")\n",
    "\n",
    "# 4) save model\n",
    "m_2_model.save(save_model_path+\"/m_2.h5\")\n",
    "print(\"Model_2 saved.\")\n",
    "\n",
    "# 5) evaluate model\n",
    "m_2_output_list = model_performance(\n",
    "    information = False, using_model=m_2_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_2, tr_y_val=y_val_2, ts_x_val=test_x_val_2, ts_y_val=test_y_val_2,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "m_2_tr_loss, m_2_tr_accuracy, m_2_tr_sensitivity, m_2_tr_specificity, m_2_tr_predictions, m_2_labeled_tr_predictions, m_2_tr_predictions_flat, m_2_roc_auc_tr, m_2_ts_loss, m_2_ts_accuracy, m_2_ts_sensitivity, m_2_ts_specificity, m_2_ts_predictions,m_2_labeled_ts_predictions, m_2_ts_predictions_flat, m_2_roc_auc_ts, m_2_roc_auc_total = m_2_output_list\n",
    "\n",
    "print(\"Overall AUC: \", m_2_roc_auc_total)\n",
    "print(\"Train AUC: \", m_2_roc_auc_tr)\n",
    "print(\"Test AUC: \", m_2_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_2_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_2_tr_sensitivity)+\", \"+str(m_2_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_2_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_2_ts_sensitivity)+\", \"+str(m_2_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_m_2 = pd.DataFrame(data={\"patient\":list(train_data_2.index), \"hypothesis 1\": list(m_2_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_2_labeled_tr_predictions), \"Platinum_Status\":list(y_val_2)})\n",
    "tr_df_m_2.to_csv(save_prediction_path+\"prediction_result_m_2_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_2 = pd.DataFrame(data={\"patient\":list(test_data_2.index), \"hypothesis 1\": list(m_2_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_2_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_2)})\n",
    "ts_df_m_2.to_csv(save_prediction_path+\"prediction_result_m_2_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model_3: \"+str(types[2]))\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "input_drop_out_m_3 = 0.3\n",
    "drop_out_m_3 = 0.5\n",
    "layers = [5]\n",
    "m_3_tr_loss_best = 100 # for saving best loss value \n",
    "best_m_3_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "input_m_3 = Input(shape=(features_3,))\n",
    "m_3_m_dp = Dropout(input_drop_out_m_3)(input_m_3)\n",
    "for i in layers:\n",
    "    m_3_m = Dense(i,activation='relu')(m_3_m_dp)\n",
    "    m_3_m_dp = Dropout(drop_out_m_3)(m_3_m)\n",
    "m_3_m_final = m_3_m_dp\n",
    "output_m_3 = Dense(1, activation=\"sigmoid\")(m_3_m_final)\n",
    "m_3_model = Model(inputs=input_m_3,outputs=output_m_3)\n",
    "m_3_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    m_3_model.fit(x_val_3, y_val_3, batch_size=5, nb_epoch=1)\n",
    "    m_3_tr_loss=m_3_model.evaluate(x_val_3,y_val_3)[0]\n",
    "    if m_3_tr_loss < m_3_tr_loss_best: # new best model. count reset.\n",
    "        m_3_tr_loss_best = m_3_tr_loss\n",
    "        count=0\n",
    "        best_m_3_model = m_3_model\n",
    "    if count>3: # no increase three time. stop.\n",
    "        m_3_model = best_m_3_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"Model_3 trained.\")\n",
    "\n",
    "# 4) save model\n",
    "m_3_model.save(save_model_path+\"/m_3.h5\")\n",
    "print(\"Model_3 saved.\")\n",
    "\n",
    "# 5) evaluate model\n",
    "m_3_output_list = model_performance(\n",
    "    information = False, using_model=m_3_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_3, tr_y_val=y_val_3, ts_x_val=test_x_val_3, ts_y_val=test_y_val_3,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "m_3_tr_loss, m_3_tr_accuracy, m_3_tr_sensitivity, m_3_tr_specificity, m_3_tr_predictions, m_3_labeled_tr_predictions, m_3_tr_predictions_flat, m_3_roc_auc_tr, m_3_ts_loss, m_3_ts_accuracy, m_3_ts_sensitivity, m_3_ts_specificity, m_3_ts_predictions,m_3_labeled_ts_predictions, m_3_ts_predictions_flat, m_3_roc_auc_ts, m_3_roc_auc_total = m_3_output_list\n",
    "\n",
    "print(\"Overall AUC: \", m_3_roc_auc_total)\n",
    "print(\"Train AUC: \", m_3_roc_auc_tr)\n",
    "print(\"Test AUC: \", m_3_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_3_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_3_tr_sensitivity)+\", \"+str(m_3_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_3_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_3_ts_sensitivity)+\", \"+str(m_3_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_m_3 = pd.DataFrame(data={\"patient\":list(train_data_3.index), \"hypothesis 1\": list(m_3_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_3_labeled_tr_predictions), \"Platinum_Status\":list(y_val_3)})\n",
    "tr_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_3 = pd.DataFrame(data={\"patient\":list(test_data_3.index), \"hypothesis 1\": list(m_3_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_3_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_3)})\n",
    "ts_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model 4"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
=======
   "execution_count": 22,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Model_4: OV_six_fold_new_Diff_100\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 3ms/step - loss: 0.6863 - acc: 0.6075\n",
      "186/186 [==============================] - 0s 452us/step\n",
      "best model: 0.7096774206366591\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 660us/step - loss: 0.5718 - acc: 0.7097\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 0.7688172010965245\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.5213 - acc: 0.7581\n",
      "186/186 [==============================] - 0s 113us/step\n",
      "best model: 0.849462366232308\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.5149 - acc: 0.7688\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.5242 - acc: 0.7527\n",
      "186/186 [==============================] - 0s 82us/step\n",
      "best model: 0.849462366232308\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 654us/step - loss: 0.4727 - acc: 0.8065\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 0.8763440866624156\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.4242 - acc: 0.8065\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 0.8870967748344586\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 649us/step - loss: 0.4276 - acc: 0.7903\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.4577 - acc: 0.8011\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 0.8924731144341089\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 676us/step - loss: 0.4856 - acc: 0.7903\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 0.9032258070925231\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.4529 - acc: 0.7957\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "best model: 0.9032258032470621\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.4124 - acc: 0.8065\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 0.9086021473330836\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 660us/step - loss: 0.4510 - acc: 0.8387\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 601us/step - loss: 0.4556 - acc: 0.7957\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 643us/step - loss: 0.4398 - acc: 0.8011\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "best model: 0.9139784907781949\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 568us/step - loss: 0.4361 - acc: 0.8333\n",
      "186/186 [==============================] - 0s 134us/step\n",
      "best model: 0.9193548348642164\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 665us/step - loss: 0.4031 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "best model: 0.9247311789502379\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 643us/step - loss: 0.4004 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 0.9301075268817204\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.4270 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 0.9354838671222809\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 622us/step - loss: 0.3621 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 0.9301075230362594\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 558us/step - loss: 0.3840 - acc: 0.8226\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 617us/step - loss: 0.4427 - acc: 0.7903\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 0.9408602112083024\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 563us/step - loss: 0.4244 - acc: 0.7903\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 0.9516128993803455\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 579us/step - loss: 0.4327 - acc: 0.8118\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 643us/step - loss: 0.4530 - acc: 0.8118\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 0.946236555294324\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 579us/step - loss: 0.4236 - acc: 0.7796\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 0.946236555294324\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 633us/step - loss: 0.3654 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 617us/step - loss: 0.3945 - acc: 0.8387\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 0.9623655913978495\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 697us/step - loss: 0.3947 - acc: 0.8333\n",
      "186/186 [==============================] - 0s 107us/step\n",
      "best model: 0.9516129032258065\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 617us/step - loss: 0.3492 - acc: 0.8495\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 0.9623655913978495\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 568us/step - loss: 0.3698 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 0.967741935483871\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 558us/step - loss: 0.3541 - acc: 0.8656\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 0.978494623655914\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 558us/step - loss: 0.4008 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 0.978494623655914\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 520us/step - loss: 0.3615 - acc: 0.8548\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 0.9731182795698925\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.3722 - acc: 0.8226\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 0.978494623655914\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.3845 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.3981 - acc: 0.8226\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 0.9731182795698925\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 654us/step - loss: 0.4001 - acc: 0.8441\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 0.978494623655914\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.3433 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.4561 - acc: 0.7957\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.4237 - acc: 0.8226\n",
      "186/186 [==============================] - 0s 107us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 563us/step - loss: 0.3894 - acc: 0.8065\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.3344 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 0.9838709677419355\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 531us/step - loss: 0.3536 - acc: 0.8333\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 0.9731182795698925\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.4277 - acc: 0.7903\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 579us/step - loss: 0.4033 - acc: 0.8280\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 0.9838709677419355\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.4312 - acc: 0.8065\n",
      "186/186 [==============================] - 0s 118us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: 0.9731182795698925\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 638us/step - loss: 0.3895 - acc: 0.8333\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "best model: 0.9731182795698925\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.4256 - acc: 0.8118\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.3355 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 660us/step - loss: 0.3697 - acc: 0.8118\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 656us/step - loss: 0.3859 - acc: 0.8333\n",
      "186/186 [==============================] - 0s 88us/step\n",
      "best model: 0.9838709677419355\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.4335 - acc: 0.7957\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 0.9838709677419355\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 831us/step - loss: 0.3922 - acc: 0.8226\n",
      "186/186 [==============================] - 0s 140us/step\n",
      "best model: 0.989247311827957\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 767us/step - loss: 0.3618 - acc: 0.8387\n",
      "186/186 [==============================] - 0s 139us/step\n",
      "best model: 0.989247311827957\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 777us/step - loss: 0.3158 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "best model: 0.9838709677419355\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 804us/step - loss: 0.4330 - acc: 0.7957\n",
      "186/186 [==============================] - 0s 166us/step\n",
      "best model: 0.9946236559139785\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 777us/step - loss: 0.3834 - acc: 0.8280\n",
      "186/186 [==============================] - 0s 118us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 783us/step - loss: 0.3784 - acc: 0.8280\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 724us/step - loss: 0.3930 - acc: 0.8548 0s - loss: 0.4015 - acc: 0.856\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 0.9946236559139785\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 692us/step - loss: 0.3148 - acc: 0.8548\n",
      "186/186 [==============================] - 0s 96us/step\n",
      "best model: 0.9946236559139785\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 649us/step - loss: 0.3464 - acc: 0.8871\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "best model: 0.989247311827957\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 638us/step - loss: 0.3262 - acc: 0.8387\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 670us/step - loss: 0.3368 - acc: 0.8548\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 0.989247311827957\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 601us/step - loss: 0.2812 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 622us/step - loss: 0.3727 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.3850 - acc: 0.8065\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 0.9946236559139785\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 568us/step - loss: 0.4188 - acc: 0.8118\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.3696 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.3941 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 590us/step - loss: 0.3579 - acc: 0.8280\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.3051 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 777us/step - loss: 0.2992 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 697us/step - loss: 0.3772 - acc: 0.8548\n",
      "186/186 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 681us/step - loss: 0.3827 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 670us/step - loss: 0.3738 - acc: 0.8548\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 719us/step - loss: 0.3387 - acc: 0.8441\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 692us/step - loss: 0.2764 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 702us/step - loss: 0.3482 - acc: 0.8548\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 676us/step - loss: 0.3622 - acc: 0.8387\n",
      "186/186 [==============================] - 0s 113us/step\n",
      "best model: 0.9946236520685175\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 713us/step - loss: 0.4121 - acc: 0.8333\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.3476 - acc: 0.8495\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 579us/step - loss: 0.3493 - acc: 0.8441\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 579us/step - loss: 0.3735 - acc: 0.8333\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 568us/step - loss: 0.3210 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.3643 - acc: 0.8011\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 633us/step - loss: 0.3061 - acc: 0.8817 0s - loss: 0.2968 - acc: 0.904 - ETA: 0s - loss: 0.3002 - acc: 0.886\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 568us/step - loss: 0.3193 - acc: 0.8387\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 633us/step - loss: 0.3071 - acc: 0.8656\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.2876 - acc: 0.8871\n",
      "186/186 [==============================] - 0s 107us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 654us/step - loss: 0.3128 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 643us/step - loss: 0.3418 - acc: 0.8333\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 665us/step - loss: 0.2913 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 702us/step - loss: 0.3310 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 676us/step - loss: 0.3922 - acc: 0.8280\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 692us/step - loss: 0.3088 - acc: 0.9086\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 633us/step - loss: 0.2927 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 740us/step - loss: 0.3482 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 702us/step - loss: 0.2517 - acc: 0.9140\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 617us/step - loss: 0.3378 - acc: 0.8548\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.2751 - acc: 0.9032\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 622us/step - loss: 0.3164 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 617us/step - loss: 0.3368 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.3559 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 77us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.2910 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.2854 - acc: 0.9194\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.3083 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 64us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.2770 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 575us/step - loss: 0.3460 - acc: 0.8441\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.2723 - acc: 0.8978\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 563us/step - loss: 0.3148 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 610us/step - loss: 0.3099 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 713us/step - loss: 0.2722 - acc: 0.8925\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 756us/step - loss: 0.3994 - acc: 0.8226\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 660us/step - loss: 0.2596 - acc: 0.9086\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 670us/step - loss: 0.2993 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 826us/step - loss: 0.2689 - acc: 0.9086\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 660us/step - loss: 0.3283 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 724us/step - loss: 0.3367 - acc: 0.8441\n",
      "186/186 [==============================] - 0s 156us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 697us/step - loss: 0.3059 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 118us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.3082 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.2822 - acc: 0.9032\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 638us/step - loss: 0.3926 - acc: 0.8226\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 590us/step - loss: 0.3221 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.3076 - acc: 0.8925\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.2333 - acc: 0.9355\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 622us/step - loss: 0.3342 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 622us/step - loss: 0.2994 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 563us/step - loss: 0.2702 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 622us/step - loss: 0.3611 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 563us/step - loss: 0.2714 - acc: 0.8871\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.3130 - acc: 0.8656\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.3043 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.2879 - acc: 0.8978\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.2949 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 536us/step - loss: 0.3091 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 590us/step - loss: 0.3745 - acc: 0.8387\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.3306 - acc: 0.8656\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 590us/step - loss: 0.3195 - acc: 0.8656\n",
      "186/186 [==============================] - 0s 80us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 531us/step - loss: 0.2798 - acc: 0.9032\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 536us/step - loss: 0.2969 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 547us/step - loss: 0.2586 - acc: 0.8656\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.3129 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.2849 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 113us/step\n",
      "best model: 1.0\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.3048 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.2490 - acc: 0.9140\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 563us/step - loss: 0.2935 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 590us/step - loss: 0.2969 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 542us/step - loss: 0.3078 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.3468 - acc: 0.8495\n",
      "186/186 [==============================] - 0s 91us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.2909 - acc: 0.8925\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 558us/step - loss: 0.2733 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 536us/step - loss: 0.3098 - acc: 0.8710\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.2974 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 64us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 702us/step - loss: 0.3038 - acc: 0.8710 0s - loss: 0.2635 - acc: 0.90\n",
      "186/186 [==============================] - 0s 102us/step\n",
      "Model_4 trained.\n",
      "Model_4 saved.\n",
      "186/186 [==============================] - 0s 97us/step\n",
      "31/31 [==============================] - 0s 504us/step\n",
      "Overall AUC:  0.9942279942279942\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8333333333333333\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.774193525314331\n",
      "Test Sensitivities & Specificities : 0.5555555555555556, 0.8636363636363636\n"
=======
      "Model_4: OV_six_fold_new_Diff_400\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6712 - acc: 0.6344\n",
      "186/186 [==============================] - 0s 2ms/step\n",
      "best model: 0.7688172062238058\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.5001 - acc: 0.7312\n",
      "186/186 [==============================] - 0s 65us/step\n",
      "best model: 0.7580645135653916\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.4220 - acc: 0.8226\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 0.8602150550452612\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.3446 - acc: 0.8495\n",
      "186/186 [==============================] - 0s 65us/step\n",
      "best model: 0.8602150550452612\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.3951 - acc: 0.8172\n",
      "186/186 [==============================] - 0s 65us/step\n",
      "best model: 0.9301075236771696\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.3178 - acc: 0.8763\n",
      "186/186 [==============================] - 0s 65us/step\n",
      "best model: 0.9838709638964745\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.2652 - acc: 0.8871\n",
      "186/186 [==============================] - 0s 59us/step\n",
      "best model: 0.9731182757244315\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.3317 - acc: 0.8602\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 0.9838709638964745\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.2862 - acc: 0.8871\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 0.989247307982496\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.3638 - acc: 0.8118\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "best model: 0.9946236559139785\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.9194\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.3038 - acc: 0.8548\n",
      "186/186 [==============================] - 0s 65us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.2671 - acc: 0.8817\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "best model: 0.9946236559139785\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.2306 - acc: 0.9086\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.2386 - acc: 0.8978\n",
      "186/186 [==============================] - 0s 70us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.2804 - acc: 0.8925\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.3187 - acc: 0.8495\n",
      "186/186 [==============================] - 0s 75us/step\n",
      "Model_4 trained.\n",
      "Model_4 saved.\n",
      "186/186 [==============================] - 0s 86us/step\n",
      "31/31 [==============================] - 0s 65us/step\n",
      "Overall AUC:  0.9786641929499071\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.606060606060606\n",
      "Train Accuracy: 0.989247311827957\n",
      "Train Sensitivities & Specificities : 1.0, 0.9848484848484849\n",
      "Test Accuracy: 0.6129032373428345\n",
      "Test Sensitivities & Specificities : 0.7777777777777778, 0.5454545454545454\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "print(\"Model_4: \"+str(types[3]))\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "input_drop_out_m_4 = 0.3\n",
    "drop_out_m_4 = 0.5\n",
    "layers = [100]\n",
    "m_4_tr_loss_best = 100 # for saving best loss value \n",
    "best_m_4_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "input_m_4 = Input(shape=(features_4,))\n",
    "m_4_m_bn = Dropout(input_drop_out_m_4)(input_m_4)\n",
    "for i in layers:\n",
    "    m_4_m = Dense(i)(m_4_m_bn)\n",
    "    m_4_m_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(m_4_m)\n",
    "    m_4_m_ac = Activation(\"relu\")(m_4_m_bn)\n",
    "m_4_m_final = m_4_m_ac\n",
    "output_m_4 = Dense(1, activation=\"sigmoid\")(m_4_m_final)\n",
    "m_4_model = Model(inputs=input_m_4,outputs=output_m_4)\n",
    "m_4_model.compile(optimizer=optimizers.Adam(), \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    m_4_model.fit(x_val_4, y_val_4, batch_size=5, epochs=1)\n",
    "    m_4_tr_loss, m_4_tr_accuracy =m_4_model.evaluate(x_val_4,y_val_4)\n",
    "    if m_4_tr_loss < m_4_tr_loss_best: # new best model. count reset.\n",
    "        m_4_tr_loss_best = m_4_tr_loss\n",
    "        count=0\n",
    "        best_m_4_model = m_4_model\n",
    "        print(\"best model: \"+str(m_4_tr_accuracy))\n",
<<<<<<< Updated upstream
    "    if count>10: # no increase three time. stop.\n",
=======
    "    if count>3: # no increase three time. stop.\n",
>>>>>>> Stashed changes
    "        m_4_model = best_m_4_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"Model_4 trained.\")\n",
    "\n",
    "# 4) save model\n",
    "m_4_model.save(save_model_path+\"/m_4.h5\")\n",
    "print(\"Model_4 saved.\")\n",
    "\n",
    "# 5) evaluate model\n",
    "m_4_output_list = model_performance(\n",
    "    information = False, using_model=m_4_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_4, tr_y_val=y_val_4, ts_x_val=test_x_val_4, ts_y_val=test_y_val_4,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "m_4_tr_loss, m_4_tr_accuracy, m_4_tr_sensitivity, m_4_tr_specificity, m_4_tr_predictions, m_4_labeled_tr_predictions, m_4_tr_predictions_flat, m_4_roc_auc_tr, m_4_ts_loss, m_4_ts_accuracy, m_4_ts_sensitivity, m_4_ts_specificity, m_4_ts_predictions,m_4_labeled_ts_predictions, m_4_ts_predictions_flat, m_4_roc_auc_ts, m_4_roc_auc_total = m_4_output_list\n",
    "\n",
    "print(\"Overall AUC: \", m_4_roc_auc_total)\n",
    "print(\"Train AUC: \", m_4_roc_auc_tr)\n",
    "print(\"Test AUC: \", m_4_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_4_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_4_tr_sensitivity)+\", \"+str(m_4_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_4_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_4_ts_sensitivity)+\", \"+str(m_4_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_m_3 = pd.DataFrame(data={\"patient\":list(train_data_3.index), \"hypothesis 1\": list(m_3_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_3_labeled_tr_predictions), \"Platinum_Status\":list(y_val_3)})\n",
    "tr_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_3 = pd.DataFrame(data={\"patient\":list(test_data_3.index), \"hypothesis 1\": list(m_3_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_3_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_3)})\n",
    "ts_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model_5: \"+str(types[0]))\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "input_drop_out_m_5 = 0.3\n",
    "drop_out_m_5 = 0.5\n",
    "layers = [5]\n",
    "m_5_tr_loss_best = 100 # for saving best loss value \n",
    "best_m_5_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "input_m_5 = Input(shape=(features_5,))\n",
    "m_5_m_dp = Dropout(input_drop_out_m_5)(input_m_5)\n",
    "for i in layers:\n",
    "    m_5_m = Dense(i,activation='relu')(m_5_m_dp)\n",
    "    m_5_m_dp = Dropout(drop_out_m_5)(m_5_m)\n",
    "m_5_m_final = m_5_m_dp\n",
    "output_m_5 = Dense(1, activation=\"sigmoid\")(m_5_m_final)\n",
    "m_5_model = Model(inputs=input_m_5,outputs=output_m_5)\n",
    "m_5_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    m_5_model.fit(x_val_5, y_val_5, batch_size=5, nb_epoch=1)\n",
    "    m_5_tr_loss=m_5_model.evaluate(x_val_5,y_val_5)[0]\n",
    "    if m_5_tr_loss < m_5_tr_loss_best: # new best model. count reset.\n",
    "        m_5_tr_loss_best = m_5_tr_loss\n",
    "        count=0\n",
    "        best_m_5_model = m_5_model\n",
    "    if count>3: # no increase three time. stop.\n",
    "        m_5_model = best_m_5_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"Model_5 trained.\")\n",
    "\n",
    "# 4) save model\n",
    "m_5_model.save(save_model_path+\"/m_5.h5\")\n",
    "print(\"Model_5 saved.\")\n",
    "\n",
    "# 5) evaluate model\n",
    "m_5_output_list = model_performance(\n",
    "    information = False, using_model=m_5_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_5, tr_y_val=y_val_5, ts_x_val=test_x_val_5, ts_y_val=test_y_val_5,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "m_5_tr_loss, m_5_tr_accuracy, m_5_tr_sensitivity, m_5_tr_specificity, m_5_tr_predictions, m_5_labeled_tr_predictions, m_5_tr_predictions_flat, m_5_roc_auc_tr, m_5_ts_loss, m_5_ts_accuracy, m_5_ts_sensitivity, m_5_ts_specificity, m_5_ts_predictions,m_5_labeled_ts_predictions, m_5_ts_predictions_flat, m_5_roc_auc_ts, m_5_roc_auc_total = m_5_output_list\n",
    "\n",
    "print(\"Overall AUC: \", m_5_roc_auc_total)\n",
    "print(\"Train AUC: \", m_5_roc_auc_tr)\n",
    "print(\"Test AUC: \", m_5_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_5_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_5_tr_sensitivity)+\", \"+str(m_5_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_5_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_5_ts_sensitivity)+\", \"+str(m_5_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_m_3 = pd.DataFrame(data={\"patient\":list(train_data_3.index), \"hypothesis 1\": list(m_3_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_3_labeled_tr_predictions), \"Platinum_Status\":list(y_val_3)})\n",
    "tr_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_3 = pd.DataFrame(data={\"patient\":list(test_data_3.index), \"hypothesis 1\": list(m_3_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_3_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_3)})\n",
    "ts_df_m_3.to_csv(save_prediction_path+\"prediction_result_m_3_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Model 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model_6: \"+str(types[0]))\n",
    "\n",
    "# 1) parameter setting\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "input_drop_out_m_6 = 0.3\n",
    "drop_out_m_6 = 0.5\n",
    "layers = [5]\n",
    "m_6_tr_loss_best = 100 # for saving best loss value \n",
    "best_m_6_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "input_m_6 = Input(shape=(features_6,))\n",
    "m_6_m_dp = Dropout(input_drop_out_m_6)(input_m_6)\n",
    "for i in layers:\n",
    "    m_6_m = Dense(i,activation='relu')(m_6_m_dp)\n",
    "    m_6_m_dp = Dropout(drop_out_m_6)(m_6_m)\n",
    "m_6_m_final = m_6_m_dp\n",
    "output_m_6 = Dense(1, activation=\"sigmoid\")(m_6_m_final)\n",
    "m_6_model = Model(inputs=input_m_6,outputs=output_m_6)\n",
    "m_6_model.compile(optimizer=adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    m_6_model.fit(x_val_6, y_val_6, batch_size=5, nb_epoch=1)\n",
    "    m_6_tr_loss=m_6_model.evaluate(x_val_6,y_val_6)[0]\n",
    "    if m_6_tr_loss < m_6_tr_loss_best: # new best model. count reset.\n",
    "        m_6_tr_loss_best = m_6_tr_loss\n",
    "        count=0\n",
    "        best_m_6_model = m_6_model\n",
    "    if count>3: # no increase three time. stop.\n",
    "        m_6_model = best_m_6_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"Model_6 trained.\")\n",
    "\n",
    "# 4) save model\n",
    "m_6_model.save(save_model_path+\"/m_6.h5\")\n",
    "print(\"Model_6 saved.\")\n",
    "\n",
    "# 5) evaluate model\n",
    "m_6_output_list = model_performance(\n",
    "    information = False, using_model=m_6_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=x_val_6, tr_y_val=y_val_6, ts_x_val=test_x_val_6, ts_y_val=test_y_val_6,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "m_6_tr_loss, m_6_tr_accuracy, m_6_tr_sensitivity, m_6_tr_specificity, m_6_tr_predictions, m_6_labeled_tr_predictions, m_6_tr_predictions_flat, m_6_roc_auc_tr, m_6_ts_loss, m_6_ts_accuracy, m_6_ts_sensitivity, m_6_ts_specificity, m_6_ts_predictions,m_6_labeled_ts_predictions, m_6_ts_predictions_flat, m_6_roc_auc_ts, m_6_roc_auc_total = m_6_output_list\n",
    "\n",
    "print(\"Overall AUC: \", m_6_roc_auc_total)\n",
    "print(\"Train AUC: \", m_6_roc_auc_tr)\n",
    "print(\"Test AUC: \", m_6_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(m_6_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(m_6_tr_sensitivity)+\", \"+str(m_6_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(m_6_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(m_6_ts_sensitivity)+\", \"+str(m_6_ts_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction result.\n",
    "\n",
    "tr_df_m_6 = pd.DataFrame(data={\"patient\":list(train_data_6.index), \"hypothesis 1\": list(m_6_tr_predictions_flat), \n",
    "                        \"prediction\":list(m_6_labeled_tr_predictions), \"Platinum_Status\":list(y_val_6)})\n",
    "tr_df_m_6.to_csv(save_prediction_path+\"prediction_result_m_6_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_m_6 = pd.DataFrame(data={\"patient\":list(test_data_6.index), \"hypothesis 1\": list(m_6_ts_predictions_flat), \n",
    "                        \"prediction\":list(m_6_labeled_ts_predictions), \"Platinum_Status\":list(test_y_val_6)})\n",
    "ts_df_m_6.to_csv(save_prediction_path+\"prediction_result_m_6_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "tr_accuracy_list = [m_1_tr_accuracy, m_2_tr_accuracy, m_3_tr_accuracy, m_4_tr_accuracy, m_5_tr_accuracy, m_6_tr_accuracy]\n",
    "ts_accuracy_list = [m_1_ts_accuracy, m_2_ts_accuracy, m_3_ts_accuracy, m_4_ts_accuracy, m_5_ts_accuracy, m_6_ts_accuracy]\n",
    "\n",
    "for i in range(1,7):\n",
    "    label.append(\"model\"+str(i))\n",
    "\n",
    "for model_num in range(len(label)):\n",
    "    print(\"< \"+label[model_num]+\" > tr: \"+str(tr_accuracy_list[model_num])+\", ts: \"+str(ts_accuracy_list[model_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_x():\n",
    "    # this is for plotting purpose\n",
    "    plt.figure(figsize=(30,20))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([min(ts_accuracy_list)-0.02, max(ts_accuracy_list)+0.02])\n",
    "    index = np.arange(len(label))\n",
    "    plt.bar(index, ts_accuracy_list,color=['red', 'orange', 'yellow', \"green\",'blue', 'purple'],alpha=0.5,width=0.3)\n",
    "    plt.xlabel('Method', fontsize=35)\n",
    "    plt.ylabel('Accuracy', fontsize=35)\n",
    "    plt.yticks(fontsize=30)    \n",
    "    plt.xticks(index, types, fontsize=30, rotation=90)\n",
    "    plt.title('Performance Comparison for each Models',fontsize=40)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_bar_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
