{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Input, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, load_model, Sequential \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "#ensemble\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Functions library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['resistant-correct'] = 0\n",
    "    result['resistant-wrong'] = 0\n",
    "    result['sensitive-correct'] = 0\n",
    "    result['sensitive-wrong'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-correct'] += 1\n",
    "            else :\n",
    "                result['resistant-correct'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['sensitive-wrong'] += 1\n",
    "            else :\n",
    "                result['resistant-wrong'] += 1\n",
    "\n",
    "    #for result_k, result_v in result.items():\n",
    "    #    print(result_k +\" : \"+ str(result_v))\n",
    "    sensitivity=result['resistant-correct']/(result['resistant-correct']+result['resistant-wrong'])\n",
    "    specificity=result['sensitive-correct']/(result['sensitive-correct']+result['sensitive-wrong'])\n",
    "    #print(\"Sensitivity :\", sensitivity)\n",
    "    #print(\"Specificity :\", specificity)\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide raw data into train / test & x_val / y_val\n",
    "def data_split(raw_data, index_col, test_index):\n",
    "    \n",
    "    train_data = raw_data.iloc[list(raw_data.iloc[:,index_col]!=test_index)]\n",
    "    test_data = raw_data.iloc[list(raw_data.iloc[:,index_col]==test_index)]\n",
    "    \n",
    "    y_val = train_data.Platinum_Status\n",
    "    x_val = train_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    test_y_val = test_data.Platinum_Status\n",
    "    test_x_val = test_data.drop([\"Platinum_Status\",\"index\"],axis=1)\n",
    "    \n",
    "    return train_data, test_data, y_val, x_val, test_y_val, test_x_val\n",
    "\n",
    "    # raw_data: have gene_expressions(maybe multiple columns), index column, Platinum_Status column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all of model performance \n",
    "# - predictions(probability) / labeled predictions(0/1) / Loss / Accuracy / Sensitivity / Specificity / AUC values of Train / Test dataset.\n",
    "# using trained models, or you can put predictions(probability) passively(in this case, Loss & Accuracy do not provided.)\n",
    "def model_performance(information=False, Input_Prediction_Passively=False, using_model=None, tr_predictions=None, ts_predictions=None, tr_x_val=None, tr_y_val=None, ts_x_val=None, ts_y_val=None, output_list=None):\n",
    "    \n",
    "    if information == True:            \n",
    "        print(\"options model_performance:\\n1) using_model: keras models that you want to check performance. \\\"Input_Prediction_Passive\\\" option for input prediction list instead using models.\\n3) tr_predictions & ts_predictions: prediction input passively. put this data only when not using keras model.\\n4) tr_x_val & ts_x_val: input samples of train/test samples.\\n4) tr_y_val & ts_y_val: results of train/test samples.\\n5) output_list: return values that you want to recieve.\\n CAUTION: Essential variable.\\n\\t tr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\\n\\n* CAUTION: if 'None' value is returned, please check your input tr inputs(None value for tr outputs) or ts inputs(None value for ts outputs).\") \n",
    "        return 0\n",
    "    elif information != False:\n",
    "        print(\"for using information options, please set 'information' variable for 'True'\")\n",
    "        return -1\n",
    "    \n",
    "    if using_model is None:\n",
    "        if Input_Prediction_Passively == False:\n",
    "            print(\"ERROR: There are no models for using.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\") \n",
    "            return -1\n",
    "        elif (tr_predictions is None) and (ts_predictions is None): # No model/prediction input. no performance should be calculated.\n",
    "                print(\"ERROR: Input prediction list instead using saved model.\")\n",
    "                return -1\n",
    "        else: # No model input, but Input_Prediction_Passively is True & input prediction is valid.\n",
    "            tr_loss,tr_accuracy= None, None\n",
    "            ts_loss,ts_accuracy= None, None\n",
    "            \n",
    "    elif Input_Prediction_Passively == True: # both of model/prediction putted, could cause confusing.\n",
    "        ch = input(\"You put both model and prediction. Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "        while 1:\n",
    "            if ch == 'p':\n",
    "                using_model = None\n",
    "                break\n",
    "            elif ch == 'm':\n",
    "                tr_predictions = None\n",
    "                ts_predictions = None\n",
    "                break\n",
    "            elif ch == 'e':\n",
    "                return 0\n",
    "            else:\n",
    "                print(\"you put worng option: \"+str(ch))\n",
    "            ch = input(\"Select one method:\\n'p' for using prediction only, 'm' using models only, 'n' for quit the function.\")\n",
    "                \n",
    "    if output_list is None:\n",
    "        print(\"ERROR: There are no output_list for return.\\nusing \\\"model_performance(information = True)\\\" for getting informations of this function.\")\n",
    "        return -1\n",
    "    \n",
    "    if not(tr_x_val is None) and not(tr_y_val is None):\n",
    "        # predict tr result only when no tr_prediction input\n",
    "        if tr_predictions is None:\n",
    "            tr_loss,tr_accuracy= using_model.evaluate(tr_x_val,tr_y_val)\n",
    "            tr_predictions = using_model.predict(tr_x_val)\n",
    "        # tr sensitivity / specificity\n",
    "        labeled_tr_predictions = np.where(tr_predictions > 0.5, 1, 0).flatten()\n",
    "        tr_sensitivity, tr_specificity = check_correct(labeled_tr_predictions, tr_y_val)\n",
    "        tr_predictions_flat = tr_predictions[:,0]   \n",
    "        # roc(tr)\n",
    "        fpr_tr, tpr_tr, threshold_tr = metrics.roc_curve(tr_y_val, tr_predictions)\n",
    "        roc_auc_tr = metrics.auc(fpr_tr, tpr_tr)\n",
    "    \n",
    "    if not(ts_x_val is None) and not(ts_y_val is None):\n",
    "        # predict ts result only when no ts_prediction input\n",
    "        if ts_predictions is None:\n",
    "            ts_loss,ts_accuracy= using_model.evaluate(ts_x_val,ts_y_val)\n",
    "            ts_predictions = using_model.predict(ts_x_val)\n",
    "        labeled_ts_predictions = np.where(ts_predictions > 0.5, 1, 0).flatten()\n",
    "        ts_sensitivity, ts_specificity = check_correct(labeled_ts_predictions, ts_y_val)\n",
    "        ts_predictions_flat = ts_predictions[:,0]   \n",
    "        # roc(ts)\n",
    "        fpr_ts, tpr_ts, threshold_ts = metrics.roc_curve(ts_y_val, ts_predictions)\n",
    "        roc_auc_ts = metrics.auc(fpr_ts, tpr_ts)    \n",
    "    \n",
    "    if (not(tr_x_val is None) and not(tr_y_val is None)) and (not(ts_x_val is None) and not(ts_y_val is None)):\n",
    "        y_true = np.append(tr_y_val, ts_y_val)\n",
    "        y_pred = np.append(tr_predictions, ts_predictions)\n",
    "        fpr_total, tpr_total, threshold_total = metrics.roc_curve(y_true, y_pred)\n",
    "        roc_auc_total = metrics.auc(fpr_total, tpr_total)\n",
    "        \n",
    "    return_list = []\n",
    "    \n",
    "    for output in output_list:\n",
    "        \n",
    "        if(output == \"tr_loss\"):\n",
    "            return_list.append(tr_loss)\n",
    "                               \n",
    "        elif(output == \"tr_accuracy\"):\n",
    "            return_list.append(tr_accuracy)\n",
    "                               \n",
    "        elif(output == \"tr_sensitivity\"):\n",
    "            return_list.append(tr_sensitivity)\n",
    "                               \n",
    "        elif(output == \"tr_specificity\"):\n",
    "            return_list.append(tr_specificity)\n",
    "                               \n",
    "        elif(output == \"tr_predictions\"):\n",
    "            return_list.append(tr_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_tr_predictions\"):\n",
    "            return_list.append(labeled_tr_predictions)\n",
    "                               \n",
    "        elif(output == \"tr_predictions_flat\"):\n",
    "            return_list.append(tr_predictions_flat)\n",
    "            \n",
    "        elif(output == \"roc_auc_tr\"):\n",
    "            return_list.append(roc_auc_tr)\n",
    "\n",
    "        elif(output == \"ts_loss\"):\n",
    "            return_list.append(ts_loss)\n",
    "                               \n",
    "        elif(output == \"ts_accuracy\"):\n",
    "            return_list.append(ts_accuracy)\n",
    "                               \n",
    "        elif(output == \"ts_sensitivity\"):\n",
    "            return_list.append(ts_sensitivity)\n",
    "                               \n",
    "        elif(output == \"ts_specificity\"):\n",
    "            return_list.append(ts_specificity)\n",
    "                               \n",
    "        elif(output == \"ts_predictions\"):\n",
    "            return_list.append(ts_predictions)\n",
    "                               \n",
    "        elif(output == \"labeled_ts_predictions\"):\n",
    "            return_list.append(labeled_ts_predictions)\n",
    "                               \n",
    "        elif(output == \"ts_predictions_flat\"):\n",
    "            return_list.append(ts_predictions_flat)\n",
    "        \n",
    "        elif(output == \"roc_auc_ts\"):\n",
    "            return_list.append(roc_auc_ts)\n",
    "            \n",
    "        elif(output == \"roc_auc_total\"):\n",
    "            return_list.append(roc_auc_total)\n",
    "                               \n",
    "        else:\n",
    "            print(\"There are no options <\"+str(output)+\">. Please refer these output options:\\ntr_loss, tr_accuracy, tr_sensitivity, tr_specificity, tr_predictions, labeled_tr_predictions, tr_predictions_flat, roc_auc_tr,\\nts_loss, ts_accuracy, ts_sensitivity, ts_specificity, ts_predictions, labeled_ts_predictions, ts_predictions_flat, roc_auc_ts,\\nroc_auc_total\")\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage algorithm\n",
    "def ensemble_coverage(inputModels,x,y):\n",
    "    \n",
    "    outputModels = []\n",
    "    modelInfo = []\n",
    "    coverageTotal= [False]*len(y)\n",
    "    \n",
    "    for i in range(len(inputModels)):\n",
    "        m = inputModels[i]\n",
    "        yHat = m.predict(x[i])\n",
    "        yHat = [round(i) for [i] in yHat]\n",
    "        \n",
    "        loss, acc = m.evaluate(x[i],y)\n",
    "        modelInfo.append((m,yHat,acc))\n",
    "        #print(yHat[0:10])\n",
    "        #print(acc)\n",
    "    \n",
    "    modelInfo.sort(key=lambda x : x[2],reverse=True)\n",
    "    #print(modelInfo)\n",
    "    \n",
    "    for m,yHat,acc in modelInfo:\n",
    "        beforeCoverage = sum(coverageTotal)\n",
    "        coverage = [a == b for a,b in zip(y,yHat)]\n",
    "        coverageTotal = [a or b for a,b in zip(coverageTotal,coverage)]\n",
    "        afterCoverage = sum(coverageTotal)\n",
    "        \n",
    "        print(afterCoverage/len(y))\n",
    "        \n",
    "        if afterCoverage > beforeCoverage:\n",
    "            outputModels.append(m)\n",
    "            print(\"Increased Coverage : model added!\")\n",
    "        else:\n",
    "            print(\"Same Coverage : model not added\")\n",
    "        if afterCoverage == len(y):\n",
    "            print(\"Fully Covered!\")\n",
    "            break\n",
    "                \n",
    "    return outputModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation: import & preprocessing data + import module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input path & name of models / raw data for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test index(1~5): 1\n"
     ]
    }
   ],
   "source": [
    "# change model_path & each model_name.\n",
    "\n",
    "types = [\"OV_six_fold_Annotation3000_400\", \n",
    "         \"OV_six_fold_CV_400\", \n",
    "         \"OV_six_fold_Var_400\", \n",
    "         \"OV_six_fold_new_Diff_400\",\n",
    "         \"OV_six_fold_Clin\", \n",
    "         \"OV_six_fold_SNV_400\" \n",
    "         ]\n",
    "\n",
    "ch = input(\"test index(1~5): \")\n",
    "ts_i = int(ch)\n",
    "\n",
    "# input model path & ensemble data(Transcriptome, Cinical Information, Somatic Mutation data)\n",
    "# data path(server): /home/tjahn/TCGA_Ovary/01.Data/DNN/TC_intersect_subsamples_by_names \n",
    "input_model_path = \"../best_models/test_\"+str(ts_i)+\"/\"\n",
    "path = \"../TC_six_fold_subsamples/\"\n",
    "save_model_path = \"../models/\"\n",
    "save_prediction_path = \"../predictions/\"\n",
    "save_result_path = \"../result/\"\n",
    "\n",
    "model_names = []\n",
    "model_index = []\n",
    "files = os.listdir(input_model_path)\n",
    "\n",
    "for f in files:\n",
    "    ext= os.path.splitext(f)[-1]\n",
    "    if ext == \".h5\":\n",
    "        model_names.append(os.path.splitext(f)[0])\n",
    "        ind = int(f.split(\"_\")[1].split(\"-\")[0])\n",
    "        model_index.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_0-1_49\n",
      "OV_six_fold_Annotation3000_400\n",
      "\n",
      "m_0-1_62\n",
      "OV_six_fold_Annotation3000_400\n",
      "\n",
      "m_1-1_31\n",
      "OV_six_fold_CV_400\n",
      "\n",
      "m_1-1_43\n",
      "OV_six_fold_CV_400\n",
      "\n",
      "m_1-1_6\n",
      "OV_six_fold_CV_400\n",
      "\n",
      "m_2-1_57\n",
      "OV_six_fold_Var_400\n",
      "\n",
      "m_2-1_89\n",
      "OV_six_fold_Var_400\n",
      "\n",
      "m_3-1_15\n",
      "OV_six_fold_new_Diff_400\n",
      "\n",
      "m_3-1_18\n",
      "OV_six_fold_new_Diff_400\n",
      "\n",
      "m_4-1_101\n",
      "OV_six_fold_Clin\n",
      "\n",
      "m_4-1_40\n",
      "OV_six_fold_Clin\n",
      "\n",
      "m_5-1_2\n",
      "OV_six_fold_SNV_400\n",
      "\n",
      "m_5-1_40\n",
      "OV_six_fold_SNV_400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(model_index)):\n",
    "    print(model_names[t])\n",
    "    print(types[model_index[t]]+\"\\n\")\n",
    "    t = t+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### test index is [1] ###############\n",
      "\n",
      "\n",
      "model index: 0\n",
      "[0]: m_0-1_49 for type: OV_six_fold_Annotation3000_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 0\n",
      "[1]: m_0-1_62 for type: OV_six_fold_Annotation3000_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 1\n",
      "[2]: m_1-1_31 for type: OV_six_fold_CV_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 1\n",
      "[3]: m_1-1_43 for type: OV_six_fold_CV_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 1\n",
      "[4]: m_1-1_6 for type: OV_six_fold_CV_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 2\n",
      "[5]: m_2-1_57 for type: OV_six_fold_Var_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 2\n",
      "[6]: m_2-1_89 for type: OV_six_fold_Var_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 3\n",
      "[7]: m_3-1_15 for type: OV_six_fold_new_Diff_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 3\n",
      "[8]: m_3-1_18 for type: OV_six_fold_new_Diff_400.\n",
      " full tr & ts: (186, 400), (31, 400)\n",
      "\n",
      "model index: 4\n",
      "[9]: m_4-1_101 for type: OV_six_fold_Clin.\n",
      " full tr & ts: (256, 35), (31, 35)\n",
      "\n",
      "model index: 4\n",
      "[10]: m_4-1_40 for type: OV_six_fold_Clin.\n",
      " full tr & ts: (256, 35), (31, 35)\n",
      "\n",
      "model index: 5\n",
      "[11]: m_5-1_2 for type: OV_six_fold_SNV_400.\n",
      " full tr & ts: (182, 402), (31, 402)\n",
      "\n",
      "model index: 5\n",
      "[12]: m_5-1_40 for type: OV_six_fold_SNV_400.\n",
      " full tr & ts: (182, 402), (31, 402)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_1 = path+types[0]+\".csv\"\n",
    "file_2 = path+types[1]+\".csv\"\n",
    "file_3 = path+types[2]+\".csv\"\n",
    "file_4 = path+types[3]+\".csv\"\n",
    "file_5 = path+types[4]+\".csv\"\n",
    "file_6 = path+types[5]+\".csv\"\n",
    "\n",
    "idx_col = 0\n",
    "\n",
    "full_data_1 = pd.read_csv(file_1,index_col=idx_col)\n",
    "full_data_2 = pd.read_csv(file_2,index_col=idx_col)\n",
    "full_data_3 = pd.read_csv(file_3,index_col=idx_col)\n",
    "full_data_4 = pd.read_csv(file_4,index_col=idx_col)\n",
    "full_data_5 = pd.read_csv(file_5,index_col=idx_col)\n",
    "full_data_6 = pd.read_csv(file_6,index_col=idx_col)\n",
    "\n",
    "inter_data_1 = full_data_1.iloc[list(full_data_1.iloc[:,-1]!=6)]\n",
    "inter_data_2 = full_data_2.iloc[list(full_data_2.iloc[:,-1]!=6)]\n",
    "inter_data_3 = full_data_3.iloc[list(full_data_3.iloc[:,-1]!=6)]\n",
    "inter_data_4 = full_data_4.iloc[list(full_data_4.iloc[:,-1]!=6)]\n",
    "inter_data_5 = full_data_5.iloc[list(full_data_5.iloc[:,-1]!=6)]\n",
    "inter_data_6 = full_data_6.iloc[list(full_data_6.iloc[:,-1]!=6)]\n",
    "\n",
    "full_ds_list = [full_data_1, full_data_2, full_data_3, full_data_4, full_data_5, full_data_6]\n",
    "inter_ds_list = [inter_data_1, inter_data_2, inter_data_3, inter_data_4, inter_data_5, inter_data_6]\n",
    "\n",
    "# Split Train Test Data & Make full & inter dataset\n",
    "\n",
    "full_dataset = {\"tr_data\":[], \"ts_data\":[], \"tr_y_val\":[], \"tr_x_val\":[], \"ts_y_val\":[], \"ts_x_val\":[]}\n",
    "inter_dataset = {\"tr_data\":[], \"ts_data\":[], \"tr_y_val\":[], \"tr_x_val\":[], \"ts_y_val\":[], \"ts_x_val\":[]}\n",
    "\n",
    "\n",
    "print(\"############### test index is [\"+str(ts_i)+\"] ###############\\n\\n\")\n",
    "for m in range(len(model_index)):\n",
    "    print(\"model index: \"+str(model_index[m]))\n",
    "    full_tr_data, full_ts_data, full_tr_y_val, full_tr_x_val, full_ts_y_val, full_ts_x_val = data_split(raw_data = full_ds_list[model_index[m]], index_col = -1, test_index = ts_i)\n",
    "    print(\"[\"+str(m)+\"]: \"+model_names[m]+\" for type: \"+types[model_index[m]]+\".\\n full tr & ts: \"+str(full_tr_x_val.shape)+\", \"+str(full_ts_x_val.shape)+\"\\n\")\n",
    "    full_dataset['tr_data'].append(full_tr_data)\n",
    "    full_dataset['ts_data'].append(full_ts_data)\n",
    "    full_dataset['tr_x_val'].append(full_tr_x_val)\n",
    "    full_dataset['tr_y_val'].append(full_tr_y_val)\n",
    "    full_dataset['ts_x_val'].append(full_ts_x_val)\n",
    "    full_dataset['ts_y_val'].append(full_ts_y_val)  \n",
    "    inter_tr_data, inter_ts_data, inter_tr_y_val, inter_tr_x_val, inter_ts_y_val, inter_ts_x_val = data_split(raw_data = inter_ds_list[model_index[m]], index_col = -1, test_index = ts_i)\n",
    "    inter_dataset['tr_data'].append(inter_tr_data)\n",
    "    inter_dataset['ts_data'].append(inter_ts_data)\n",
    "    inter_dataset['tr_x_val'].append(inter_tr_x_val)\n",
    "    inter_dataset['tr_y_val'].append(inter_tr_y_val)\n",
    "    inter_dataset['ts_x_val'].append(inter_ts_x_val)\n",
    "    inter_dataset['ts_y_val'].append(inter_ts_y_val)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inter_newDiff_dataset = {\"tr_data\":[], \"ts_data\":[], \"tr_y_val\":[], \"tr_x_val\":[], \"ts_y_val\":[], \"ts_x_val\":[]}\\ninter_tr_data, inter_ts_data, inter_tr_y_val, inter_tr_x_val, inter_ts_y_val, inter_ts_x_val = data_split(raw_data = inter_ds_list[3], index_col = -1, test_index = ts_i)\\ninter_newDiff_dataset[\\'tr_data\\']= inter_tr_data\\ninter_newDiff_dataset[\\'ts_data\\']= inter_ts_data\\ninter_newDiff_dataset[\\'tr_x_val\\']= inter_tr_x_val\\ninter_newDiff_dataset[\\'tr_y_val\\']= inter_tr_y_val\\ninter_newDiff_dataset[\\'ts_x_val\\']= inter_ts_x_val\\ninter_newDiff_dataset[\\'ts_y_val\\']= inter_ts_y_val    \\n#inter_new_Diff_dataset = inter_dataset[1]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''inter_newDiff_dataset = {\"tr_data\":[], \"ts_data\":[], \"tr_y_val\":[], \"tr_x_val\":[], \"ts_y_val\":[], \"ts_x_val\":[]}\n",
    "inter_tr_data, inter_ts_data, inter_tr_y_val, inter_tr_x_val, inter_ts_y_val, inter_ts_x_val = data_split(raw_data = inter_ds_list[3], index_col = -1, test_index = ts_i)\n",
    "inter_newDiff_dataset['tr_data']= inter_tr_data\n",
    "inter_newDiff_dataset['ts_data']= inter_ts_data\n",
    "inter_newDiff_dataset['tr_x_val']= inter_tr_x_val\n",
    "inter_newDiff_dataset['tr_y_val']= inter_tr_y_val\n",
    "inter_newDiff_dataset['ts_x_val']= inter_ts_x_val\n",
    "inter_newDiff_dataset['ts_y_val']= inter_ts_y_val    \n",
    "#inter_new_Diff_dataset = inter_dataset[1]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import separate models & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 96us/step\n",
      "\n",
      "model: m_0-1_49\n",
      "tr & ts for inter data: 1.0, 0.774193525314331\n",
      "\n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_0-1_62\n",
      "tr & ts for inter data: 1.0, 0.7419354915618896\n",
      "\n",
      "122/122 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_1-1_31\n",
      "tr & ts for inter data: 0.9918032728257726, 0.6451612710952759\n",
      "\n",
      "122/122 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 96us/step\n",
      "\n",
      "model: m_1-1_43\n",
      "tr & ts for inter data: 1.0, 0.6451612710952759\n",
      "\n",
      "122/122 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_1-1_6\n",
      "tr & ts for inter data: 0.959016387579871, 0.6129032373428345\n",
      "\n",
      "122/122 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_2-1_57\n",
      "tr & ts for inter data: 1.0, 0.8387096524238586\n",
      "\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_2-1_89\n",
      "tr & ts for inter data: 1.0, 0.8387096524238586\n",
      "\n",
      "122/122 [==============================] - 1s 5ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_3-1_15\n",
      "tr & ts for inter data: 0.9180327878623712, 0.8709677457809448\n",
      "\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_3-1_18\n",
      "tr & ts for inter data: 0.9836065573770492, 0.8709677457809448\n",
      "\n",
      "122/122 [==============================] - 1s 4ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_4-1_101\n",
      "tr & ts for inter data: 0.9918032786885246, 0.774193525314331\n",
      "\n",
      "122/122 [==============================] - 1s 4ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_4-1_40\n",
      "tr & ts for inter data: 0.9754098370426991, 0.7419354915618896\n",
      "\n",
      "122/122 [==============================] - 1s 5ms/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "\n",
      "model: m_5-1_2\n",
      "tr & ts for inter data: 0.8360655747476171, 0.774193525314331\n",
      "\n",
      "122/122 [==============================] - 1s 5ms/step\n",
      "31/31 [==============================] - 0s 96us/step\n",
      "\n",
      "model: m_5-1_40\n",
      "tr & ts for inter data: 0.8032786836389636, 0.774193525314331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model load & evaluation. <model_n_l> is full-layer model, <model_n_l_new> is without-sigmoid-layer model.\n",
    "'''\n",
    "Each model's tr_accuracy can be differ to original model, but ts_accuracy should be same to original tested models.\n",
    "Because we using full-size data(about 200 patients data used Transcriptome, Clinical, SNV models.) for train each models.\n",
    "In contrast, in this code, we using ensemble-input data(intersected 153 patients).\n",
    "For-training-patients may be different in ensemble data and whole size data, but for-test-patients are the same.\n",
    "'''\n",
    "\n",
    "model_list = []\n",
    "model_output_list = {\"tr_accuracy\":[], \"tr_sensitivity\":[], \"tr_specificity\":[], \"tr_predictions\":[],\n",
    "                 \"labeled_tr_predictions\":[], \"tr_predictions_flat\":[], \"roc_auc_tr\":[], \n",
    "                 \"ts_accuracy\":[], \"ts_sensitivity\":[], \"ts_specificity\":[], \"ts_predictions\":[],\n",
    "                 \"labeled_ts_predictions\":[], \"ts_predictions_flat\":[], \"roc_auc_ts\":[], \n",
    "                 \"roc_auc_total\":[], \"tr_result\":[], \"ts_result\":[]}\n",
    "tr_predictions = []\n",
    "ts_predictions = []\n",
    "\n",
    "for m in range(len(model_names)):\n",
    "    \n",
    "    model_l = load_model(input_model_path+model_names[m]+\".h5\")\n",
    "    model_list.append(model_l)\n",
    "    output_list = output_list = model_performance(\n",
    "        information = False, using_model=model_l,Input_Prediction_Passively = False, \n",
    "        tr_x_val=inter_dataset['tr_x_val'][m], tr_y_val=inter_dataset['tr_y_val'][m], ts_x_val=inter_dataset['ts_x_val'][m], ts_y_val=inter_dataset['ts_y_val'][m],\n",
    "        output_list=[\"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                     \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                     \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                     \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                     \"roc_auc_total\"])\n",
    "    m_tr_accuracy, m_tr_sensitivity, m_tr_specificity, m_tr_predictions, m_labeled_tr_predictions, m_tr_predictions_flat, m_roc_auc_tr, m_ts_accuracy, m_ts_sensitivity, m_ts_specificity, m_ts_predictions,m_labeled_ts_predictions, m_ts_predictions_flat, m_roc_auc_ts, m_roc_auc_total = output_list\n",
    "    print(\"\\nmodel: \"+model_names[m])\n",
    "    print(\"tr & ts for inter data: \"+str(m_tr_accuracy)+\", \"+str(m_ts_accuracy)+\"\\n\")\n",
    "    \n",
    "    model_l_new = Model(inputs = model_l.input, outputs=model_l.get_layer(model_l.layers[-2].name).output)\n",
    "    m_tr_result = model_l_new.predict([inter_dataset['tr_x_val'][m]])\n",
    "    m_ts_result = model_l_new.predict([inter_dataset['ts_x_val'][m]])\n",
    "    \n",
    "    model_output_list[\"tr_accuracy\"].append(m_tr_accuracy)\n",
    "    model_output_list[\"tr_sensitivity\"].append(m_tr_sensitivity)\n",
    "    model_output_list[\"tr_specificity\"].append(m_tr_specificity)\n",
    "    model_output_list[\"ts_accuracy\"].append(m_ts_accuracy)\n",
    "    model_output_list[\"ts_sensitivity\"].append(m_ts_sensitivity)\n",
    "    model_output_list[\"ts_specificity\"].append(m_ts_specificity)\n",
    "    model_output_list[\"tr_result\"].append(m_tr_result)\n",
    "    \n",
    "    model_output_list[\"tr_predictions\"].append(m_tr_predictions)\n",
    "    model_output_list[\"labeled_tr_predictions\"].append(m_labeled_tr_predictions)\n",
    "    model_output_list[\"tr_predictions_flat\"].append(m_tr_predictions_flat)\n",
    "    model_output_list[\"roc_auc_tr\"].append(m_roc_auc_tr)\n",
    "    model_output_list[\"ts_predictions\"].append(m_ts_predictions)\n",
    "    model_output_list[\"labeled_ts_predictions\"].append(m_labeled_ts_predictions)\n",
    "    model_output_list[\"ts_predictions_flat\"].append(m_ts_predictions_flat)\n",
    "    model_output_list[\"roc_auc_ts\"].append(m_roc_auc_ts)\n",
    "    model_output_list[\"ts_result\"].append(m_ts_result)\n",
    "    \n",
    "    model_output_list[\"roc_auc_total\"].append(m_roc_auc_total)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6451612710952759 0.1111111111111111 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "print(model_output_list['ts_accuracy'][0], model_output_list['ts_sensitivity'][0], model_output_list['ts_specificity'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "1.0\n",
      "Increased Coverage : model added!\n",
      "Fully Covered!\n",
      "model numbers: 1\n"
     ]
    }
   ],
   "source": [
    "# select models automatically\n",
    "\n",
    "e_models_select = ensemble_coverage(model_list,inter_dataset[\"tr_x_val\"],inter_dataset[\"tr_y_val\"][0])\n",
    "print(\"model numbers: \"+str(len(e_models_select)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.9918032728257726,\n",
       " 1.0,\n",
       " 0.959016387579871,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9180327878623712,\n",
       " 0.9836065573770492,\n",
       " 0.9918032786885246,\n",
       " 0.9754098370426991,\n",
       " 0.8360655747476171,\n",
       " 0.8032786836389636]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names\n",
    "model_output_list['tr_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### [1] m_3-1_0 ####\n",
      "types: OV_six_fold_new_Diff_400\n",
      "tr: 1.0, ts: 0.7419354915618896\n",
      "\n",
      "#### [2] m_5-1_0 ####\n",
      "types: OV_six_fold_SNV_400\n",
      "tr: 0.7786885206816626, ts: 0.7096773982048035\n",
      "\n",
      "input numbers for selection(1 ~ 2. 'q' for quit.: 1\n",
      "input numbers for selection(1 ~ 2. 'q' for quit.: 2\n",
      "input numbers for selection(1 ~ 2. 'q' for quit.: q\n",
      "################### select models: m_3-1_0, m_5-1_0 ###################\n"
     ]
    }
   ],
   "source": [
    "# select models manually\n",
    "\n",
    "for m in range(len(model_names)):\n",
    "    print(\"#### [\"+str(m+1)+\"] \"+model_names[m]+\" ####\")\n",
    "    print(\"types: \"+types[model_index[m]])\n",
    "    print(\"tr: \"+str(model_output_list[\"tr_accuracy\"][m])+\", ts: \"+str(model_output_list[\"ts_accuracy\"][m])+\"\\n\")\n",
    "\n",
    "comb = ''\n",
    "select = []\n",
    "while 1:\n",
    "    ch = input(\"input numbers for selection(1 ~ \"+str(len(model_names))+\". \\'q\\' for quit.: \")\n",
    "    if(ch == 'q'):\n",
    "        break\n",
    "    else:\n",
    "        select.append(int(ch))\n",
    "        if(len(comb)<1):\n",
    "            comb = model_names[int(ch)-1]\n",
    "        else:\n",
    "            comb = comb + \", \" +model_names[int(ch)-1]\n",
    "        \n",
    "print(\"################### select models: \"+comb+\" ###################\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variables for saving performance & hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_list = []\n",
    "model_comb_list = []\n",
    "test_index_list = []\n",
    "tr_acc_list = []\n",
    "ts_acc_list = []\n",
    "tr_sensitivity_list = []\n",
    "ts_sensitivity_list = []\n",
    "tr_specificity_list = []\n",
    "ts_specificity_list = []\n",
    "tr_auc_list = []\n",
    "ts_auc_list = []\n",
    "tot_auc_list = []\n",
    "\n",
    "\n",
    "k = 0\n",
    "lr_box = []\n",
    "layers_box = []\n",
    "batch_size_box = []\n",
    "drop_out_box = []\n",
    "input_drop_out_box = []\n",
    "batch_normalize_box = []\n",
    "count_lim_box=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) DNN-Combiner Ensmeble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Input listup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tr_predictions_select = []\n",
    "m_ts_predictions_select = []   \n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_tr_predictions_select.append(model_output_list[\"tr_predictions\"][select[i]-1])\n",
    "    m_ts_predictions_select.append(model_output_list[\"ts_predictions\"][select[i]-1])\n",
    "    #print(m_tr_predictions[select[i]-1].shape)\n",
    "    \n",
    "em_tr_x_val = np.concatenate(m_tr_predictions_select, axis=1)\n",
    "em_ts_x_val = np.concatenate(m_ts_predictions_select, axis=1)\n",
    "\n",
    "tr_y_val = inter_dataset[\"tr_y_val\"][0]\n",
    "ts_y_val = inter_dataset[\"ts_y_val\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 2)\n",
      "(31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(em_tr_x_val.shape)\n",
    "print(em_ts_x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter change\n",
    "\n",
    "lr = 0.01\n",
    "drop_out_m = 0\n",
    "input_drop_out_m = 0.3\n",
    "batch_size = 10\n",
    "BN = True\n",
    "layers = [3]\n",
    "count_lim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################## DNN em ##################################\n",
      "select: [1, 2]\n",
      "\n",
      "OV_six_fold_new_Diff_400\n",
      "m_3-1_0\n",
      "\n",
      "OV_six_fold_SNV_400\n",
      "m_5-1_0\n",
      "#############################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 3ms/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "Model emDNN-1 trained.\n"
     ]
    }
   ],
   "source": [
    "print(\"################################## DNN em ##################################\")\n",
    "print(\"select: \"+str(select))\n",
    "for select_i in select:\n",
    "    print(\"\\n\"+types[model_index[select_i-1]])\n",
    "    print(model_names[select_i-1])\n",
    "\n",
    "    \n",
    "print(\"#############################################################################################\")\n",
    "\n",
    "# 1) parameter setting\n",
    "em_adam = optimizers.Adam(lr=lr)                                   \n",
    "em_tr_loss_best = 100 # for saving best loss value \n",
    "em_best_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "em_input = Input(shape=(len(select),))\n",
    "em_dp = Dropout(input_drop_out_m)(em_input)\n",
    "for l in layers:\n",
    "    if BN == True:\n",
    "        em_m = Dense(l)(em_dp)\n",
    "        em_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(em_m)\n",
    "        em_dp = Activation(\"relu\")(em_bn)\n",
    "    else:\n",
    "        em_m = Dense(l,activation='relu')(em_dp)\n",
    "        em_dp = Dropout(drop_out_m)(em_m)\n",
    "\n",
    "em_final = em_dp\n",
    "em_output = Dense(1, activation=\"sigmoid\")(em_final)\n",
    "em_model = Model(inputs=em_input,outputs=em_output)\n",
    "em_model.compile(optimizer=em_adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    em_model.fit(em_tr_x_val, tr_y_val, batch_size=batch_size, nb_epoch=1, verbose = 0)\n",
    "    em_tr_loss=em_model.evaluate( em_tr_x_val, tr_y_val)[0]\n",
    "    if em_tr_loss < em_tr_loss_best: # new best model. count reset.\n",
    "        em_tr_loss_best = em_tr_loss\n",
    "        count=0\n",
    "        em_best_model = em_model\n",
    "    if count>count_lim: # no increase three time. stop.\n",
    "        em_model = em_best_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "print(\"Model emDNN\" +\"-\"+str(ts_i)+\" trained.\")\n",
    "\n",
    "# 4) save model\n",
    "em_model.save(save_model_path+\"/m_emDNN-\"+str(ts_i)+\"_\"+str(k)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _DNN Combiner_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 98us/step\n",
      "31/31 [==============================] - 0s 32us/step\n",
      "Overall AUC:  0.9904862579281184\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8181818181818181\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.7096773982048035\n",
      "Test Sensitivities & Specificities : 0.4444444444444444, 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "em_output_list = model_performance(\n",
    "    information = False, using_model=em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=em_tr_x_val, tr_y_val=tr_y_val, ts_x_val=em_ts_x_val, ts_y_val=ts_y_val,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "em_tr_loss, em_tr_accuracy, em_tr_sensitivity, em_tr_specificity, em_tr_predictions, em_labeled_tr_predictions, em_tr_predictions_flat, em_roc_auc_tr, em_ts_loss, em_ts_accuracy, em_ts_sensitivity, em_ts_specificity, em_ts_predictions,em_labeled_ts_predictions, em_ts_predictions_flat, em_roc_auc_ts, em_roc_auc_total = em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", em_roc_auc_total)\n",
    "print(\"Train AUC: \", em_roc_auc_tr)\n",
    "print(\"Test AUC: \", em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(em_tr_sensitivity)+\", \"+str(em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(em_ts_sensitivity)+\", \"+str(em_ts_specificity))\n",
    "\n",
    "# save prediction result.\n",
    "\n",
    "tr_df_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"tr_data\"][0].index), \"hypothesis 1\": list(em_tr_predictions_flat), \n",
    "                        \"prediction\":list(em_labeled_tr_predictions), \"Platinum_Status\":list(tr_y_val)})\n",
    "tr_df_em.to_csv(save_prediction_path+\"emDNN-\"+str(ts_i)+\"_\"+str(k)+\"_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"ts_data\"][0].index), \"hypothesis 1\": list(em_ts_predictions_flat), \n",
    "                        \"prediction\":list(em_labeled_ts_predictions), \"Platinum_Status\":list(ts_y_val)})\n",
    "ts_df_em.to_csv(save_prediction_path+\"emDNN-\"+str(ts_i)+\"_\"+str(k)+\"_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "count_lim_box.append(count_lim)\n",
    "lr_box.append(lr)\n",
    "layers_box.append(layers)\n",
    "batch_size_box.append(batch_size)\n",
    "drop_out_box.append(drop_out_m)\n",
    "input_drop_out_box.append(input_drop_out_m)\n",
    "batch_normalize_box.append(BN)\n",
    "model_type_list.append(\"em-DNN\")\n",
    "model_comb_list.append(comb)\n",
    "test_index_list.append(ts_i)\n",
    "tr_acc_list.append(em_tr_accuracy)\n",
    "ts_acc_list.append(em_ts_accuracy)\n",
    "tr_sensitivity_list.append(em_tr_sensitivity)\n",
    "ts_sensitivity_list.append(em_ts_sensitivity)\n",
    "tr_specificity_list.append(em_tr_specificity)\n",
    "ts_specificity_list.append(em_ts_specificity)\n",
    "tr_auc_list.append(em_roc_auc_tr)\n",
    "ts_auc_list.append(em_roc_auc_ts)\n",
    "tot_auc_list.append(em_roc_auc_total)\n",
    "\n",
    "k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Mean Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating _mean_ ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC:  0.9847780126849894\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8282828282828283\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.7419354838709677\n",
      "Test Sensitivities & Specificities : 0.3333333333333333, 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "mean_em_tr_predictions=sum(m_tr_predictions_select)/len(select)\n",
    "mean_em_ts_predictions=sum(m_ts_predictions_select)/len(select)\n",
    "\n",
    "mean_em_output_list = model_performance(\n",
    "    information = False, using_model=None,Input_Prediction_Passively = True, \n",
    "    tr_predictions=mean_em_tr_predictions, ts_predictions=mean_em_ts_predictions, \n",
    "    tr_x_val=em_tr_x_val, tr_y_val=tr_y_val, ts_x_val=em_ts_x_val, ts_y_val=ts_y_val,\n",
    "    output_list=[\"tr_sensitivity\", \"tr_specificity\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_sensitivity\", \"ts_specificity\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "mean_em_tr_sensitivity, mean_em_tr_specificity,  mean_em_labeled_tr_predictions, mean_em_tr_predictions_flat, mean_em_roc_auc_tr, mean_em_ts_sensitivity, mean_em_ts_specificity, mean_em_labeled_ts_predictions, mean_em_ts_predictions_flat, mean_em_roc_auc_ts, mean_em_roc_auc_total = mean_em_output_list\n",
    "\n",
    "mean_em_tr_accuracy = sum(mean_em_labeled_tr_predictions==tr_y_val.values)/len(tr_y_val)\n",
    "mean_em_ts_accuracy = sum(mean_em_labeled_ts_predictions==ts_y_val.values)/len(ts_y_val)\n",
    "\n",
    "print(\"Overall AUC: \", mean_em_roc_auc_total)\n",
    "print(\"Train AUC: \", mean_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", mean_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(mean_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(mean_em_tr_sensitivity)+\", \"+str(mean_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(mean_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(mean_em_ts_sensitivity)+\", \"+str(mean_em_ts_specificity))\n",
    "\n",
    "# save prediction result.\n",
    "\n",
    "tr_df_mean = pd.DataFrame(data={\"patient\":list(inter_dataset[\"tr_data\"][0].index), \"hypothesis 1\": list(mean_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(mean_em_labeled_tr_predictions), \"Platinum_Status\":list(tr_y_val)})\n",
    "tr_df_mean.to_csv(save_prediction_path+\"emMean-\"+str(ts_i)+\"_\"+str(k)+\"_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_mean = pd.DataFrame(data={\"patient\":list(inter_dataset[\"ts_data\"][0].index), \"hypothesis 1\": list(mean_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(mean_em_labeled_ts_predictions), \"Platinum_Status\":list(ts_y_val)})\n",
    "ts_df_mean.to_csv(save_prediction_path+\"emMean-\"+str(ts_i)+\"_\"+str(k)+\"_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "count_lim_box.append(\"-\")\n",
    "lr_box.append(\"-\")\n",
    "layers_box.append(\"-\")\n",
    "batch_size_box.append(\"-\")\n",
    "drop_out_box.append(\"-\")\n",
    "input_drop_out_box.append(\"-\")\n",
    "batch_normalize_box.append(\"-\")\n",
    "model_type_list.append(\"em-Mean\")\n",
    "model_comb_list.append(comb)\n",
    "test_index_list.append(ts_i)\n",
    "tr_acc_list.append(mean_em_tr_accuracy)\n",
    "ts_acc_list.append(mean_em_ts_accuracy)\n",
    "tr_sensitivity_list.append(mean_em_tr_sensitivity)\n",
    "ts_sensitivity_list.append(mean_em_ts_sensitivity)\n",
    "tr_specificity_list.append(mean_em_tr_specificity)\n",
    "ts_specificity_list.append(mean_em_ts_specificity)\n",
    "tr_auc_list.append(mean_em_roc_auc_tr)\n",
    "ts_auc_list.append(mean_em_roc_auc_ts)\n",
    "tot_auc_list.append(mean_em_roc_auc_total)\n",
    "\n",
    "k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Transferred Ensemble Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making new input data for t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################### t-em x val merged. ###############################################\n",
      "\n",
      "(122, 50)\n",
      "(31, 50)\n"
     ]
    }
   ],
   "source": [
    "m_tr_result_select = []\n",
    "m_ts_result_select = []\n",
    "\n",
    "for i in range(len(select)):\n",
    "    m_tr_result_select.append(model_output_list[\"tr_result\"][select[i]-1])\n",
    "    m_ts_result_select.append(model_output_list[\"ts_result\"][select[i]-1])\n",
    "\n",
    "t_em_tr_x_val = np.concatenate(m_tr_result_select, axis=1)\n",
    "t_em_ts_x_val = np.concatenate(m_ts_result_select, axis=1)\n",
    "print(\"\\n############################################### t-em x val merged. ###############################################\\n\")\n",
    "print(t_em_tr_x_val.shape)\n",
    "print(t_em_ts_x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling t-ensemble  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter change\n",
    "\n",
    "lr = 0.01\n",
    "drop_out_m = 0\n",
    "input_drop_out_m = 0.2\n",
    "batch_size = 5\n",
    "BN = True\n",
    "layers = [100]\n",
    "count_lim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################## Transferred em ##################################\n",
      "select: [1, 2]\n",
      "\n",
      "OV_six_fold_new_Diff_400\n",
      "m_3-1_0\n",
      "\n",
      "OV_six_fold_SNV_400\n",
      "m_5-1_0\n",
      "#############################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 2ms/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 115us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 65us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 74us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 82us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Model em_T-1 trained.\n"
     ]
    }
   ],
   "source": [
    "print(\"################################## Transferred em ##################################\")\n",
    "print(\"select: \"+str(select))\n",
    "for select_i in select:\n",
    "    print(\"\\n\"+types[model_index[select_i-1]])\n",
    "    print(model_names[select_i-1])\n",
    "\n",
    "    \n",
    "print(\"#############################################################################################\")\n",
    "\n",
    "# 1) parameter setting\n",
    "t_em_adam = optimizers.Adam(lr=lr)                                   \n",
    "input_drop_out_m = 0.3\n",
    "drop_out_m = 0\n",
    "batch_size = 5\n",
    "BN = True                           \n",
    "layers = [100]\n",
    "\n",
    "t_em_tr_loss_best = 100 # for saving best loss value \n",
    "t_em_best_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "t_em_input = Input(shape=(t_em_ts_x_val.shape[1],))\n",
    "t_em_dp = Dropout(input_drop_out_m)(t_em_input)\n",
    "for l in layers:\n",
    "    if BN == True:\n",
    "        t_em_m = Dense(l)(t_em_dp)\n",
    "        t_em_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(t_em_m)\n",
    "        t_em_dp = Activation(\"relu\")(t_em_bn)\n",
    "    else:\n",
    "        t_em_m = Dense(l,activation='relu')(t_em_dp)\n",
    "        t_em_dp = Dropout(drop_out_m)(t_em_m)\n",
    "\n",
    "t_em_final = t_em_dp\n",
    "t_em_output = Dense(1, activation=\"sigmoid\")(t_em_final)\n",
    "t_em_model = Model(inputs=t_em_input,outputs=t_em_output)\n",
    "t_em_model.compile(optimizer=t_em_adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    t_em_model.fit(t_em_tr_x_val, tr_y_val, batch_size=batch_size, nb_epoch=1, verbose = 0)\n",
    "    t_em_tr_loss=t_em_model.evaluate( t_em_tr_x_val, tr_y_val)[0]\n",
    "    if t_em_tr_loss < t_em_tr_loss_best: # new best model. count reset.\n",
    "        t_em_tr_loss_best = t_em_tr_loss\n",
    "        count=0\n",
    "        t_em_best_model = t_em_model\n",
    "    if count>count_lim: # no increase three time. stop.\n",
    "        t_em_model = t_em_best_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "        \n",
    "print(\"Model em_T\" +\"-\"+str(ts_i)+\" trained.\")\n",
    "\n",
    "# 4) save model\n",
    "em_model.save(save_model_path+\"/m_emT-\"+str(ts_i)+\"_\"+str(k)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating t-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 114us/step\n",
      "31/31 [==============================] - 0s 32us/step\n",
      "Overall AUC:  0.9756871035940803\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.7828282828282828\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.774193525314331\n",
      "Test Sensitivities & Specificities : 0.8888888888888888, 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "t_em_output_list = model_performance(\n",
    "    information = False, using_model=t_em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=t_em_tr_x_val, tr_y_val=tr_y_val, ts_x_val=t_em_ts_x_val, ts_y_val=ts_y_val,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "t_em_tr_loss, t_em_tr_accuracy, t_em_tr_sensitivity, t_em_tr_specificity, t_em_tr_predictions, t_em_labeled_tr_predictions, t_em_tr_predictions_flat, t_em_roc_auc_tr, t_em_ts_loss, t_em_ts_accuracy, t_em_ts_sensitivity, t_em_ts_specificity, t_em_ts_predictions,t_em_labeled_ts_predictions, t_em_ts_predictions_flat, t_em_roc_auc_ts, t_em_roc_auc_total = t_em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", t_em_roc_auc_total)\n",
    "print(\"Train AUC: \", t_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", t_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(t_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(t_em_tr_sensitivity)+\", \"+str(t_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(t_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(t_em_ts_sensitivity)+\", \"+str(t_em_ts_specificity))\n",
    "\n",
    "# save prediction result.\n",
    "\n",
    "tr_df_t_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"tr_data\"][0].index), \"hypothesis 1\": list(t_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(t_em_labeled_tr_predictions), \"Platinum_Status\":list(tr_y_val)})\n",
    "tr_df_t_em.to_csv(save_prediction_path+\"m_emT-\"+str(ts_i)+\"_\"+str(k)+\"_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_t_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"ts_data\"][0].index), \"hypothesis 1\": list(t_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(t_em_labeled_ts_predictions), \"Platinum_Status\":list(ts_y_val)})\n",
    "ts_df_t_em.to_csv(save_prediction_path+\"m_emT-\"+str(ts_i)+\"_\"+str(k)+\"_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "count_lim_box.append(count_lim)\n",
    "lr_box.append(lr)\n",
    "layers_box.append(layers)\n",
    "batch_size_box.append(batch_size)\n",
    "drop_out_box.append(drop_out_m)\n",
    "input_drop_out_box.append(input_drop_out_m)\n",
    "batch_normalize_box.append(BN)\n",
    "model_type_list.append(\"em-T\")\n",
    "model_comb_list.append(comb)\n",
    "test_index_list.append(ts_i)\n",
    "tr_acc_list.append(t_em_tr_accuracy)\n",
    "ts_acc_list.append(t_em_ts_accuracy)\n",
    "tr_sensitivity_list.append(t_em_tr_sensitivity)\n",
    "ts_sensitivity_list.append(t_em_ts_sensitivity)\n",
    "tr_specificity_list.append(t_em_tr_specificity)\n",
    "ts_specificity_list.append(t_em_ts_specificity)\n",
    "tr_auc_list.append(t_em_roc_auc_tr)\n",
    "ts_auc_list.append(t_em_roc_auc_ts)\n",
    "tot_auc_list.append(t_em_roc_auc_total)\n",
    "\n",
    "k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hybrid ensemble input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset : raw data + prediction results\n",
    "h_em_tr_x_val = np.concatenate([inter_newDiff_dataset[\"tr_x_val\"], em_tr_x_val], axis = 1)\n",
    "h_em_ts_x_val = np.concatenate([inter_newDiff_dataset[\"ts_x_val\"], em_ts_x_val], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 402)\n",
      "(31, 402)\n"
     ]
    }
   ],
   "source": [
    "print(h_em_tr_x_val.shape)\n",
    "print(h_em_ts_x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter change\n",
    "\n",
    "lr = 0.05\n",
    "drop_out_m = 0\n",
    "input_drop_out_m = 0.4\n",
    "batch_size = 7\n",
    "BN = True\n",
    "layers = [120]\n",
    "count_lim = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hybrid ensemble model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hgh97\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 2ms/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 164us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 180us/step\n",
      "122/122 [==============================] - 0s 163us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 114us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 155us/step\n",
      "122/122 [==============================] - 0s 139us/step\n",
      "122/122 [==============================] - 0s 147us/step\n",
      "122/122 [==============================] - 0s 188us/step\n",
      "122/122 [==============================] - 0s 188us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 131us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 163us/step\n",
      "122/122 [==============================] - 0s 196us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 90us/step\n",
      "122/122 [==============================] - 0s 106us/step\n",
      "122/122 [==============================] - 0s 98us/step\n",
      "Model h-em-1 trained.\n",
      "122/122 [==============================] - 0s 123us/step\n",
      "31/31 [==============================] - 0s 64us/step\n",
      "Overall AUC:  0.9828752642706131\n",
      "Train AUC:  1.0\n",
      "Test AUC:  0.8080808080808081\n",
      "Train Accuracy: 1.0\n",
      "Train Sensitivities & Specificities : 1.0, 1.0\n",
      "Test Accuracy: 0.774193525314331\n",
      "Test Sensitivities & Specificities : 0.5555555555555556, 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "print(\"hybrid ensemble model\")\n",
    "\n",
    "# 1) parameter setting\n",
    "h_em_adam = optimizers.Adam(lr=lr)\n",
    "h_em_tr_loss_best = 100 # for saving best loss value \n",
    "h_em_best_model=[] #for saving best model\n",
    "count=0 # for early stopping\n",
    "\n",
    "# 2) model build\n",
    "h_em_input = Input(shape=(h_em_ts_x_val.shape[1],))\n",
    "h_em_dp = Dropout(input_drop_out_m)(h_em_input)\n",
    "for l in layers:\n",
    "    if BN == True:\n",
    "        h_em_m = Dense(l)(h_em_dp)\n",
    "        h_em_bn = BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(h_em_m)\n",
    "        h_em_dp = Activation(\"relu\")(h_em_bn)\n",
    "    else:\n",
    "        h_em_m = Dense(l,activation='relu')(h_em_dp)\n",
    "        h_em_dp = Dropout(drop_out_m)(h_em_m)\n",
    "\n",
    "h_em_final = h_em_dp\n",
    "h_em_output = Dense(1, activation=\"sigmoid\")(h_em_final)\n",
    "h_em_model = Model(inputs=h_em_input,outputs=h_em_output)\n",
    "h_em_model.compile(optimizer=h_em_adam, \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3) Training: if no increase of tr_loss three times, stop training.\n",
    "while 1:\n",
    "    h_em_model.fit(h_em_tr_x_val, tr_y_val, batch_size=batch_size, nb_epoch=1, verbose = 0)\n",
    "    h_em_tr_loss=h_em_model.evaluate( h_em_tr_x_val, tr_y_val)[0]\n",
    "    if h_em_tr_loss < h_em_tr_loss_best: # new best model. count reset.\n",
    "        h_em_tr_loss_best = h_em_tr_loss\n",
    "        count=0\n",
    "        h_em_best_model = h_em_model\n",
    "    if count>count_lim: # no increase three time. stop.\n",
    "        h_em_model = h_em_best_model\n",
    "        break\n",
    "    else: count=count+1\n",
    "        \n",
    "print(\"Model h-em\" +\"-\"+str(ts_i)+\" trained.\")\n",
    "\n",
    "# 4) save model\n",
    "em_model.save(save_model_path+\"/m_emH-\"+str(ts_i)+\".h5\")\n",
    "\n",
    "# 5) evaluate model\n",
    "h_em_output_list = model_performance(\n",
    "    information = False, using_model=h_em_model,Input_Prediction_Passively = False, \n",
    "    tr_x_val=h_em_tr_x_val, tr_y_val=tr_y_val, ts_x_val=h_em_ts_x_val, ts_y_val=ts_y_val,\n",
    "    output_list=[\"tr_loss\", \"tr_accuracy\", \"tr_sensitivity\", \"tr_specificity\", \"tr_predictions\",\n",
    "                 \"labeled_tr_predictions\", \"tr_predictions_flat\", \"roc_auc_tr\", \n",
    "                 \"ts_loss\", \"ts_accuracy\", \"ts_sensitivity\", \"ts_specificity\", \"ts_predictions\",\n",
    "                 \"labeled_ts_predictions\", \"ts_predictions_flat\", \"roc_auc_ts\", \n",
    "                 \"roc_auc_total\"])\n",
    "\n",
    "h_em_tr_loss, h_em_tr_accuracy, h_em_tr_sensitivity, h_em_tr_specificity, h_em_tr_predictions, h_em_labeled_tr_predictions, h_em_tr_predictions_flat, h_em_roc_auc_tr, h_em_ts_loss, h_em_ts_accuracy, h_em_ts_sensitivity, h_em_ts_specificity, h_em_ts_predictions,h_em_labeled_ts_predictions, h_em_ts_predictions_flat, h_em_roc_auc_ts, h_em_roc_auc_total = h_em_output_list\n",
    "\n",
    "print(\"Overall AUC: \", h_em_roc_auc_total)\n",
    "print(\"Train AUC: \", h_em_roc_auc_tr)\n",
    "print(\"Test AUC: \", h_em_roc_auc_ts)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(h_em_tr_accuracy))\n",
    "print(\"Train Sensitivities & Specificities : \"+str(h_em_tr_sensitivity)+\", \"+str(h_em_tr_specificity))\n",
    "print(\"Test Accuracy: {}\".format(h_em_ts_accuracy))\n",
    "print(\"Test Sensitivities & Specificities : \"+str(h_em_ts_sensitivity)+\", \"+str(h_em_ts_specificity))\n",
    "\n",
    "# save prediction result.\n",
    "\n",
    "tr_df_h_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"tr_data\"][0].index), \"hypothesis 1\": list(h_em_tr_predictions_flat), \n",
    "                        \"prediction\":list(h_em_labeled_tr_predictions), \"Platinum_Status\":list(tr_y_val)})\n",
    "tr_df_h_em.to_csv(save_prediction_path+\"m_emH-\"+str(ts_i)+\"_\"+str(k)+\"_tr.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "ts_df_h_em = pd.DataFrame(data={\"patient\":list(inter_dataset[\"ts_data\"][0].index), \"hypothesis 1\": list(h_em_ts_predictions_flat), \n",
    "                        \"prediction\":list(h_em_labeled_ts_predictions), \"Platinum_Status\":list(ts_y_val)})\n",
    "ts_df_h_em.to_csv(save_prediction_path+\"m_emH-\"+str(ts_i)+\"_\"+str(k)+\"_ts.csv\", index=False, header=True, columns = [\"patient\", \"hypothesis 1\", \"prediction\", \"Platinum_Status\"])\n",
    "\n",
    "count_lim_box.append(count_lim)\n",
    "lr_box.append(lr)\n",
    "layers_box.append(layers)\n",
    "batch_size_box.append(batch_size)\n",
    "drop_out_box.append(drop_out_m)\n",
    "input_drop_out_box.append(input_drop_out_m)\n",
    "batch_normalize_box.append(BN)\n",
    "model_type_list.append(\"em-H\")\n",
    "model_comb_list.append(comb)\n",
    "test_index_list.append(ts_i)\n",
    "tr_acc_list.append(h_em_tr_accuracy)\n",
    "ts_acc_list.append(h_em_ts_accuracy)\n",
    "tr_sensitivity_list.append(h_em_tr_sensitivity)\n",
    "ts_sensitivity_list.append(h_em_ts_sensitivity)\n",
    "tr_specificity_list.append(h_em_tr_specificity)\n",
    "ts_specificity_list.append(h_em_ts_specificity)\n",
    "tr_auc_list.append(h_em_roc_auc_tr)\n",
    "ts_auc_list.append(h_em_roc_auc_ts)\n",
    "tot_auc_list.append(h_em_roc_auc_total)\n",
    "\n",
    "k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df(data = {'model_types':model_type_list,\n",
    "                  'model_comb':model_comb_list,\n",
    "                'index': range(0,k),\n",
    "                'rate':lr_box,\n",
    "                'count':count_lim_box,\n",
    "                'layers':layers_box,\n",
    "                'batch_size': batch_size_box,\n",
    "                'input_drop_out':input_drop_out_box,\n",
    "                'drop_out':drop_out_box,\n",
    "                'batch_normalize':batch_normalize_box,\n",
    "                'test_index':test_index_list ,\n",
    "                'tr_accuracy':tr_acc_list, \n",
    "                'tr_sensitivity':tr_sensitivity_list, \n",
    "                'tr_specificity':tr_specificity_list, \n",
    "                'ts_accuracy': ts_acc_list,\n",
    "                'ts_sensitivity':ts_sensitivity_list, \n",
    "                'ts_specificity':ts_specificity_list, \n",
    "                \"tr_auc\":tr_auc_list, \n",
    "                \"ts_auc\":ts_auc_list, \n",
    "                \"total_auc\":tot_auc_list}, \n",
    "          columns =['index','model_types','model_comb', 'test_index', 'rate', 'count', 'layers','batch_size','input_drop_out','drop_out','batch_normalize', 'tr_accuracy', 'tr_sensitivity', 'tr_specificity', 'ts_accuracy', 'ts_sensitivity', 'ts_specificity', \"tr_auc\", \"ts_auc\", \"total_auc\"])\n",
    "df_1.to_csv(save_result_path+\"Ensembles_\"+str(ts_i)+\".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
